<!doctype html><html lang=pt class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Plataforma para disponibilização cursos de cálculo."><link href=https:///disponha.com/pre_calculo/funcoes/introducao_a_funcao/ rel=canonical><meta name=author content="Carlos André"><link rel="shortcut icon" href=../../../assets/favicon.png><meta name=generator content="mkdocs-1.1.2, mkdocs-material-5.4.0"><title>Introducao a funcao - disponha</title><link rel=stylesheet href=../../../assets/stylesheets/main.545621a7.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.36d1b78f.min.css><meta name=theme-color content=#009688><link href=https://fonts.gstatic.com rel=preconnect crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Helvetica:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>body,input{font-family:"Helvetica",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","None","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){if(this.value){var e=document.location.pathname;ga("send","pageview",e+"?q="+this.value)}})}),document.addEventListener("DOMContentSwitch",function(){ga("send","pageview")})</script><script async src=https://www.google-analytics.com/analytics.js></script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=teal data-md-color-accent=teal> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#goal-of-frozen-lake class=md-skip> Ir para o conteúdo </a> </div> <!-- 
    <div data-md-component="announce">
      
    </div>
  --> <header class=md-header data-md-component=header> <nav class="md-header-nav md-grid" aria-label=Header> <a href=https:/disponha.com title=disponha class="md-header-nav__button md-logo" aria-label=disponha> <?xml version="1.0" encoding="UTF-8"?> <!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><!-- Creator: CorelDRAW X7 --><svg xmlns=http://www.w3.org/2000/svg xml:space=preserve width=9000px height=9000px version=1.1 style="shape-rendering:geometricPrecision; text-rendering:geometricPrecision; image-rendering:optimizeQuality; fill-rule:evenodd; clip-rule:evenodd" viewbox="0 0 9000 9000" xmlns:xlink=http://www.w3.org/1999/xlink> <defs> <style type=text/css>
   <![CDATA[
    .str0 {stroke:#2E72A4;stroke-width:118.11}
    .fil0 {fill:#FEFEFE}
    .fil1 {fill:#2E72A4}
   ]]>
  </style> </defs> <g id=Camada_x0020_1> <metadata id=CorelCorpID_0Corel-Layer /> <g id=_1793748728448> <circle cx=4472 cy=4507 r=4281 class="fil0 str0"/> <path class="fil1 str0" d="M2045 5171c120,204 210,379 402,449 314,115 1000,-177 1339,-330 79,-35 179,-68 254,-120 41,-13 94,-46 135,-68l951 -479c363,-177 729,-363 1095,-521 186,-80 370,-180 558,-244 465,-158 1366,-413 1814,-369l1 -59c-328,-34 -853,93 -1189,181 -431,113 -680,200 -1103,395 -706,324 -1401,670 -2099,1021 -397,199 -1256,618 -1669,556 -218,-33 -320,-195 -449,-416 -47,-80 -137,-241 -177,-328 -49,-108 -114,-212 -179,-311 -379,-575 -831,-826 -1274,-1083l-119 -63 -10 46 247 149c311,184 648,381 929,716 107,128 198,250 291,408 61,104 217,424 252,470z"/> </g> </g> </svg> </a> <label class="md-header-nav__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header-nav__title data-md-component=header-title> <div class=md-header-nav__ellipsis> <span class="md-header-nav__topic md-ellipsis"> disponha </span> <span class="md-header-nav__topic md-ellipsis"> Introducao a funcao </span> </div> </div> <label class="md-header-nav__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Buscar placeholder=Buscar autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query data-md-state=active> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <button type=reset class="md-search__icon md-icon" aria-label=Clear data-md-component=search-reset tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header-nav__source> <!-- 

<a href="https://github.com/andhremattos/" title="Ir ao repositório" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    esead
  </div>
</a>
--> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list> <li class=md-tabs__item> <!--
      <a href="../../.." class="md-tabs__link md-tabs__link--active">
        Home
      </a>
    --> <a href=/explore/ class="md-tabs__link md-tabs__link--active"> Explore e-books </a> </li> <!--
    <li class="md-tabs__item">
      
        <a href="../../../sobre/" class="md-tabs__link">
          Sobre
        </a>
      
    </li>--> <!--
    <li class="md-tabs__item">
      
        <a href="../../../explore/" class="md-tabs__link">
          Explore
        </a>
      
    </li>--> <!--
    <li class="md-tabs__item">
      
        <a href="../../../app_web_ebook/servico/" class="md-tabs__link">
          App Web ebook
        </a>
      
    </li>--> <!--
    <li class="md-tabs__item">
      
        <a href="../../../diagramacao/servico/" class="md-tabs__link">
          Diagramação
        </a>
      
    </li>--> <!--
    <li class="md-tabs__item">
      
        <a href="../../../ciencia_de_dados/servico/" class="md-tabs__link">
          Ciência de dados
        </a>
      
    </li>--> <!--
    <li class="md-tabs__item">
      
        <a href="../../../aprendacalculo/" class="md-tabs__link">
          Aprenda Cálculo
        </a>
      
    </li>--> <!--
    <li class="md-tabs__item">
      
        <a href="../../../cursolatex/" class="md-tabs__link">
          Curso de LaTeX
        </a>
      
    </li>--> <!--
    <li class="md-tabs__item">
      
        <a href="../../../pre-calculo/conjuntos/" class="md-tabs__link">
          Pré-cálculo
        </a>
      
    </li>--> <!--
    <li class="md-tabs__item">
      
        <a href="../../../limite/definicao/" class="md-tabs__link">
          Limite
        </a>
      
    </li>--> <!--
    <li class="md-tabs__item">
      
        <a href="../../../derivada/inclinacao-reta/" class="md-tabs__link">
          Derivada
        </a>
      
    </li>--> <!--
    <li class="md-tabs__item">
      
        <a href="../../../aplicacao/definicao/" class="md-tabs__link">
          Aplicações
        </a>
      
    </li>--> <!--
    <li class="md-tabs__item">
      
        <a href="../../../integral/definicao/" class="md-tabs__link">
          Integral
        </a>
      
    </li>--> <!--
    <li class="md-tabs__item">
      
        <a href="../../../listas/limite/" class="md-tabs__link">
          Listas
        </a>
      
    </li>--> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=https:/disponha.com title=disponha class="md-nav__button md-logo" aria-label=disponha> <?xml version="1.0" encoding="UTF-8"?> <!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><!-- Creator: CorelDRAW X7 --><svg xmlns=http://www.w3.org/2000/svg xml:space=preserve width=9000px height=9000px version=1.1 style="shape-rendering:geometricPrecision; text-rendering:geometricPrecision; image-rendering:optimizeQuality; fill-rule:evenodd; clip-rule:evenodd" viewbox="0 0 9000 9000" xmlns:xlink=http://www.w3.org/1999/xlink> <defs> <style type=text/css>
   <![CDATA[
    .str0 {stroke:#2E72A4;stroke-width:118.11}
    .fil0 {fill:#FEFEFE}
    .fil1 {fill:#2E72A4}
   ]]>
  </style> </defs> <g id=Camada_x0020_1> <metadata id=CorelCorpID_0Corel-Layer /> <g id=_1793748728448> <circle cx=4472 cy=4507 r=4281 class="fil0 str0"/> <path class="fil1 str0" d="M2045 5171c120,204 210,379 402,449 314,115 1000,-177 1339,-330 79,-35 179,-68 254,-120 41,-13 94,-46 135,-68l951 -479c363,-177 729,-363 1095,-521 186,-80 370,-180 558,-244 465,-158 1366,-413 1814,-369l1 -59c-328,-34 -853,93 -1189,181 -431,113 -680,200 -1103,395 -706,324 -1401,670 -2099,1021 -397,199 -1256,618 -1669,556 -218,-33 -320,-195 -449,-416 -47,-80 -137,-241 -177,-328 -49,-108 -114,-212 -179,-311 -379,-575 -831,-826 -1274,-1083l-119 -63 -10 46 247 149c311,184 648,381 929,716 107,128 198,250 291,408 61,104 217,424 252,470z"/> </g> </g> </svg> </a> disponha </label> <div class=md-nav__source> <!-- 

<a href="https://github.com/andhremattos/" title="Ir ao repositório" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    esead
  </div>
</a>
--> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. title=Home class=md-nav__link> Home </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2 type=checkbox id=nav-2> <label class=md-nav__link for=nav-2> Sobre <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Sobre data-md-level=1> <label class=md-nav__title for=nav-2> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Sobre </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../sobre/ title=Home class=md-nav__link> Home </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3 type=checkbox id=nav-3> <label class=md-nav__link for=nav-3> Explore <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Explore data-md-level=1> <label class=md-nav__title for=nav-3> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Explore </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../explore/ title=E-books class=md-nav__link> E-books </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../apoie/ title=Apoie class=md-nav__link> Apoie </a> </li> <li class=md-nav__item> <a href=../../../consultoria/ title=Consultoria class=md-nav__link> Consultoria </a> </li> <li class=md-nav__item> <a href=../../../politica_privacidade/ title=Privacidade class=md-nav__link> Privacidade </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-7 type=checkbox id=nav-7> <label class=md-nav__link for=nav-7> App Web ebook <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="App Web ebook" data-md-level=1> <label class=md-nav__title for=nav-7> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> App Web ebook </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../app_web_ebook/servico/ title=Serviço class=md-nav__link> Serviço </a> </li> <li class=md-nav__item> <a href=../../../app_web_ebook/amostra/ title="App Web ebook - amostra" class=md-nav__link> App Web ebook - amostra </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-8 type=checkbox id=nav-8> <label class=md-nav__link for=nav-8> Diagramação <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Diagramação data-md-level=1> <label class=md-nav__title for=nav-8> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Diagramação </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../diagramacao/servico/ title=Serviço class=md-nav__link> Serviço </a> </li> <li class=md-nav__item> <a href=../../../diagramacao/amostra-diagramacao/ title=Amostra class=md-nav__link> Amostra </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-9 type=checkbox id=nav-9> <label class=md-nav__link for=nav-9> Ciência de dados <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="Ciência de dados" data-md-level=1> <label class=md-nav__title for=nav-9> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Ciência de dados </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../ciencia_de_dados/servico/ title=Serviço class=md-nav__link> Serviço </a> </li> <li class=md-nav__item> <a href=../../../ciencia_de_dados/amostra-1/ title="Amostra 1" class=md-nav__link> Amostra 1 </a> </li> <li class=md-nav__item> <a href=../../../ciencia_de_dados/amostra-2/ title="Amostra 2" class=md-nav__link> Amostra 2 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-10 type=checkbox id=nav-10> <label class=md-nav__link for=nav-10> Aprenda Cálculo <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="Aprenda Cálculo" data-md-level=1> <label class=md-nav__title for=nav-10> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Aprenda Cálculo </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../aprendacalculo/ title=Bem-Vindo(a)s class=md-nav__link> Bem-Vindo(a)s </a> </li> <li class=md-nav__item> <a href=../../../aprendacalculo/pre_calculo/ title=Pré-Cálculo class=md-nav__link> Pré-Cálculo </a> </li> <li class=md-nav__item> <a href=../../../aprendacalculo/calculo_i/ title="Cálculo I" class=md-nav__link> Cálculo I </a> </li> <li class=md-nav__item> <a href=../../../aprendacalculo/calculo_ii/ title="Cálculo II" class=md-nav__link> Cálculo II </a> </li> <li class=md-nav__item> <a href=../../../aprendacalculo/calculo_iii/ title="Cálculo III" class=md-nav__link> Cálculo III </a> </li> <li class=md-nav__item> <a href=../../../aprendacalculo/calculo_iv/ title="Cálculo IV" class=md-nav__link> Cálculo IV </a> </li> <li class=md-nav__item> <a href=../../../aprendacalculo/calculo_numerico/ title="C. Numérico" class=md-nav__link> C. Numérico </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-11 type=checkbox id=nav-11> <label class=md-nav__link for=nav-11> Curso de LaTeX <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="Curso de LaTeX" data-md-level=1> <label class=md-nav__title for=nav-11> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Curso de LaTeX </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../cursolatex/ title=Bem-Vindo(a)s class=md-nav__link> Bem-Vindo(a)s </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/programas/ title=Programas class=md-nav__link> Programas </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/latex_online/ title="LaTeX online" class=md-nav__link> LaTeX online </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/parte_1/ title="Parte 1" class=md-nav__link> Parte 1 </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/parte_2/ title="Parte 2" class=md-nav__link> Parte 2 </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/parte_3/ title="Parte 3" class=md-nav__link> Parte 3 </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/parte_4/ title="Parte 4" class=md-nav__link> Parte 4 </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/parte_5/ title="Parte 5" class=md-nav__link> Parte 5 </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/parte_6/ title="Parte 6" class=md-nav__link> Parte 6 </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/parte_7/ title="Parte 7" class=md-nav__link> Parte 7 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-12 type=checkbox id=nav-12> <label class=md-nav__link for=nav-12> Pré-cálculo <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Pré-cálculo data-md-level=1> <label class=md-nav__title for=nav-12> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Pré-cálculo </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../pre-calculo/conjuntos/ title=Conjuntos class=md-nav__link> Conjuntos </a> </li> <li class=md-nav__item> <a href=../../../pre-calculo/conjuntos-numericos/ title="Conjuntos Numéricos" class=md-nav__link> Conjuntos Numéricos </a> </li> <li class=md-nav__item> <a href=../../../pre-calculo/divisibilidade/ title=Divisibilidade class=md-nav__link> Divisibilidade </a> </li> <li class=md-nav__item> <a href=../../../pre-calculo/operacoes-numericas/ title="Operações Numéricas" class=md-nav__link> Operações Numéricas </a> </li> <li class=md-nav__item> <a href=../../../pre-calculo/potenciacao/ title=Potenciação class=md-nav__link> Potenciação </a> </li> <li class=md-nav__item> <a href=../../../pre-calculo/expressoes-algebricas/ title="Expressões Algébricas" class=md-nav__link> Expressões Algébricas </a> </li> <li class=md-nav__item> <a href=../../../pre-calculo/equacoes/ title=Equações class=md-nav__link> Equações </a> </li> <li class=md-nav__item> <a href=../../../pre-calculo/inequacoes.md title=Inequações class=md-nav__link> Inequações </a> </li> <li class=md-nav__item> <a href=../../../pre-calculo/funcoes/ title=Funções class=md-nav__link> Funções </a> </li> <li class=md-nav__item> <a href=../../../pre-calculo/trigonometria/ title=Trigonometria class=md-nav__link> Trigonometria </a> </li> <li class=md-nav__item> <a href=../../../pre-calculo/funcoes-exponenciais/ title="Funções Exponenciais" class=md-nav__link> Funções Exponenciais </a> </li> <li class=md-nav__item> <a href=../../../pre-calculo/funcoes-logaritmicas/ title="Funções Logarítmicas" class=md-nav__link> Funções Logarítmicas </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-13 type=checkbox id=nav-13> <label class=md-nav__link for=nav-13> Limite <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Limite data-md-level=1> <label class=md-nav__title for=nav-13> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Limite </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../limite/definicao/ title=Definição class=md-nav__link> Definição </a> </li> <li class=md-nav__item> <a href=../../../limite/propriedades/ title=Propriedades class=md-nav__link> Propriedades </a> </li> <li class=md-nav__item> <a href=../../../limite/indeterminados/ title=Indeterminados class=md-nav__link> Indeterminados </a> </li> <li class=md-nav__item> <a href=../../../limite/laterais/ title=Laterais class=md-nav__link> Laterais </a> </li> <li class=md-nav__item> <a href=../../../limite/infinitos/ title=Infinitos class=md-nav__link> Infinitos </a> </li> <li class=md-nav__item> <a href=../../../limite/no-infinito/ title="No infinito" class=md-nav__link> No infinito </a> </li> <li class=md-nav__item> <a href=../../../limite/assintotas/ title=Assíntotas class=md-nav__link> Assíntotas </a> </li> <li class=md-nav__item> <a href=../../../limite/continuidade/ title=Continuidade class=md-nav__link> Continuidade </a> </li> <li class=md-nav__item> <a href=../../../limite/teo-confronto/ title="Teo. do Confronto" class=md-nav__link> Teo. do Confronto </a> </li> <li class=md-nav__item> <a href=../../../limite/fundamentais/ title=Fundamentais class=md-nav__link> Fundamentais </a> </li> <li class=md-nav__item> <a href=../../../limite/exercicios/ title=Exercícios class=md-nav__link> Exercícios </a> </li> <li class=md-nav__item> <a href=../../../limite/creative-commons/ title=Licença class=md-nav__link> Licença </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-14 type=checkbox id=nav-14> <label class=md-nav__link for=nav-14> Derivada <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Derivada data-md-level=1> <label class=md-nav__title for=nav-14> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Derivada </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../derivada/inclinacao-reta/ title=Inclinação class=md-nav__link> Inclinação </a> </li> <li class=md-nav__item> <a href=../../../derivada/definicao/ title=Definição class=md-nav__link> Definição </a> </li> <li class=md-nav__item> <a href=../../../derivada/funcao-derivada/ title="Função derivada" class=md-nav__link> Função derivada </a> </li> <li class=md-nav__item> <a href=../../../derivada/propriedades/ title=Propriedades class=md-nav__link> Propriedades </a> </li> <li class=md-nav__item> <a href=../../../derivada/creative-commons/ title=Licença class=md-nav__link> Licença </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-15 type=checkbox id=nav-15> <label class=md-nav__link for=nav-15> Aplicações <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Aplicações data-md-level=1> <label class=md-nav__title for=nav-15> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Aplicações </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../aplicacao/definicao/ title=Definição class=md-nav__link> Definição </a> </li> <li class=md-nav__item> <a href=../../../aplicacao/propriedades/ title=Propriedades class=md-nav__link> Propriedades </a> </li> <li class=md-nav__item> <a href=../../../aplicacao/creative-commons/ title=Licença class=md-nav__link> Licença </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-16 type=checkbox id=nav-16> <label class=md-nav__link for=nav-16> Integral <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Integral data-md-level=1> <label class=md-nav__title for=nav-16> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Integral </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../integral/definicao/ title=Definição class=md-nav__link> Definição </a> </li> <li class=md-nav__item> <a href=../../../integral/propriedades/ title=Propriedades class=md-nav__link> Propriedades </a> </li> <li class=md-nav__item> <a href=../../../integral/creative-commons/ title=Licença class=md-nav__link> Licença </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-17 type=checkbox id=nav-17> <label class=md-nav__link for=nav-17> Listas <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Listas data-md-level=1> <label class=md-nav__title for=nav-17> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Listas </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../listas/limite/ title=Limite class=md-nav__link> Limite </a> </li> <li class=md-nav__item> <a href=../../../listas/limite-extra/ title="Limite extra" class=md-nav__link> Limite extra </a> </li> <li class=md-nav__item> <a href=../../../listas/limite-extra-2/ title="Limite extra 2" class=md-nav__link> Limite extra 2 </a> </li> <li class=md-nav__item> <a href=../../../listas/derivada/ title=Derivada class=md-nav__link> Derivada </a> </li> <li class=md-nav__item> <a href=../../../listas/aplicacao/ title=Aplicações class=md-nav__link> Aplicações </a> </li> <li class=md-nav__item> <a href=../../../listas/integral/ title=Integral class=md-nav__link> Integral </a> </li> <li class=md-nav__item> <a href=../../../listas/creative-commons/ title=Licença class=md-nav__link> Licença </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label=Índice> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Índice </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=#goal-of-frozen-lake class=md-nav__link> Goal of Frozen Lake </a> </li> <li class=md-nav__item> <a href=#why-dynamic-programming class=md-nav__link> Why Dynamic Programming? </a> </li> <li class=md-nav__item> <a href=#deterministic-policy-environment class=md-nav__link> Deterministic Policy Environment </a> <nav class=md-nav aria-label="Deterministic Policy Environment"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#making-steps class=md-nav__link> Making Steps </a> </li> <li class=md-nav__item> <a href=#dying-drop-in-hole-grid-12-h class=md-nav__link> Dying: drop in hole grid 12, H </a> </li> <li class=md-nav__item> <a href=#winning-get-to-grid-15-g class=md-nav__link> Winning: get to grid 15, G </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#non-deterministic-policy-environment class=md-nav__link> Non-deterministic Policy Environment </a> </li> <li class=md-nav__item> <a href=#custom-frozen-lake-non-deterministic-policy-environment class=md-nav__link> Custom Frozen Lake Non-deterministic Policy Environment </a> </li> <li class=md-nav__item> <a href=#policy-evaluation class=md-nav__link> Policy Evaluation </a> <nav class=md-nav aria-label="Policy Evaluation"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#transition-probability-function class=md-nav__link> Transition Probability Function </a> <nav class=md-nav aria-label="Transition Probability Function"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#deterministic-environment class=md-nav__link> Deterministic Environment </a> </li> <li class=md-nav__item> <a href=#stochastic-environment class=md-nav__link> Stochastic Environment </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#random-policy-function class=md-nav__link> Random Policy Function </a> </li> <li class=md-nav__item> <a href=#policy-evaluation-function-comprising-state-value-function class=md-nav__link> Policy Evaluation Function comprising State-value Function </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#policy-improvement class=md-nav__link> Policy Improvement </a> <nav class=md-nav aria-label="Policy Improvement"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#action-value-q-value-function-from-state-value-function class=md-nav__link> Action-value (Q-value) function from State-value function </a> </li> <li class=md-nav__item> <a href=#policy-improvement-function class=md-nav__link> Policy Improvement Function </a> </li> <li class=md-nav__item> <a href=#policy-iteration-function class=md-nav__link> Policy Iteration Function </a> </li> <li class=md-nav__item> <a href=#value-iteration class=md-nav__link> Value iteration </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content> <article class="md-content__inner md-typeset"> <h1>Introducao a funcao</h1> <div class="admonition tip"> <p class=admonition-title>Run Jupyter Notebook</p> <p>You can run the code for this section in this <a href=https://github.com/ritchieng/deep-learning-wizard/blob/master/docs/deep_learning/deep_reinforcement_learning_pytorch/dynamic_programming_frozenlake.ipynb>jupyter notebook link</a>.</p> </div> <ul> <li><a href=https://gym.openai.com/envs/FrozenLake-v0/ >Fronze Lake</a> is a simple game where you are on a frozen lake and you need to retrieve an item on the frozen lake where some parts are frozen and some parts are holes (if you walk into them you die)</li> <li>Actions: <span><span class=MathJax_Preview>\mathcal{A} = \{0, 1, 2, 3\}</span><script type=math/tex>\mathcal{A} = \{0, 1, 2, 3\}</script></span><ol> <li>LEFT: 0</li> <li>DOWN = 1</li> <li>RIGHT = 2</li> <li>UP = 3</li> </ol> </li> <li>Whole lake is a 4 x 4 grid world, <span><span class=MathJax_Preview>\mathcal{S} = \{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15\}</span><script type=math/tex>\mathcal{S} = \{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15\}</script></span><ul> <li><img alt src=./images/gridworld.png></li> </ul> </li> <li>On each grid, there are 4 possibilities<ul> <li>S: starting point, safe (code = 'SFFF')</li> <li>F: frozen surface, safe (code = 'FHFH')</li> <li>H: hole, fall to your doom (code = 'FFFH')</li> <li>G: goal, where the frisbee is located ('HFFG')</li> <li><img alt src=./images/gridworld_examples.png></li> </ul> </li> </ul> <h3 id=goal-of-frozen-lake>Goal of Frozen Lake<a class=headerlink href=#goal-of-frozen-lake title="Permanent link">&para;</a></h3> <p>The key here is we want to get to <strong>G</strong> without falling into the hole <strong>H</strong> in the shortest amount of time</p> <h3 id=why-dynamic-programming>Why Dynamic Programming?<a class=headerlink href=#why-dynamic-programming title="Permanent link">&para;</a></h3> <p>In this game, we know our transition probability function and reward function, essentially the whole environment, allowing us to turn this game into a simple planning problem via dynamic programming through 4 simple functions: (1) policy evaluation (2) policy improvement (3) policy iteration or (4) value iteration</p> <p>Before we explore how to solve this game, let's first understand how the game works in detail.</p> <h3 id=deterministic-policy-environment>Deterministic Policy Environment<a class=headerlink href=#deterministic-policy-environment title="Permanent link">&para;</a></h3> <div class="admonition note"> <p class=admonition-title>Make OpenAI Gym Environment for Frozen Lake</p> <div class=highlight><pre><span></span><code><span class=c1># Import gym, installable via `pip install gym`</span>
<span class=kn>import</span> <span class=nn>gym</span>

<span class=c1># Environment environment Slippery (stochastic policy, move left probability = 1/3) comes by default!</span>
<span class=c1># If we want deterministic policy, we need to create new environment</span>
<span class=c1># Make environment No Slippery (deterministic policy, move left = left)</span>

<span class=n>gym</span><span class=o>.</span><span class=n>envs</span><span class=o>.</span><span class=n>register</span><span class=p>(</span>
    <span class=nb>id</span><span class=o>=</span><span class=s1>&#39;FrozenLakeNotSlippery-v0&#39;</span><span class=p>,</span>
    <span class=n>entry_point</span><span class=o>=</span><span class=s1>&#39;gym.envs.toy_text:FrozenLakeEnv&#39;</span><span class=p>,</span>
    <span class=n>kwargs</span><span class=o>=</span><span class=p>{</span><span class=s1>&#39;map_name&#39;</span> <span class=p>:</span> <span class=s1>&#39;4x4&#39;</span><span class=p>,</span> <span class=s1>&#39;is_slippery&#39;</span><span class=p>:</span> <span class=kc>False</span><span class=p>},</span>
    <span class=n>max_episode_steps</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>
    <span class=n>reward_threshold</span><span class=o>=</span><span class=mf>0.78</span><span class=p>,</span> <span class=c1># optimum = .8196</span>
<span class=p>)</span>

<span class=c1># You can only register once</span>
<span class=c1># To delete any new environment</span>
<span class=c1># del gym.envs.registry.env_specs[&#39;FrozenLakeNotSlippery-v0&#39;]</span>

<span class=c1># Make the environment based on deterministic policy</span>
<span class=n>env</span> <span class=o>=</span> <span class=n>gym</span><span class=o>.</span><span class=n>make</span><span class=p>(</span><span class=s1>&#39;FrozenLakeNotSlippery-v0&#39;</span><span class=p>)</span>
</code></pre></div> </div> <div class="admonition note"> <p class=admonition-title>Observation space</p> <div class=highlight><pre><span></span><code><span class=c1># State space</span>
<span class=nb>print</span><span class=p>(</span><span class=n>env</span><span class=o>.</span><span class=n>observation_space</span><span class=p>)</span>
</code></pre></div> </div> <div class=highlight><pre><span></span><code>Discrete(16)
</code></pre></div> <div class="admonition note"> <p class=admonition-title>State space</p> <div class=highlight><pre><span></span><code><span class=n>S_n</span> <span class=o>=</span> <span class=n>env</span><span class=o>.</span><span class=n>observation_space</span><span class=o>.</span><span class=n>n</span>
<span class=nb>print</span><span class=p>(</span><span class=n>S_n</span><span class=p>)</span>
</code></pre></div> </div> <div class=highlight><pre><span></span><code>16
</code></pre></div> <div class="admonition note"> <p class=admonition-title>Sampling state space</p> <div class=highlight><pre><span></span><code><span class=c1># We should expect to see 15 possible grids from 0 to 15 when</span>
<span class=c1># we uniformly randomly sample from our observation space</span>
<span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10</span><span class=p>):</span>
    <span class=nb>print</span><span class=p>(</span><span class=n>env</span><span class=o>.</span><span class=n>observation_space</span><span class=o>.</span><span class=n>sample</span><span class=p>())</span>
</code></pre></div> </div> <div class=highlight><pre><span></span><code>11
12
7
13
7
11
14
14
4
12
</code></pre></div> <div class="admonition note"> <p class=admonition-title>Action space</p> <div class=highlight><pre><span></span><code><span class=c1># Action space</span>
<span class=nb>print</span><span class=p>(</span><span class=n>env</span><span class=o>.</span><span class=n>action_space</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>A_n</span> <span class=o>=</span> <span class=n>env</span><span class=o>.</span><span class=n>action_space</span><span class=o>.</span><span class=n>n</span>
<span class=nb>print</span><span class=p>(</span><span class=n>A_n</span><span class=p>)</span>
</code></pre></div> </div> <div class=highlight><pre><span></span><code>Discrete(4)

4
</code></pre></div> <div class="admonition note"> <p class=admonition-title>Random sampling of actions</p> <div class=highlight><pre><span></span><code><span class=c1># We should expect to see 4 actions when</span>
<span class=c1># we uniformly randomly sample:</span>
<span class=c1>#     1. LEFT: 0</span>
<span class=c1>#     2. DOWN = 1</span>
<span class=c1>#     3. RIGHT = 2</span>
<span class=c1>#     4. UP = 3</span>
<span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10</span><span class=p>):</span>
    <span class=nb>print</span><span class=p>(</span><span class=n>env</span><span class=o>.</span><span class=n>action_space</span><span class=o>.</span><span class=n>sample</span><span class=p>())</span>
</code></pre></div> </div> <div class=highlight><pre><span></span><code>0
3
1
3
3
2
3
2
2
2
</code></pre></div> <h4 id=making-steps>Making Steps<a class=headerlink href=#making-steps title="Permanent link">&para;</a></h4> <div class="admonition note"> <p class=admonition-title>Initial state</p> <div class=highlight><pre><span></span><code><span class=c1># This sets the initial state at S, our starting point</span>
<span class=c1># We can render the environment to see where we are on the 4x4 frozenlake gridworld</span>
<span class=n>env</span><span class=o>.</span><span class=n>reset</span><span class=p>()</span>
<span class=n>env</span><span class=o>.</span><span class=n>render</span><span class=p>()</span>
</code></pre></div> </div> <div class=highlight><pre><span></span><code>[S]FFF
FHFH
FFFH
HFFG
</code></pre></div> <div class="admonition note"> <p class=admonition-title>Go left</p> <div class=highlight><pre><span></span><code><span class=c1># Go left (action=0), nothing should happen, and we should stay at the starting point, because there&#39;s no grid on the left</span>
<span class=n>env</span><span class=o>.</span><span class=n>reset</span><span class=p>()</span>
<span class=n>action</span> <span class=o>=</span> <span class=mi>0</span>
<span class=p>(</span><span class=n>observation</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span><span class=p>,</span> <span class=n>prob</span><span class=p>)</span> <span class=o>=</span> <span class=n>env</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>action</span><span class=p>)</span>
<span class=n>env</span><span class=o>.</span><span class=n>render</span><span class=p>()</span>

<span class=c1># Observation = 1: move to grid number 1 (unchanged)</span>
<span class=c1># Prob = 1: deterministic policy, if we choose to go left, we&#39;ll go left</span>
<span class=nb>print</span><span class=p>(</span><span class=n>observation</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span><span class=p>,</span> <span class=n>prob</span><span class=p>)</span>
</code></pre></div> </div> <div class=highlight><pre><span></span><code>(Left)
[S]FFF
FHFH
FFFH
HFFG

0 0.0 False {&#39;prob&#39;: 1.0}
</code></pre></div> <div class="admonition note"> <p class=admonition-title>Go down</p> <div class=highlight><pre><span></span><code><span class=c1># Go down (action = 1), we should be safe as we step on frozen grid</span>
<span class=n>env</span><span class=o>.</span><span class=n>reset</span><span class=p>()</span>
<span class=n>action</span> <span class=o>=</span> <span class=mi>1</span>
<span class=p>(</span><span class=n>observation</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span><span class=p>,</span> <span class=n>prob</span><span class=p>)</span> <span class=o>=</span> <span class=n>env</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>action</span><span class=p>)</span>
<span class=n>env</span><span class=o>.</span><span class=n>render</span><span class=p>()</span>

<span class=c1># Observation = 4: move to grid number 4</span>
<span class=c1># Prob = 1: deterministic policy, if we choose to go down we&#39;ll go down</span>
<span class=nb>print</span><span class=p>(</span><span class=n>observation</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span><span class=p>,</span> <span class=n>prob</span><span class=p>)</span>
</code></pre></div> </div> <div class=highlight><pre><span></span><code>(Down)
SFFF
[F]HFH
FFFH
HFFG

4 0.0 False {&#39;prob&#39;: 1.0}
</code></pre></div> <div class="admonition note"> <p class=admonition-title>Go right</p> <div class=highlight><pre><span></span><code><span class=c1># Go right (action = 2), we should be safe as we step on frozen grid</span>
<span class=n>env</span><span class=o>.</span><span class=n>reset</span><span class=p>()</span>
<span class=n>action</span> <span class=o>=</span> <span class=mi>2</span>
<span class=p>(</span><span class=n>observation</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span><span class=p>,</span> <span class=n>prob</span><span class=p>)</span> <span class=o>=</span> <span class=n>env</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>action</span><span class=p>)</span>
<span class=n>env</span><span class=o>.</span><span class=n>render</span><span class=p>()</span>

<span class=c1># Observation = 1: move to grid number 1</span>
<span class=c1># Prob = 1: deterministic policy, if we choose to go right we&#39;ll go right</span>
<span class=nb>print</span><span class=p>(</span><span class=n>observation</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span><span class=p>,</span> <span class=n>prob</span><span class=p>)</span>
</code></pre></div> </div> <div class=highlight><pre><span></span><code>(Right)
S[F]FF
FHFH
FFFH
HFFG

1 0.0 False {&#39;prob&#39;: 1.0}
</code></pre></div> <div class="admonition note"> <p class=admonition-title>Go right twice</p> <div class=highlight><pre><span></span><code><span class=c1># Go right twice (action = 2), we should be safe as we step on 2 frozen grids</span>
<span class=n>env</span><span class=o>.</span><span class=n>reset</span><span class=p>()</span>
<span class=n>action</span> <span class=o>=</span> <span class=mi>2</span>
<span class=p>(</span><span class=n>observation</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span><span class=p>,</span> <span class=n>prob</span><span class=p>)</span> <span class=o>=</span> <span class=n>env</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>action</span><span class=p>)</span>
<span class=n>env</span><span class=o>.</span><span class=n>render</span><span class=p>()</span>
<span class=p>(</span><span class=n>observation</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span><span class=p>,</span> <span class=n>prob</span><span class=p>)</span> <span class=o>=</span> <span class=n>env</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>action</span><span class=p>)</span>
<span class=n>env</span><span class=o>.</span><span class=n>render</span><span class=p>()</span>

<span class=c1># Observation = 2: move to the right twice from grid 0 to grid 2</span>
<span class=c1># Prob = 1: deterministic policy, if we choose to go right twice we&#39;ll go right twice</span>
<span class=nb>print</span><span class=p>(</span><span class=n>observation</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span><span class=p>,</span> <span class=n>prob</span><span class=p>)</span>
</code></pre></div> </div> <div class=highlight><pre><span></span><code>(Right)
S[F]FF
FHFH
FFFH
HFFG

(Right)
SF[F]F
FHFH
FFFH
HFFG

2 0.0 False {&#39;prob&#39;: 1.0}
</code></pre></div> <h4 id=dying-drop-in-hole-grid-12-h>Dying: drop in hole grid 12, H<a class=headerlink href=#dying-drop-in-hole-grid-12-h title="Permanent link">&para;</a></h4> <div class="admonition note"> <p class=admonition-title>Go down thrice</p> <div class=highlight><pre><span></span><code><span class=c1># Go down thrice (action = 1), we will die as we step onto the grid with a hole</span>
<span class=n>env</span><span class=o>.</span><span class=n>reset</span><span class=p>()</span>
<span class=n>action</span> <span class=o>=</span> <span class=mi>1</span>
<span class=p>(</span><span class=n>observation</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span><span class=p>,</span> <span class=n>prob</span><span class=p>)</span> <span class=o>=</span> <span class=n>env</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>action</span><span class=p>)</span>
<span class=n>env</span><span class=o>.</span><span class=n>render</span><span class=p>()</span>
<span class=p>(</span><span class=n>observation</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span><span class=p>,</span> <span class=n>prob</span><span class=p>)</span> <span class=o>=</span> <span class=n>env</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>action</span><span class=p>)</span>
<span class=n>env</span><span class=o>.</span><span class=n>render</span><span class=p>()</span>
<span class=p>(</span><span class=n>observation</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span><span class=p>,</span> <span class=n>prob</span><span class=p>)</span> <span class=o>=</span> <span class=n>env</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>action</span><span class=p>)</span>
<span class=n>env</span><span class=o>.</span><span class=n>render</span><span class=p>()</span>

<span class=c1># Observation = 2: move to the right twice from grid 0 to grid 2</span>
<span class=c1># Prob = 1: deterministic policy, if we choose to go right twice we&#39;ll go right twice</span>
<span class=c1># Done = True because the game ends when we die (go onto hole grid (H) or finish the game (G))</span>
<span class=nb>print</span><span class=p>(</span><span class=n>observation</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span><span class=p>,</span> <span class=n>prob</span><span class=p>)</span>
</code></pre></div> </div> <div class=highlight><pre><span></span><code>(Down)
SFFF
[F]HFH
FFFH
HFFG

(Down)
SFFF
FHFH
[F]FFH
HFFG

(Down)
SFFF
FHFH
FFFH
[H]FFG

12 0.0 True {&#39;prob&#39;: 1.0}
</code></pre></div> <h4 id=winning-get-to-grid-15-g>Winning: get to grid 15, G<a class=headerlink href=#winning-get-to-grid-15-g title="Permanent link">&para;</a></h4> <div class="admonition note"> <p class=admonition-title>Go right twice, go down thrice, go right once</p> <div class=highlight><pre><span></span><code><span class=c1># Go right twice (action = 2), go down thrice (action = 1), go right once (action = 2)</span>
<span class=n>env</span><span class=o>.</span><span class=n>reset</span><span class=p>()</span>

<span class=c1># Right Twice</span>
<span class=n>action</span> <span class=o>=</span> <span class=mi>2</span>
<span class=p>(</span><span class=n>observation</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span><span class=p>,</span> <span class=n>prob</span><span class=p>)</span> <span class=o>=</span> <span class=n>env</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>action</span><span class=p>)</span>
<span class=n>env</span><span class=o>.</span><span class=n>render</span><span class=p>()</span>
<span class=p>(</span><span class=n>observation</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span><span class=p>,</span> <span class=n>prob</span><span class=p>)</span> <span class=o>=</span> <span class=n>env</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>action</span><span class=p>)</span>
<span class=n>env</span><span class=o>.</span><span class=n>render</span><span class=p>()</span>

<span class=c1># Down Thrice</span>
<span class=n>action</span> <span class=o>=</span> <span class=mi>1</span>
<span class=p>(</span><span class=n>observation</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span><span class=p>,</span> <span class=n>prob</span><span class=p>)</span> <span class=o>=</span> <span class=n>env</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>action</span><span class=p>)</span>
<span class=n>env</span><span class=o>.</span><span class=n>render</span><span class=p>()</span>
<span class=p>(</span><span class=n>observation</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span><span class=p>,</span> <span class=n>prob</span><span class=p>)</span> <span class=o>=</span> <span class=n>env</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>action</span><span class=p>)</span>
<span class=n>env</span><span class=o>.</span><span class=n>render</span><span class=p>()</span>
<span class=p>(</span><span class=n>observation</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span><span class=p>,</span> <span class=n>prob</span><span class=p>)</span> <span class=o>=</span> <span class=n>env</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>action</span><span class=p>)</span>
<span class=n>env</span><span class=o>.</span><span class=n>render</span><span class=p>()</span>

<span class=c1># Right Once</span>
<span class=n>action</span> <span class=o>=</span> <span class=mi>2</span>
<span class=p>(</span><span class=n>observation</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span><span class=p>,</span> <span class=n>prob</span><span class=p>)</span> <span class=o>=</span> <span class=n>env</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>action</span><span class=p>)</span>
<span class=n>env</span><span class=o>.</span><span class=n>render</span><span class=p>()</span>

<span class=c1># Observation = 2: move to the right twice from grid 0 to grid 2</span>
<span class=c1># Prob = 1: deterministic policy, if we choose to go right twice we&#39;ll go right twice</span>
<span class=c1># Done = True because the game ends when we die (go onto hole grid (H) or finish the game (G))</span>
<span class=nb>print</span><span class=p>(</span><span class=n>observation</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span><span class=p>,</span> <span class=n>prob</span><span class=p>)</span>
</code></pre></div> </div> <div class=highlight><pre><span></span><code>(Right)
S[F]FF
FHFH
FFFH
HFFG

(Right)
SF[F]F
FHFH
FFFH
HFFG

(Down)
SFFF
FH[F]H
FFFH
HFFG

(Down)
SFFF
FHFH
FF[F]H
HFFG

(Down)
SFFF
FHFH
FFFH
HF[F]mG

(Right)
SFFF
FHFH
FFFH
HFF[G]

15 1.0 True {&#39;prob&#39;: 1.0}
</code></pre></div> <h3 id=non-deterministic-policy-environment>Non-deterministic Policy Environment<a class=headerlink href=#non-deterministic-policy-environment title="Permanent link">&para;</a></h3> <div class="admonition note"> <p class=admonition-title>Go right?</p> <div class=highlight><pre><span></span><code><span class=c1># Make the environment based on non-deterministic policy</span>
<span class=n>env</span> <span class=o>=</span> <span class=n>gym</span><span class=o>.</span><span class=n>make</span><span class=p>(</span><span class=s1>&#39;FrozenLake-v0&#39;</span><span class=p>)</span>

<span class=c1># Go right once (action = 2), we should go to the right but we did not!</span>
<span class=n>env</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>8</span><span class=p>)</span>
<span class=n>env</span><span class=o>.</span><span class=n>reset</span><span class=p>()</span>
<span class=n>action</span> <span class=o>=</span> <span class=mi>2</span>
<span class=p>(</span><span class=n>observation</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span><span class=p>,</span> <span class=n>prob</span><span class=p>)</span> <span class=o>=</span> <span class=n>env</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>action</span><span class=p>)</span>
<span class=n>env</span><span class=o>.</span><span class=n>render</span><span class=p>()</span>

<span class=c1># Observation = 0: move to the right once from grid 0 to grid 1</span>
<span class=c1># Prob = 1/3: non-deterministic policy, if we choose to go right, there&#39;s only a 1/3 probability we would go to the right and with this environment seed we did not</span>
<span class=nb>print</span><span class=p>(</span><span class=n>observation</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span><span class=p>,</span> <span class=n>prob</span><span class=p>)</span>
</code></pre></div> </div> <div class=highlight><pre><span></span><code>(Right)
[S]FFF
FHFH
FFFH
HFFG

0 0.0 False {&#39;prob&#39;: 0.3333333333333333}
</code></pre></div> <div class="admonition note"> <p class=admonition-title>Go right 10 times?</p> <div class=highlight><pre><span></span><code><span class=c1># Try to go to the right 10 times, let&#39;s see how many times it goes to the right, by right we won&#39;t die because we would end up at the extreme right of grid 3</span>
<span class=c1># See how it can go down/left/up/nothing instead of just right? </span>
<span class=c1># Intuitively when we are moving on a frozen lake, some times when we want to walk one direction we may end up in another direction as it&#39;s slippery</span>
<span class=c1># Setting seed here of the environment so you can reproduce my results, otherwise stochastic policy will yield different results for each run</span>
<span class=n>env</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>8</span><span class=p>)</span>
<span class=n>env</span><span class=o>.</span><span class=n>reset</span><span class=p>()</span>
<span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10</span><span class=p>):</span>
    <span class=n>action</span> <span class=o>=</span> <span class=mi>2</span>
    <span class=p>(</span><span class=n>observation</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span><span class=p>,</span> <span class=n>prob</span><span class=p>)</span> <span class=o>=</span> <span class=n>env</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>action</span><span class=p>)</span>
    <span class=n>env</span><span class=o>.</span><span class=n>render</span><span class=p>()</span>
</code></pre></div> <div class=codehilite><pre><span></span><code>(Right)
[S]FFF
FHFH
FFFH
HFFG

(Right)
S[F]FF
FHFH
FFFH
HFFG

(Right)
SF[F]F
FHFH
FFFH
HFFG

(Right)
SFFF
FH[F]H
FFFH
HFFG

(Right)
SFFF
FHF[H]
FFFH
HFFG

(Right)
SFFF
FHF[4H]
FFFH
HFFG

(Right)
SFFF
FHF[H]
FFFH
HFFG

(Right)
SFFF
FHF[H]
FFFH
HFFG

(Right)
SFFF
FHF[H]
FFFH
HFFG

(Right)
SFFF
FHF[H]
FFFH
HFFG
</code></pre></div> </div> <h3 id=custom-frozen-lake-non-deterministic-policy-environment>Custom Frozen Lake Non-deterministic Policy Environment<a class=headerlink href=#custom-frozen-lake-non-deterministic-policy-environment title="Permanent link">&para;</a></h3> <ul> <li>Because original code from <a href=https://github.com/openai/gym/blob/master/gym/envs/toy_text/frozen_lake.py>OpenAI</a> only allows us to run <code>env.step(action)</code>, this is challenging if we want to do some visualization of our state-value and action-value (q-value) functions for learning</li> <li>Hence, we'll be copying the whole code from <a href=https://github.com/openai/gym/blob/master/gym/envs/toy_text/frozen_lake.py>OpenAI Frozen Lake implementation</a> and adding just one line to make sure we can get P via <code>self.P = P</code></li> <li>This code is not important, you can just copy it</li> </ul> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>sys</span>
<span class=kn>from</span> <span class=nn>contextlib</span> <span class=kn>import</span> <span class=n>closing</span>

<span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
<span class=kn>from</span> <span class=nn>six</span> <span class=kn>import</span> <span class=n>StringIO</span><span class=p>,</span> <span class=n>b</span>

<span class=kn>from</span> <span class=nn>gym</span> <span class=kn>import</span> <span class=n>utils</span>
<span class=kn>from</span> <span class=nn>gym.envs.toy_text</span> <span class=kn>import</span> <span class=n>discrete</span>

<span class=n>LEFT</span> <span class=o>=</span> <span class=mi>0</span>
<span class=n>DOWN</span> <span class=o>=</span> <span class=mi>1</span>
<span class=n>RIGHT</span> <span class=o>=</span> <span class=mi>2</span>
<span class=n>UP</span> <span class=o>=</span> <span class=mi>3</span>

<span class=n>MAPS</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s2>&quot;4x4&quot;</span><span class=p>:</span> <span class=p>[</span>
        <span class=s2>&quot;SFFF&quot;</span><span class=p>,</span>
        <span class=s2>&quot;FHFH&quot;</span><span class=p>,</span>
        <span class=s2>&quot;FFFH&quot;</span><span class=p>,</span>
        <span class=s2>&quot;HFFG&quot;</span>
    <span class=p>],</span>
    <span class=s2>&quot;8x8&quot;</span><span class=p>:</span> <span class=p>[</span>
        <span class=s2>&quot;SFFFFFFF&quot;</span><span class=p>,</span>
        <span class=s2>&quot;FFFFFFFF&quot;</span><span class=p>,</span>
        <span class=s2>&quot;FFFHFFFF&quot;</span><span class=p>,</span>
        <span class=s2>&quot;FFFFFHFF&quot;</span><span class=p>,</span>
        <span class=s2>&quot;FFFHFFFF&quot;</span><span class=p>,</span>
        <span class=s2>&quot;FHHFFFHF&quot;</span><span class=p>,</span>
        <span class=s2>&quot;FHFFHFHF&quot;</span><span class=p>,</span>
        <span class=s2>&quot;FFFHFFFG&quot;</span>
    <span class=p>],</span>
<span class=p>}</span>

<span class=c1># Generates a random valid map (one that has a path from start to goal)</span>
<span class=c1># @params size, size of each side of the grid</span>
<span class=c1># @prams p, probability that a tile is frozen</span>
<span class=k>def</span> <span class=nf>generate_random_map</span><span class=p>(</span><span class=n>size</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span> <span class=n>p</span><span class=o>=</span><span class=mf>0.8</span><span class=p>):</span>
    <span class=n>valid</span> <span class=o>=</span> <span class=kc>False</span>

    <span class=c1>#BFS to check that it&#39;s a valid path</span>
    <span class=k>def</span> <span class=nf>is_valid</span><span class=p>(</span><span class=n>arr</span><span class=p>,</span> <span class=n>r</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>c</span><span class=o>=</span><span class=mi>0</span><span class=p>):</span>
        <span class=k>if</span> <span class=n>arr</span><span class=p>[</span><span class=n>r</span><span class=p>][</span><span class=n>c</span><span class=p>]</span> <span class=o>==</span> <span class=s1>&#39;G&#39;</span><span class=p>:</span>
            <span class=k>return</span> <span class=kc>True</span>

        <span class=n>tmp</span> <span class=o>=</span> <span class=n>arr</span><span class=p>[</span><span class=n>r</span><span class=p>][</span><span class=n>c</span><span class=p>]</span>
        <span class=n>arr</span><span class=p>[</span><span class=n>r</span><span class=p>][</span><span class=n>c</span><span class=p>]</span> <span class=o>=</span> <span class=s2>&quot;#&quot;</span>

        <span class=k>if</span> <span class=n>r</span><span class=o>+</span><span class=mi>1</span> <span class=o>&lt;</span> <span class=n>size</span> <span class=ow>and</span> <span class=n>arr</span><span class=p>[</span><span class=n>r</span><span class=o>+</span><span class=mi>1</span><span class=p>][</span><span class=n>c</span><span class=p>]</span> <span class=ow>not</span> <span class=ow>in</span> <span class=s1>&#39;#H&#39;</span><span class=p>:</span>
            <span class=k>if</span> <span class=n>is_valid</span><span class=p>(</span><span class=n>arr</span><span class=p>,</span> <span class=n>r</span><span class=o>+</span><span class=mi>1</span><span class=p>,</span> <span class=n>c</span><span class=p>)</span> <span class=o>==</span> <span class=kc>True</span><span class=p>:</span>
                <span class=n>arr</span><span class=p>[</span><span class=n>r</span><span class=p>][</span><span class=n>c</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp</span>
                <span class=k>return</span> <span class=kc>True</span>

        <span class=k>if</span> <span class=n>c</span><span class=o>+</span><span class=mi>1</span> <span class=o>&lt;</span> <span class=n>size</span> <span class=ow>and</span> <span class=n>arr</span><span class=p>[</span><span class=n>r</span><span class=p>][</span><span class=n>c</span><span class=o>+</span><span class=mi>1</span><span class=p>]</span> <span class=ow>not</span> <span class=ow>in</span> <span class=s1>&#39;#H&#39;</span><span class=p>:</span>
            <span class=k>if</span> <span class=n>is_valid</span><span class=p>(</span><span class=n>arr</span><span class=p>,</span> <span class=n>r</span><span class=p>,</span> <span class=n>c</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span> <span class=o>==</span> <span class=kc>True</span><span class=p>:</span>
                <span class=n>arr</span><span class=p>[</span><span class=n>r</span><span class=p>][</span><span class=n>c</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp</span>
                <span class=k>return</span> <span class=kc>True</span>

        <span class=k>if</span> <span class=n>r</span><span class=o>-</span><span class=mi>1</span> <span class=o>&gt;=</span> <span class=mi>0</span> <span class=ow>and</span> <span class=n>arr</span><span class=p>[</span><span class=n>r</span><span class=o>-</span><span class=mi>1</span><span class=p>][</span><span class=n>c</span><span class=p>]</span> <span class=ow>not</span> <span class=ow>in</span> <span class=s1>&#39;#H&#39;</span><span class=p>:</span>
            <span class=k>if</span> <span class=n>is_valid</span><span class=p>(</span><span class=n>arr</span><span class=p>,</span> <span class=n>r</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>c</span><span class=p>)</span> <span class=o>==</span> <span class=kc>True</span><span class=p>:</span>
                <span class=n>arr</span><span class=p>[</span><span class=n>r</span><span class=p>][</span><span class=n>c</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp</span>
                <span class=k>return</span> <span class=kc>True</span>

        <span class=k>if</span> <span class=n>c</span><span class=o>-</span><span class=mi>1</span> <span class=o>&gt;=</span> <span class=mi>0</span> <span class=ow>and</span> <span class=n>arr</span><span class=p>[</span><span class=n>r</span><span class=p>][</span><span class=n>c</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=ow>not</span> <span class=ow>in</span> <span class=s1>&#39;#H&#39;</span><span class=p>:</span>
            <span class=k>if</span> <span class=n>is_valid</span><span class=p>(</span><span class=n>arr</span><span class=p>,</span><span class=n>r</span><span class=p>,</span> <span class=n>c</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span> <span class=o>==</span> <span class=kc>True</span><span class=p>:</span>
                <span class=n>arr</span><span class=p>[</span><span class=n>r</span><span class=p>][</span><span class=n>c</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp</span>
                <span class=k>return</span> <span class=kc>True</span>
        <span class=n>arr</span><span class=p>[</span><span class=n>r</span><span class=p>][</span><span class=n>c</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp</span>
        <span class=k>return</span> <span class=kc>False</span>

    <span class=k>while</span> <span class=ow>not</span> <span class=n>valid</span><span class=p>:</span>
        <span class=n>p</span> <span class=o>=</span> <span class=nb>min</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>p</span><span class=p>)</span>
        <span class=n>res</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>([</span><span class=s1>&#39;F&#39;</span><span class=p>,</span><span class=s1>&#39;H&#39;</span><span class=p>],</span> <span class=p>(</span><span class=n>size</span><span class=p>,</span> <span class=n>size</span><span class=p>),</span> <span class=n>p</span><span class=o>=</span><span class=p>[</span><span class=n>p</span><span class=p>,</span> <span class=mi>1</span><span class=o>-</span><span class=n>p</span><span class=p>])</span>
        <span class=n>res</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=s1>&#39;S&#39;</span>
        <span class=n>res</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>][</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>=</span> <span class=s1>&#39;G&#39;</span>
        <span class=n>valid</span> <span class=o>=</span> <span class=n>is_valid</span><span class=p>(</span><span class=n>res</span><span class=p>)</span>
    <span class=k>return</span> <span class=p>[</span><span class=s2>&quot;&quot;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>res</span><span class=p>]</span>


<span class=k>class</span> <span class=nc>FrozenLakeEnv</span><span class=p>(</span><span class=n>discrete</span><span class=o>.</span><span class=n>DiscreteEnv</span><span class=p>):</span>
    <span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Winter is here. You and your friends were tossing around a frisbee at the park</span>
<span class=sd>    when you made a wild throw that left the frisbee out in the middle of the lake.</span>
<span class=sd>    The water is mostly frozen, but there are a few holes where the ice has melted.</span>
<span class=sd>    If you step into one of those holes, you&#39;ll fall into the freezing water.</span>
<span class=sd>    At this time, there&#39;s an international frisbee shortage, so it&#39;s absolutely imperative that</span>
<span class=sd>    you navigate across the lake and retrieve the disc.</span>
<span class=sd>    However, the ice is slippery, so you won&#39;t always move in the direction you intend.</span>
<span class=sd>    The surface is described using a grid like the following</span>
<span class=sd>        SFFF</span>
<span class=sd>        FHFH</span>
<span class=sd>        FFFH</span>
<span class=sd>        HFFG</span>
<span class=sd>    S : starting point, safe</span>
<span class=sd>    F : frozen surface, safe</span>
<span class=sd>    H : hole, fall to your doom</span>
<span class=sd>    G : goal, where the frisbee is located</span>
<span class=sd>    The episode ends when you reach the goal or fall in a hole.</span>
<span class=sd>    You receive a reward of 1 if you reach the goal, and zero otherwise.</span>
<span class=sd>    &quot;&quot;&quot;</span>

    <span class=n>metadata</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;render.modes&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;human&#39;</span><span class=p>,</span> <span class=s1>&#39;ansi&#39;</span><span class=p>]}</span>

    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>desc</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>map_name</span><span class=o>=</span><span class=s2>&quot;4x4&quot;</span><span class=p>,</span><span class=n>is_slippery</span><span class=o>=</span><span class=kc>True</span><span class=p>):</span>
        <span class=k>if</span> <span class=n>desc</span> <span class=ow>is</span> <span class=kc>None</span> <span class=ow>and</span> <span class=n>map_name</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
            <span class=n>desc</span> <span class=o>=</span> <span class=n>generate_random_map</span><span class=p>()</span>
        <span class=k>elif</span> <span class=n>desc</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
            <span class=n>desc</span> <span class=o>=</span> <span class=n>MAPS</span><span class=p>[</span><span class=n>map_name</span><span class=p>]</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>desc</span> <span class=o>=</span> <span class=n>desc</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>asarray</span><span class=p>(</span><span class=n>desc</span><span class=p>,</span><span class=n>dtype</span><span class=o>=</span><span class=s1>&#39;c&#39;</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>nrow</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>ncol</span> <span class=o>=</span> <span class=n>nrow</span><span class=p>,</span> <span class=n>ncol</span> <span class=o>=</span> <span class=n>desc</span><span class=o>.</span><span class=n>shape</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>reward_range</span> <span class=o>=</span> <span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

        <span class=n>nA</span> <span class=o>=</span> <span class=mi>4</span>
        <span class=n>nS</span> <span class=o>=</span> <span class=n>nrow</span> <span class=o>*</span> <span class=n>ncol</span>

        <span class=n>isd</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>desc</span> <span class=o>==</span> <span class=sa>b</span><span class=s1>&#39;S&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=s1>&#39;float64&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>ravel</span><span class=p>()</span>
        <span class=n>isd</span> <span class=o>/=</span> <span class=n>isd</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

        <span class=n>P</span> <span class=o>=</span> <span class=p>{</span><span class=n>s</span> <span class=p>:</span> <span class=p>{</span><span class=n>a</span> <span class=p>:</span> <span class=p>[]</span> <span class=k>for</span> <span class=n>a</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>nA</span><span class=p>)}</span> <span class=k>for</span> <span class=n>s</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>nS</span><span class=p>)}</span>

        <span class=k>def</span> <span class=nf>to_s</span><span class=p>(</span><span class=n>row</span><span class=p>,</span> <span class=n>col</span><span class=p>):</span>
            <span class=k>return</span> <span class=n>row</span><span class=o>*</span><span class=n>ncol</span> <span class=o>+</span> <span class=n>col</span>

        <span class=k>def</span> <span class=nf>inc</span><span class=p>(</span><span class=n>row</span><span class=p>,</span> <span class=n>col</span><span class=p>,</span> <span class=n>a</span><span class=p>):</span>
            <span class=k>if</span> <span class=n>a</span><span class=o>==</span><span class=mi>0</span><span class=p>:</span> <span class=c1># left</span>
                <span class=n>col</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=n>col</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span><span class=mi>0</span><span class=p>)</span>
            <span class=k>elif</span> <span class=n>a</span><span class=o>==</span><span class=mi>1</span><span class=p>:</span> <span class=c1># down</span>
                <span class=n>row</span> <span class=o>=</span> <span class=nb>min</span><span class=p>(</span><span class=n>row</span><span class=o>+</span><span class=mi>1</span><span class=p>,</span><span class=n>nrow</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span>
            <span class=k>elif</span> <span class=n>a</span><span class=o>==</span><span class=mi>2</span><span class=p>:</span> <span class=c1># right</span>
                <span class=n>col</span> <span class=o>=</span> <span class=nb>min</span><span class=p>(</span><span class=n>col</span><span class=o>+</span><span class=mi>1</span><span class=p>,</span><span class=n>ncol</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span>
            <span class=k>elif</span> <span class=n>a</span><span class=o>==</span><span class=mi>3</span><span class=p>:</span> <span class=c1># up</span>
                <span class=n>row</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=n>row</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span><span class=mi>0</span><span class=p>)</span>
            <span class=k>return</span> <span class=p>(</span><span class=n>row</span><span class=p>,</span> <span class=n>col</span><span class=p>)</span>

        <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>nrow</span><span class=p>):</span>
            <span class=k>for</span> <span class=n>col</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>ncol</span><span class=p>):</span>
                <span class=n>s</span> <span class=o>=</span> <span class=n>to_s</span><span class=p>(</span><span class=n>row</span><span class=p>,</span> <span class=n>col</span><span class=p>)</span>
                <span class=k>for</span> <span class=n>a</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>4</span><span class=p>):</span>
                    <span class=n>li</span> <span class=o>=</span> <span class=n>P</span><span class=p>[</span><span class=n>s</span><span class=p>][</span><span class=n>a</span><span class=p>]</span>
                    <span class=n>letter</span> <span class=o>=</span> <span class=n>desc</span><span class=p>[</span><span class=n>row</span><span class=p>,</span> <span class=n>col</span><span class=p>]</span>
                    <span class=k>if</span> <span class=n>letter</span> <span class=ow>in</span> <span class=sa>b</span><span class=s1>&#39;GH&#39;</span><span class=p>:</span>
                        <span class=n>li</span><span class=o>.</span><span class=n>append</span><span class=p>((</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>s</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=kc>True</span><span class=p>))</span>
                    <span class=k>else</span><span class=p>:</span>
                        <span class=k>if</span> <span class=n>is_slippery</span><span class=p>:</span>
                            <span class=k>for</span> <span class=n>b</span> <span class=ow>in</span> <span class=p>[(</span><span class=n>a</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>%</span><span class=mi>4</span><span class=p>,</span> <span class=n>a</span><span class=p>,</span> <span class=p>(</span><span class=n>a</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span><span class=o>%</span><span class=mi>4</span><span class=p>]:</span>
                                <span class=n>newrow</span><span class=p>,</span> <span class=n>newcol</span> <span class=o>=</span> <span class=n>inc</span><span class=p>(</span><span class=n>row</span><span class=p>,</span> <span class=n>col</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span>
                                <span class=n>newstate</span> <span class=o>=</span> <span class=n>to_s</span><span class=p>(</span><span class=n>newrow</span><span class=p>,</span> <span class=n>newcol</span><span class=p>)</span>
                                <span class=n>newletter</span> <span class=o>=</span> <span class=n>desc</span><span class=p>[</span><span class=n>newrow</span><span class=p>,</span> <span class=n>newcol</span><span class=p>]</span>
                                <span class=n>done</span> <span class=o>=</span> <span class=nb>bytes</span><span class=p>(</span><span class=n>newletter</span><span class=p>)</span> <span class=ow>in</span> <span class=sa>b</span><span class=s1>&#39;GH&#39;</span>
                                <span class=n>rew</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=n>newletter</span> <span class=o>==</span> <span class=sa>b</span><span class=s1>&#39;G&#39;</span><span class=p>)</span>
                                <span class=n>li</span><span class=o>.</span><span class=n>append</span><span class=p>((</span><span class=mf>1.0</span><span class=o>/</span><span class=mf>3.0</span><span class=p>,</span> <span class=n>newstate</span><span class=p>,</span> <span class=n>rew</span><span class=p>,</span> <span class=n>done</span><span class=p>))</span>
                        <span class=k>else</span><span class=p>:</span>
                            <span class=n>newrow</span><span class=p>,</span> <span class=n>newcol</span> <span class=o>=</span> <span class=n>inc</span><span class=p>(</span><span class=n>row</span><span class=p>,</span> <span class=n>col</span><span class=p>,</span> <span class=n>a</span><span class=p>)</span>
                            <span class=n>newstate</span> <span class=o>=</span> <span class=n>to_s</span><span class=p>(</span><span class=n>newrow</span><span class=p>,</span> <span class=n>newcol</span><span class=p>)</span>
                            <span class=n>newletter</span> <span class=o>=</span> <span class=n>desc</span><span class=p>[</span><span class=n>newrow</span><span class=p>,</span> <span class=n>newcol</span><span class=p>]</span>
                            <span class=n>done</span> <span class=o>=</span> <span class=nb>bytes</span><span class=p>(</span><span class=n>newletter</span><span class=p>)</span> <span class=ow>in</span> <span class=sa>b</span><span class=s1>&#39;GH&#39;</span>
                            <span class=n>rew</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=n>newletter</span> <span class=o>==</span> <span class=sa>b</span><span class=s1>&#39;G&#39;</span><span class=p>)</span>
                            <span class=n>li</span><span class=o>.</span><span class=n>append</span><span class=p>((</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>newstate</span><span class=p>,</span> <span class=n>rew</span><span class=p>,</span> <span class=n>done</span><span class=p>))</span>

        <span class=c1># New change because environment only allows step without</span>
        <span class=c1># specific state for learning environment!</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>P</span> <span class=o>=</span> <span class=n>P</span>

        <span class=nb>super</span><span class=p>(</span><span class=n>FrozenLakeEnv</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=n>nS</span><span class=p>,</span> <span class=n>nA</span><span class=p>,</span> <span class=n>P</span><span class=p>,</span> <span class=n>isd</span><span class=p>)</span>

    <span class=k>def</span> <span class=nf>render</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>mode</span><span class=o>=</span><span class=s1>&#39;human&#39;</span><span class=p>):</span>
        <span class=n>outfile</span> <span class=o>=</span> <span class=n>StringIO</span><span class=p>()</span> <span class=k>if</span> <span class=n>mode</span> <span class=o>==</span> <span class=s1>&#39;ansi&#39;</span> <span class=k>else</span> <span class=n>sys</span><span class=o>.</span><span class=n>stdout</span>

        <span class=n>row</span><span class=p>,</span> <span class=n>col</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>s</span> <span class=o>//</span> <span class=bp>self</span><span class=o>.</span><span class=n>ncol</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>s</span> <span class=o>%</span> <span class=bp>self</span><span class=o>.</span><span class=n>ncol</span>
        <span class=n>desc</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>desc</span><span class=o>.</span><span class=n>tolist</span><span class=p>()</span>
        <span class=n>desc</span> <span class=o>=</span> <span class=p>[[</span><span class=n>c</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=s1>&#39;utf-8&#39;</span><span class=p>)</span> <span class=k>for</span> <span class=n>c</span> <span class=ow>in</span> <span class=n>line</span><span class=p>]</span> <span class=k>for</span> <span class=n>line</span> <span class=ow>in</span> <span class=n>desc</span><span class=p>]</span>
        <span class=n>desc</span><span class=p>[</span><span class=n>row</span><span class=p>][</span><span class=n>col</span><span class=p>]</span> <span class=o>=</span> <span class=n>utils</span><span class=o>.</span><span class=n>colorize</span><span class=p>(</span><span class=n>desc</span><span class=p>[</span><span class=n>row</span><span class=p>][</span><span class=n>col</span><span class=p>],</span> <span class=s2>&quot;red&quot;</span><span class=p>,</span> <span class=n>highlight</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>lastaction</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
            <span class=n>outfile</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=s2>&quot;  (</span><span class=si>{}</span><span class=s2>)</span><span class=se>\n</span><span class=s2>&quot;</span><span class=o>.</span><span class=n>format</span><span class=p>([</span><span class=s2>&quot;Left&quot;</span><span class=p>,</span><span class=s2>&quot;Down&quot;</span><span class=p>,</span><span class=s2>&quot;Right&quot;</span><span class=p>,</span><span class=s2>&quot;Up&quot;</span><span class=p>][</span><span class=bp>self</span><span class=o>.</span><span class=n>lastaction</span><span class=p>]))</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=n>outfile</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>&quot;</span><span class=p>)</span>
        <span class=n>outfile</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>&quot;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=s1>&#39;&#39;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>line</span><span class=p>)</span> <span class=k>for</span> <span class=n>line</span> <span class=ow>in</span> <span class=n>desc</span><span class=p>)</span><span class=o>+</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>&quot;</span><span class=p>)</span>

        <span class=k>if</span> <span class=n>mode</span> <span class=o>!=</span> <span class=s1>&#39;human&#39;</span><span class=p>:</span>
            <span class=k>with</span> <span class=n>closing</span><span class=p>(</span><span class=n>outfile</span><span class=p>):</span>
                <span class=k>return</span> <span class=n>outfile</span><span class=o>.</span><span class=n>getvalue</span><span class=p>()</span>
</code></pre></div> <h2 id=policy-evaluation>Policy Evaluation<a class=headerlink href=#policy-evaluation title="Permanent link">&para;</a></h2> <h3 id=transition-probability-function>Transition Probability Function<a class=headerlink href=#transition-probability-function title="Permanent link">&para;</a></h3> <ul> <li><span><span class=MathJax_Preview>\mathcal{P}_{ss'}^a = \mathcal{P}(s' \vert s, a) = \mathbb{P} [S_{t+1} = s' \vert S_t = s, A_t = a]</span><script type=math/tex>\mathcal{P}_{ss'}^a = \mathcal{P}(s' \vert s, a)  = \mathbb{P} [S_{t+1} = s' \vert S_t = s, A_t = a]</script></span></li> </ul> <h4 id=deterministic-environment>Deterministic Environment<a class=headerlink href=#deterministic-environment title="Permanent link">&para;</a></h4> <ul> <li>There's no probability distribution, if you decide to go left you'll go left</li> <li>Hence in this example, given <code>current_state = 8</code> and <code>action = 0</code> which is left, we will end up with <code>probability = 1</code> in <code>new_state = 9</code></li> </ul> <div class=highlight><pre><span></span><code><span class=c1># Deterministic</span>
<span class=n>env</span> <span class=o>=</span> <span class=n>FrozenLakeEnv</span><span class=p>(</span><span class=n>is_slippery</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>

<span class=n>current_state</span> <span class=o>=</span> <span class=mi>10</span>  <span class=c1># State from S_n=16 State space</span>
<span class=n>action</span> <span class=o>=</span> <span class=mi>0</span>  <span class=c1># Left action from A_n=4 Action space</span>
<span class=p>[(</span><span class=n>probability</span><span class=p>,</span> <span class=n>new_state</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span><span class=p>)]</span> <span class=o>=</span> <span class=n>env</span><span class=o>.</span><span class=n>P</span><span class=p>[</span><span class=n>current_state</span><span class=p>][</span><span class=n>action</span><span class=p>]</span>

<span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Probability </span><span class=si>{}</span><span class=s1>, New State </span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>probability</span><span class=p>,</span> <span class=n>new_state</span><span class=p>))</span>
</code></pre></div> <div class=codehilite><pre><span></span><code>Probability 1.0, New State 9
</code></pre></div> <h4 id=stochastic-environment>Stochastic Environment<a class=headerlink href=#stochastic-environment title="Permanent link">&para;</a></h4> <ul> <li>Given <span><span class=MathJax_Preview>S_t = 10, A_t = 0</span><script type=math/tex>S_t = 10, A_t = 0</script></span> in a stochastic environment, the transition probability functions indicate you can end up in grid 6, 9, 14 each with &#8531; probability:<ul> <li><span><span class=MathJax_Preview>\mathbb{P} [S_{t+1} = 6 \vert S_t = 10, A_t = 0] = \frac{1}{3}</span><script type=math/tex>\mathbb{P} [S_{t+1} = 6 \vert S_t = 10, A_t = 0] = \frac{1}{3}</script></span></li> <li><span><span class=MathJax_Preview>\mathbb{P} [S_{t+1} = 9 \vert S_t = 10, A_t = 0] = \frac{1}{3}</span><script type=math/tex>\mathbb{P} [S_{t+1} = 9 \vert S_t = 10, A_t = 0] = \frac{1}{3}</script></span></li> <li><span><span class=MathJax_Preview>\mathbb{P} [S_{t+1} = 14 \vert S_t = 10, A_t = 0] = \frac{1}{3}</span><script type=math/tex>\mathbb{P} [S_{t+1} = 14 \vert S_t = 10, A_t = 0] = \frac{1}{3}</script></span></li> </ul> </li> </ul> <div class=highlight><pre><span></span><code><span class=c1># Stochastic</span>
<span class=n>env</span> <span class=o>=</span> <span class=n>FrozenLakeEnv</span><span class=p>(</span><span class=n>is_slippery</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>current_state</span> <span class=o>=</span> <span class=mi>10</span>  <span class=c1># State from S_n=16 State space</span>
<span class=n>action</span> <span class=o>=</span> <span class=mi>0</span>  <span class=c1># Left action from A_n=4 Action space</span>
<span class=n>env</span><span class=o>.</span><span class=n>P</span><span class=p>[</span><span class=n>current_state</span><span class=p>][</span><span class=n>action</span><span class=p>]</span>
</code></pre></div> <div class=codehilite><pre><span></span><code>[(0.3333333333333333, 6, 0.0, False),
 (0.3333333333333333, 9, 0.0, False),
 (0.3333333333333333, 14, 0.0, False)]
</code></pre></div> <h3 id=random-policy-function>Random Policy Function<a class=headerlink href=#random-policy-function title="Permanent link">&para;</a></h3> <div class="admonition note"> <p class=admonition-title>Random Policy function</p> <div class=highlight><pre><span></span><code><span class=c1># Random policy generation</span>
<span class=k>def</span> <span class=nf>generate_random_policy</span><span class=p>(</span><span class=n>S_n</span><span class=p>,</span> <span class=n>A_n</span><span class=p>):</span>
    <span class=c1># return np.random.randint(A_n, size=(S_n, A_n))</span>
    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>ones</span><span class=p>([</span><span class=n>S_n</span><span class=p>,</span> <span class=n>A_n</span><span class=p>])</span> <span class=o>/</span> <span class=n>A_n</span>

<span class=c1># Given the total number of states S_n = 16</span>
<span class=c1># For each state out of 16 states, we can take 4 actions</span>
<span class=c1># Since this is a stochastic environment, we&#39;ll initialize a policy to have equal probabilities 0.25 of doing each action each state</span>
<span class=n>policy</span> <span class=o>=</span> <span class=n>generate_random_policy</span><span class=p>(</span><span class=n>S_n</span><span class=p>,</span> <span class=n>A_n</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>policy</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</code></pre></div> </div> <div class=highlight><pre><span></span><code>(16, 4)
</code></pre></div> <div class="admonition note"> <p class=admonition-title>Policy plot</p> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>seaborn</span> <span class=k>as</span> <span class=nn>sns</span>
<span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
<span class=o>%</span><span class=n>matplotlib</span> <span class=n>inline</span>
<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>16</span><span class=p>))</span>
<span class=n>sns</span><span class=o>.</span><span class=n>heatmap</span><span class=p>(</span><span class=n>policy</span><span class=p>,</span>  <span class=n>cmap</span><span class=o>=</span><span class=s2>&quot;YlGnBu&quot;</span><span class=p>,</span> <span class=n>annot</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>cbar</span><span class=o>=</span><span class=kc>False</span><span class=p>);</span>
</code></pre></div> </div> <p><img alt=png src=dynamic_programming_frozenlake_files/dynamic_programming_frozenlake_35_0.png></p> <h3 id=policy-evaluation-function-comprising-state-value-function>Policy Evaluation Function comprising State-value Function<a class=headerlink href=#policy-evaluation-function-comprising-state-value-function title="Permanent link">&para;</a></h3> <ul> <li>How: <span><span class=MathJax_Preview>\mathcal{V}_{\pi}(s) = \sum_{a \in \mathcal{A}} \pi(a | s) \sum_{s' \in \mathcal{S}} \mathcal{P}_{ss'}^a \big[\mathcal{R}_s^a + \gamma {V}_{\pi}(s')\big]</span><script type=math/tex>\mathcal{V}_{\pi}(s) = \sum_{a \in \mathcal{A}} \pi(a | s) \sum_{s' \in \mathcal{S}}  \mathcal{P}_{ss'}^a \big[\mathcal{R}_s^a + \gamma  {V}_{\pi}(s')\big]</script></span><ul> <li>Simple code equation:<ul> <li>Values of state given policy = sum ( action probability * transition probability * [reward + discount * value of new state] )</li> </ul> </li> </ul> </li> <li><strong>Aim: getting state-values</strong></li> </ul> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>

<span class=k>def</span> <span class=nf>policy_evaluation</span><span class=p>(</span><span class=n>env</span><span class=p>,</span> <span class=n>policy</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=mf>1.</span><span class=p>,</span> <span class=n>theta</span><span class=o>=</span><span class=mf>1e-8</span><span class=p>):</span>
    <span class=sa>r</span><span class=sd>&quot;&quot;&quot;Policy evaluation function. Loop until state values stable, delta &lt; theta.</span>

<span class=sd>    Returns V comprising values of states under given policy.</span>

<span class=sd>    Args:</span>
<span class=sd>        env (gym.env): OpenAI environment class instantiated and assigned to an object.</span>
<span class=sd>        policy (np.array): policy array to evaluate</span>
<span class=sd>        gamma (float): discount rate for rewards</span>
<span class=sd>        theta (float): tiny positive number, anything below it indicates value function convergence</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=c1># 1. Create state-value array (16,)</span>
    <span class=n>V</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>S_n</span><span class=p>)</span>
    <span class=k>while</span> <span class=kc>True</span><span class=p>:</span>
        <span class=n>delta</span> <span class=o>=</span> <span class=mi>0</span>

        <span class=c1># 2. Loop through states</span>
        <span class=k>for</span> <span class=n>s</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>S_n</span><span class=p>):</span>
            <span class=n>Vs</span> <span class=o>=</span> <span class=mi>0</span>

            <span class=c1># 2.1 Loop through actions for the unique state</span>
            <span class=c1># Given each state, we&#39;ve 4 actions associated with different probabilities</span>
            <span class=c1># 0.25 x 4 in this case, so we&#39;ll be looping 4 times (4 action probabilities) at each state</span>
            <span class=k>for</span> <span class=n>a</span><span class=p>,</span> <span class=n>action_prob</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>policy</span><span class=p>[</span><span class=n>s</span><span class=p>]):</span>
                <span class=c1># 2.1.1 Loop through to get transition probabilities, next state, rewards and whether the game ended</span>
                <span class=k>for</span> <span class=n>prob</span><span class=p>,</span> <span class=n>next_state</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span> <span class=ow>in</span> <span class=n>env</span><span class=o>.</span><span class=n>P</span><span class=p>[</span><span class=n>s</span><span class=p>][</span><span class=n>a</span><span class=p>]:</span>
                    <span class=c1># State-value function to get our values of states given policy</span>
                    <span class=n>Vs</span> <span class=o>+=</span> <span class=n>action_prob</span> <span class=o>*</span> <span class=n>prob</span> <span class=o>*</span> <span class=p>(</span><span class=n>reward</span> <span class=o>+</span> <span class=n>gamma</span> <span class=o>*</span> <span class=n>V</span><span class=p>[</span><span class=n>next_state</span><span class=p>])</span>

            <span class=c1># This simple equation allows us to stop this loop when we&#39;ve converged</span>
            <span class=c1># How do we know? The new value of the state is smaller than a tiny positive value we set</span>
            <span class=c1># State value change is tiny compared to what we have so we just stop!</span>
            <span class=n>delta</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=n>delta</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>V</span><span class=p>[</span><span class=n>s</span><span class=p>]</span><span class=o>-</span><span class=n>Vs</span><span class=p>))</span>

            <span class=c1># 2.2 Update our state value for that state</span>
            <span class=n>V</span><span class=p>[</span><span class=n>s</span><span class=p>]</span> <span class=o>=</span> <span class=n>Vs</span>

        <span class=c1># 3. Stop policy evaluation if our state values changes are smaller than our tiny positive number</span>
        <span class=k>if</span> <span class=n>delta</span> <span class=o>&lt;</span> <span class=n>theta</span><span class=p>:</span>
            <span class=k>break</span>

    <span class=k>return</span> <span class=n>V</span>

<span class=c1># Generate random policy with equal probabilities of each action given any state</span>
<span class=n>rand_policy</span> <span class=o>=</span> <span class=n>generate_random_policy</span><span class=p>(</span><span class=n>S_n</span><span class=p>,</span> <span class=n>A_n</span><span class=p>)</span>

<span class=c1># Evaluate the policy to get state values</span>
<span class=n>V</span> <span class=o>=</span> <span class=n>policy_evaluation</span><span class=p>(</span><span class=n>env</span><span class=p>,</span> <span class=n>rand_policy</span><span class=p>)</span>

<span class=c1># Plot heatmap</span>
<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>8</span><span class=p>,</span> <span class=mi>8</span><span class=p>))</span>
<span class=n>sns</span><span class=o>.</span><span class=n>heatmap</span><span class=p>(</span><span class=n>V</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>4</span><span class=p>),</span>  <span class=n>cmap</span><span class=o>=</span><span class=s2>&quot;YlGnBu&quot;</span><span class=p>,</span> <span class=n>annot</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>cbar</span><span class=o>=</span><span class=kc>False</span><span class=p>);</span>
</code></pre></div> <p><img alt=png src=dynamic_programming_frozenlake_files/dynamic_programming_frozenlake_39_0.png></p> <div class=highlight><pre><span></span><code><span class=c1># This is our environment</span>
<span class=c1># Notice how the state values near the goal have higher values?</span>
<span class=c1># Those with &quot;H&quot; = hole, where you die if you step, have 0 values indicating those are bad areas to be in</span>
<span class=n>env</span><span class=o>.</span><span class=n>render</span><span class=p>()</span>
</code></pre></div> <div class=codehilite><pre><span></span><code>[S]FFF
FHFH
FFFH
HFFG
</code></pre></div> <h2 id=policy-improvement>Policy Improvement<a class=headerlink href=#policy-improvement title="Permanent link">&para;</a></h2> <h3 id=action-value-q-value-function-from-state-value-function>Action-value (Q-value) function from State-value function<a class=headerlink href=#action-value-q-value-function-from-state-value-function title="Permanent link">&para;</a></h3> <ul> <li>How: <span><span class=MathJax_Preview>\mathcal{Q}_{\pi}(s, a) = \sum_{s' \in \mathcal{S}} \mathcal{P}_{ss'}^a \big[ \mathcal{R}_s^a + \gamma \mathcal{V}_{\pi}(s') \big]</span><script type=math/tex>\mathcal{Q}_{\pi}(s, a) = \sum_{s' \in \mathcal{S}} \mathcal{P}_{ss'}^a \big[ \mathcal{R}_s^a + \gamma  \mathcal{V}_{\pi}(s') \big]</script></span><ul> <li>Code equation<ul> <li>Values of action = sum ( transition probability * [reward + discount * value of next state] )</li> </ul> </li> </ul> </li> <li><strong>Aim: getting q-values (action-values)</strong></li> </ul> <div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>q_value</span><span class=p>(</span><span class=n>env</span><span class=p>,</span> <span class=n>V</span><span class=p>,</span> <span class=n>s</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=mi>1</span><span class=p>):</span>
    <span class=sa>r</span><span class=sd>&quot;&quot;&quot;Q-value (action-value) function from state-value function</span>

<span class=sd>    Returns Q values, values of actions.</span>

<span class=sd>    Args:</span>
<span class=sd>        env (gym.env): OpenAI environment class instantiated and assigned to an object.</span>
<span class=sd>        V (np.array): array of state-values obtained from policy evaluation function.</span>
<span class=sd>        s (integer): integer representing current state in the gridworld</span>
<span class=sd>        gamma (float): discount rate for rewards.</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=c1># 1. Create q-value array for one state</span>
    <span class=c1># We have 4 actions, so let&#39;s create an array with the size of 4</span>
    <span class=n>q</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>A_n</span><span class=p>)</span>

    <span class=c1># 2. Loop through each action</span>
    <span class=k>for</span> <span class=n>a</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>A_n</span><span class=p>):</span>
        <span class=c1># 2.1 For each action, we&#39;ve our transition probabilities, next state, rewards and whether the game ended</span>
        <span class=k>for</span> <span class=n>prob</span><span class=p>,</span> <span class=n>next_state</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span> <span class=ow>in</span> <span class=n>env</span><span class=o>.</span><span class=n>P</span><span class=p>[</span><span class=n>s</span><span class=p>][</span><span class=n>a</span><span class=p>]:</span>
            <span class=c1># 2.1.1 Get our action-values from state-values</span>
            <span class=n>q</span><span class=p>[</span><span class=n>a</span><span class=p>]</span> <span class=o>+=</span> <span class=n>prob</span> <span class=o>*</span> <span class=p>(</span><span class=n>reward</span> <span class=o>+</span> <span class=n>gamma</span> <span class=o>*</span> <span class=n>V</span><span class=p>[</span><span class=n>next_state</span><span class=p>])</span>

    <span class=c1># Return action values</span>
    <span class=k>return</span> <span class=n>q</span>

<span class=c1># For every state, we&#39;ve 4 actions, hence we&#39;ve 16 x 4 q values</span>
<span class=n>Q</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>([</span><span class=n>S_n</span><span class=p>,</span> <span class=n>A_n</span><span class=p>])</span>

<span class=c1># Loop through each state out of 16</span>
<span class=c1># For each state, we will get the 4 q-values associated with the 4 actions</span>
<span class=k>for</span> <span class=n>s</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>env</span><span class=o>.</span><span class=n>nS</span><span class=p>):</span>
    <span class=n>Q</span><span class=p>[</span><span class=n>s</span><span class=p>]</span> <span class=o>=</span> <span class=n>q_value</span><span class=p>(</span><span class=n>env</span><span class=p>,</span> <span class=n>V</span><span class=p>,</span> <span class=n>s</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>16</span><span class=p>))</span>
<span class=n>sns</span><span class=o>.</span><span class=n>heatmap</span><span class=p>(</span><span class=n>Q</span><span class=p>,</span>  <span class=n>cmap</span><span class=o>=</span><span class=s2>&quot;YlGnBu&quot;</span><span class=p>,</span> <span class=n>annot</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>cbar</span><span class=o>=</span><span class=kc>False</span><span class=p>);</span>
</code></pre></div> <p><img alt=png src=dynamic_programming_frozenlake_files/dynamic_programming_frozenlake_45_0.png></p> <div class=highlight><pre><span></span><code><span class=c1># Notice how 13/14, those in the last row of the gridworld just before reaching the goal of finishing the game, their action values are large?</span>
<span class=n>env</span><span class=o>.</span><span class=n>render</span><span class=p>()</span>
</code></pre></div> <div class=codehilite><pre><span></span><code>[S]FFF
FHFH
FFFH
HFFG
</code></pre></div> <h3 id=policy-improvement-function>Policy Improvement Function<a class=headerlink href=#policy-improvement-function title="Permanent link">&para;</a></h3> <ul> <li>How: maximizing q-values per state by choosing actions with highest q-values</li> <li>Aim: get improved policy</li> </ul> <div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>policy_improvement</span><span class=p>(</span><span class=n>env</span><span class=p>,</span> <span class=n>V</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=mf>1.</span><span class=p>):</span>
    <span class=sa>r</span><span class=sd>&quot;&quot;&quot;Function to improve the policy by utilizing state values and action (q) values.</span>

<span class=sd>    Args:</span>
<span class=sd>        env (gym.env): OpenAI environment class instantiated and assigned to an objects</span>
<span class=sd>        V (np.array): array of state-values obtained from policy evaluation function</span>
<span class=sd>        gamma (float): discount of rewards</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=c1># 1. Blank policy</span>
    <span class=n>policy</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>([</span><span class=n>env</span><span class=o>.</span><span class=n>nS</span><span class=p>,</span> <span class=n>env</span><span class=o>.</span><span class=n>nA</span><span class=p>])</span> <span class=o>/</span> <span class=n>env</span><span class=o>.</span><span class=n>nA</span>

    <span class=c1># 2. For each state in 16 states</span>
    <span class=k>for</span> <span class=n>s</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>env</span><span class=o>.</span><span class=n>nS</span><span class=p>):</span>

        <span class=c1># 2.1 Get q values: q.shape returns (4,)</span>
        <span class=n>q</span> <span class=o>=</span> <span class=n>q_value</span><span class=p>(</span><span class=n>env</span><span class=p>,</span> <span class=n>V</span><span class=p>,</span> <span class=n>s</span><span class=p>,</span> <span class=n>gamma</span><span class=p>)</span>

        <span class=c1># 2.2 Find best action based on max q-value</span>
        <span class=c1># np.argwhere(q==np.max(q)) gives the position of largest q value</span>
        <span class=c1># given array([0.00852356, 0.01163091, 0.0108613 , 0.01550788]), this would return array([[3]]) of shape (1, 1)</span>
        <span class=c1># .flatten() reduces the shape to (1,) where we&#39;ve array([3])</span>
        <span class=n>best_a</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argwhere</span><span class=p>(</span><span class=n>q</span><span class=o>==</span><span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>q</span><span class=p>))</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>

        <span class=c1># 2.3 One-hot encode best action and store into policy array&#39;s row for that state</span>
        <span class=c1># In our case where the best action is array([3]), this would return</span>
        <span class=c1># array([0., 0., 0., 1.]) where position 3 is the best action</span>
        <span class=c1># Now we can store the best action into our policy</span>
        <span class=n>policy</span><span class=p>[</span><span class=n>s</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>([</span><span class=n>np</span><span class=o>.</span><span class=n>eye</span><span class=p>(</span><span class=n>env</span><span class=o>.</span><span class=n>nA</span><span class=p>)[</span><span class=n>i</span><span class=p>]</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>best_a</span><span class=p>],</span> <span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span><span class=o>/</span><span class=nb>len</span><span class=p>(</span><span class=n>best_a</span><span class=p>)</span>

    <span class=k>return</span> <span class=n>policy</span>


<span class=n>new_policy</span> <span class=o>=</span> <span class=n>policy_improvement</span><span class=p>(</span><span class=n>env</span><span class=p>,</span> <span class=n>V</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>16</span><span class=p>))</span>
<span class=n>sns</span><span class=o>.</span><span class=n>heatmap</span><span class=p>(</span><span class=n>new_policy</span><span class=p>,</span>  <span class=n>cmap</span><span class=o>=</span><span class=s2>&quot;YlGnBu&quot;</span><span class=p>,</span> <span class=n>annot</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>cbar</span><span class=o>=</span><span class=kc>False</span><span class=p>);</span>
</code></pre></div> <p><img alt=png src=dynamic_programming_frozenlake_files/dynamic_programming_frozenlake_50_0.png></p> <div class=highlight><pre><span></span><code><span class=c1># Compared to this equiprobable policy, the one above is making some improvements by maximizing q-values per state</span>
<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>16</span><span class=p>))</span>
<span class=n>sns</span><span class=o>.</span><span class=n>heatmap</span><span class=p>(</span><span class=n>rand_policy</span><span class=p>,</span>  <span class=n>cmap</span><span class=o>=</span><span class=s2>&quot;YlGnBu&quot;</span><span class=p>,</span> <span class=n>annot</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>cbar</span><span class=o>=</span><span class=kc>False</span><span class=p>);</span>
</code></pre></div> <p><img alt=png src=dynamic_programming_frozenlake_files/dynamic_programming_frozenlake_51_0.png></p> <h3 id=policy-iteration-function>Policy Iteration Function<a class=headerlink href=#policy-iteration-function title="Permanent link">&para;</a></h3> <ul> <li>How: loop through policy evaluation (get state-values) and policy improvement functions (use state-values to calculate q-values to improve policy) until optimal policy obtained</li> <li>Aim: improve policy until convergence<ul> <li>Convergence: difference of state values between old and new policies is very small (less than theta, a very small positive number)</li> </ul> </li> </ul> <p><img alt src=./images/policy_iteration.png></p> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>copy</span>
<span class=k>def</span> <span class=nf>policy_iteration</span><span class=p>(</span><span class=n>env</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>theta</span><span class=o>=</span><span class=mf>1e-8</span><span class=p>):</span>
    <span class=c1># 1. Create equiprobable policy where every state has 4 actions with equal probabilities as a starting policy</span>
    <span class=n>policy</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>ones</span><span class=p>([</span><span class=n>env</span><span class=o>.</span><span class=n>nS</span><span class=p>,</span> <span class=n>env</span><span class=o>.</span><span class=n>nA</span><span class=p>])</span> <span class=o>/</span> <span class=n>env</span><span class=o>.</span><span class=n>nA</span>

    <span class=c1># 2. Loop through policy_evaluation and policy_improvement functions</span>
    <span class=k>while</span> <span class=kc>True</span><span class=p>:</span>
        <span class=c1># 2.1 Get state-values</span>
        <span class=n>V</span> <span class=o>=</span> <span class=n>policy_evaluation</span><span class=p>(</span><span class=n>env</span><span class=p>,</span> <span class=n>policy</span><span class=p>,</span> <span class=n>gamma</span><span class=p>,</span> <span class=n>theta</span><span class=p>)</span>

        <span class=c1># 2.2 Get new policy by getting q-values and maximizing q-values per state to get best action per state</span>
        <span class=n>new_policy</span> <span class=o>=</span> <span class=n>policy_improvement</span><span class=p>(</span><span class=n>env</span><span class=p>,</span> <span class=n>V</span><span class=p>)</span>

        <span class=c1># 2.3 Stop if the value function estimates for successive policies has converged</span>
        <span class=k>if</span> <span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=nb>abs</span><span class=p>(</span><span class=n>policy_evaluation</span><span class=p>(</span><span class=n>env</span><span class=p>,</span> <span class=n>policy</span><span class=p>)</span> <span class=o>-</span> <span class=n>policy_evaluation</span><span class=p>(</span><span class=n>env</span><span class=p>,</span> <span class=n>new_policy</span><span class=p>)))</span> <span class=o>&lt;</span> <span class=n>theta</span> <span class=o>*</span> <span class=mf>1e2</span><span class=p>:</span>
            <span class=k>break</span><span class=p>;</span>

        <span class=c1># 2.4 Replace policy with new policy</span>
        <span class=n>policy</span> <span class=o>=</span> <span class=n>copy</span><span class=o>.</span><span class=n>copy</span><span class=p>(</span><span class=n>new_policy</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>policy</span><span class=p>,</span> <span class=n>V</span>

<span class=c1># obtain the optimal policy and optimal state-value function</span>
<span class=n>policy_pi</span><span class=p>,</span> <span class=n>V_pi</span> <span class=o>=</span> <span class=n>policy_iteration</span><span class=p>(</span><span class=n>env</span><span class=p>)</span>

<span class=c1># Optimal policy (pi) </span>
<span class=c1># LEFT = 0, DOWN = 1, RIGHT = 2, UP = 3</span>
<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>16</span><span class=p>))</span>
<span class=n>sns</span><span class=o>.</span><span class=n>heatmap</span><span class=p>(</span><span class=n>policy_pi</span><span class=p>,</span>  <span class=n>cmap</span><span class=o>=</span><span class=s2>&quot;YlGnBu&quot;</span><span class=p>,</span> <span class=n>annot</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>cbar</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>square</span><span class=o>=</span><span class=kc>True</span><span class=p>);</span>
</code></pre></div> <p><img alt=png src=dynamic_programming_frozenlake_files/dynamic_programming_frozenlake_55_0.png></p> <div class=highlight><pre><span></span><code><span class=c1># State values</span>
<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>8</span><span class=p>,</span> <span class=mi>8</span><span class=p>))</span>
<span class=n>sns</span><span class=o>.</span><span class=n>heatmap</span><span class=p>(</span><span class=n>V_pi</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>4</span><span class=p>),</span>  <span class=n>cmap</span><span class=o>=</span><span class=s2>&quot;YlGnBu&quot;</span><span class=p>,</span> <span class=n>annot</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>cbar</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>square</span><span class=o>=</span><span class=kc>True</span><span class=p>);</span>
</code></pre></div> <p><img alt=png src=dynamic_programming_frozenlake_files/dynamic_programming_frozenlake_56_0.png></p> <div class=highlight><pre><span></span><code><span class=c1># State values without policy improvement, just evaluation</span>
<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>8</span><span class=p>,</span> <span class=mi>8</span><span class=p>))</span>
<span class=n>sns</span><span class=o>.</span><span class=n>heatmap</span><span class=p>(</span><span class=n>V</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>4</span><span class=p>),</span>  <span class=n>cmap</span><span class=o>=</span><span class=s2>&quot;YlGnBu&quot;</span><span class=p>,</span> <span class=n>annot</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>cbar</span><span class=o>=</span><span class=kc>False</span><span class=p>);</span>
</code></pre></div> <p><img alt=png src=dynamic_programming_frozenlake_files/dynamic_programming_frozenlake_57_0.png></p> <h3 id=value-iteration>Value iteration<a class=headerlink href=#value-iteration title="Permanent link">&para;</a></h3> <ul> <li>Alternative to policy iteration</li> <li>How: loop through to find optimal value function then get one-off policy</li> <li>Aim: improve value function until convergence<ul> <li>Convergence: until difference in new and old state values are small (smaller than theta, small positive number)</li> </ul> </li> </ul> <p><img alt src=./images/value_iteration.png></p> <div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>value_iteration</span><span class=p>(</span><span class=n>env</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>theta</span><span class=o>=</span><span class=mf>1e-8</span><span class=p>):</span>
    <span class=c1># 1. Create state values of shape (16,)</span>
    <span class=n>V</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>env</span><span class=o>.</span><span class=n>nS</span><span class=p>)</span>

    <span class=c1># 2. Loop through q-value function until convergence</span>
    <span class=k>while</span> <span class=kc>True</span><span class=p>:</span>
        <span class=n>delta</span> <span class=o>=</span> <span class=mi>0</span>

        <span class=c1># 2.1 Loop through each state</span>
        <span class=k>for</span> <span class=n>s</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>env</span><span class=o>.</span><span class=n>nS</span><span class=p>):</span>
            <span class=c1># 2.2 Archive old state value</span>
            <span class=n>v</span> <span class=o>=</span> <span class=n>V</span><span class=p>[</span><span class=n>s</span><span class=p>]</span>

            <span class=c1># 2.3 New state value = max of q-value</span>
            <span class=n>V</span><span class=p>[</span><span class=n>s</span><span class=p>]</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=n>q_value</span><span class=p>(</span><span class=n>env</span><span class=p>,</span> <span class=n>V</span><span class=p>,</span> <span class=n>s</span><span class=p>,</span> <span class=n>gamma</span><span class=p>))</span>

            <span class=n>delta</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=n>delta</span><span class=p>,</span> <span class=nb>abs</span><span class=p>(</span><span class=n>V</span><span class=p>[</span><span class=n>s</span><span class=p>]</span> <span class=o>-</span> <span class=n>v</span><span class=p>))</span>

        <span class=c1># 2.2 If state value changes small, converged</span>
        <span class=k>if</span> <span class=n>delta</span> <span class=o>&lt;</span> <span class=n>theta</span><span class=p>:</span>
            <span class=k>break</span>

    <span class=c1># 3. Extract one-off policy with optimal state values</span>
    <span class=n>policy</span> <span class=o>=</span> <span class=n>policy_improvement</span><span class=p>(</span><span class=n>env</span><span class=p>,</span> <span class=n>V</span><span class=p>,</span> <span class=n>gamma</span><span class=p>)</span>

    <span class=k>return</span> <span class=n>policy</span><span class=p>,</span> <span class=n>V</span>

<span class=n>policy_vi</span><span class=p>,</span> <span class=n>V_vi</span> <span class=o>=</span> <span class=n>value_iteration</span><span class=p>(</span><span class=n>env</span><span class=p>)</span>

<span class=c1># Optimal policy</span>
<span class=c1># LEFT = 0, DOWN = 1, RIGHT = 2, UP = 3</span>
<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>16</span><span class=p>))</span>
<span class=n>sns</span><span class=o>.</span><span class=n>heatmap</span><span class=p>(</span><span class=n>policy_vi</span><span class=p>,</span>  <span class=n>cmap</span><span class=o>=</span><span class=s2>&quot;YlGnBu&quot;</span><span class=p>,</span> <span class=n>annot</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>cbar</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>square</span><span class=o>=</span><span class=kc>True</span><span class=p>);</span>
</code></pre></div> <p><img alt=png src=dynamic_programming_frozenlake_files/dynamic_programming_frozenlake_61_0.png></p> <div class=highlight><pre><span></span><code><span class=c1># State values</span>
<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>8</span><span class=p>,</span> <span class=mi>8</span><span class=p>))</span>
<span class=n>sns</span><span class=o>.</span><span class=n>heatmap</span><span class=p>(</span><span class=n>V_vi</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>4</span><span class=p>),</span>  <span class=n>cmap</span><span class=o>=</span><span class=s2>&quot;YlGnBu&quot;</span><span class=p>,</span> <span class=n>annot</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>cbar</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>square</span><span class=o>=</span><span class=kc>True</span><span class=p>);</span>
</code></pre></div> <p><img alt=png src=dynamic_programming_frozenlake_files/dynamic_programming_frozenlake_62_0.png></p> </article> </div> </div> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> Copyright &copy; 2020 Disponha </div> Todo o conteúdo deste site está publicado sob a licença <a href=https://creativecommons.org/licenses/by-nc-sa/4.0/ target=_blank rel=noopener> Creative Commons CC BY-SA 4.0 Brasil </a> </div> <div class=md-footer-social> <a href=https://github.com/andhremattos target=_blank rel=noopener title=github.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> <a href=https://facebook.com/dhematos target=_blank rel=noopener title=facebook.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg> </a> <a href=https://instagram.com/dhematos target=_blank rel=noopener title=instagram.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M224.1 141c-63.6 0-114.9 51.3-114.9 114.9s51.3 114.9 114.9 114.9S339 319.5 339 255.9 287.7 141 224.1 141zm0 189.6c-41.1 0-74.7-33.5-74.7-74.7s33.5-74.7 74.7-74.7 74.7 33.5 74.7 74.7-33.6 74.7-74.7 74.7zm146.4-194.3c0 14.9-12 26.8-26.8 26.8-14.9 0-26.8-12-26.8-26.8s12-26.8 26.8-26.8 26.8 12 26.8 26.8zm76.1 27.2c-1.7-35.9-9.9-67.7-36.2-93.9-26.2-26.2-58-34.4-93.9-36.2-37-2.1-147.9-2.1-184.9 0-35.8 1.7-67.6 9.9-93.9 36.1s-34.4 58-36.2 93.9c-2.1 37-2.1 147.9 0 184.9 1.7 35.9 9.9 67.7 36.2 93.9s58 34.4 93.9 36.2c37 2.1 147.9 2.1 184.9 0 35.9-1.7 67.7-9.9 93.9-36.2 26.2-26.2 34.4-58 36.2-93.9 2.1-37 2.1-147.8 0-184.8zM398.8 388c-7.8 19.6-22.9 34.7-42.6 42.6-29.5 11.7-99.5 9-132.1 9s-102.7 2.6-132.1-9c-19.6-7.8-34.7-22.9-42.6-42.6-11.7-29.5-9-99.5-9-132.1s-2.6-102.7 9-132.1c7.8-19.6 22.9-34.7 42.6-42.6 29.5-11.7 99.5-9 132.1-9s102.7-2.6 132.1 9c19.6 7.8 34.7 22.9 42.6 42.6 11.7 29.5 9 99.5 9 132.1s2.7 102.7-9 132.1z"/></svg> </a> </div> </div> </div> </footer> </div> <script src=../../../assets/javascripts/vendor.de50e36d.min.js></script> <script src=../../../assets/javascripts/bundle.fc9c3121.min.js></script><script id=__lang type=application/json>{"clipboard.copy": "Copiar para \u00e1rea de transfer\u00eancia", "clipboard.copied": "Copiado para \u00e1rea de transfer\u00eancia", "search.config.lang": "pt", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Digite para iniciar a busca", "search.result.none": "Nenhum resultado encontrado", "search.result.one": "1 resultado encontrado", "search.result.other": "# resultados encontrados"}</script> <script>
        app = initialize({
          base: "../../..",
          features: ["tabs"],
          search: Object.assign({
            worker:"../../../assets/javascripts/worker/search.a68abb33.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script> <script src=../../../javascripts/config.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script> </body> </html>