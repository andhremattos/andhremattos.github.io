<!doctype html><html lang=pt class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Plataforma para disponibilização cursos de cálculo."><link href=https:///disponha.com/pre_calculo/conjuntos_numericos/optimizers/ rel=canonical><meta name=author content="Carlos André"><link rel="shortcut icon" href=../../../assets/favicon.png><meta name=generator content="mkdocs-1.1.2, mkdocs-material-5.4.0"><title>Optimization Algorithms - disponha</title><link rel=stylesheet href=../../../assets/stylesheets/main.545621a7.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.36d1b78f.min.css><meta name=theme-color content=#009688><link href=https://fonts.gstatic.com rel=preconnect crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Helvetica:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>body,input{font-family:"Helvetica",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","None","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){if(this.value){var e=document.location.pathname;ga("send","pageview",e+"?q="+this.value)}})}),document.addEventListener("DOMContentSwitch",function(){ga("send","pageview")})</script><script async src=https://www.google-analytics.com/analytics.js></script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=teal data-md-color-accent=teal> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#optimization-algorithms class=md-skip> Ir para o conteúdo </a> </div> <!-- 
    <div data-md-component="announce">
      
    </div>
  --> <header class=md-header data-md-component=header> <nav class="md-header-nav md-grid" aria-label=Header> <a href=https:/disponha.com/ title=disponha class="md-header-nav__button md-logo" aria-label=disponha> <?xml version="1.0" encoding="UTF-8"?> <!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><!-- Creator: CorelDRAW X7 --><svg xmlns=http://www.w3.org/2000/svg xml:space=preserve width=9000px height=9000px version=1.1 style="shape-rendering:geometricPrecision; text-rendering:geometricPrecision; image-rendering:optimizeQuality; fill-rule:evenodd; clip-rule:evenodd" viewbox="0 0 9000 9000" xmlns:xlink=http://www.w3.org/1999/xlink> <defs> <style type=text/css>
   <![CDATA[
    .str0 {stroke:#2E72A4;stroke-width:118.11}
    .fil0 {fill:#FEFEFE}
    .fil1 {fill:#2E72A4}
   ]]>
  </style> </defs> <g id=Camada_x0020_1> <metadata id=CorelCorpID_0Corel-Layer /> <g id=_1793748728448> <circle cx=4472 cy=4507 r=4281 class="fil0 str0"/> <path class="fil1 str0" d="M2045 5171c120,204 210,379 402,449 314,115 1000,-177 1339,-330 79,-35 179,-68 254,-120 41,-13 94,-46 135,-68l951 -479c363,-177 729,-363 1095,-521 186,-80 370,-180 558,-244 465,-158 1366,-413 1814,-369l1 -59c-328,-34 -853,93 -1189,181 -431,113 -680,200 -1103,395 -706,324 -1401,670 -2099,1021 -397,199 -1256,618 -1669,556 -218,-33 -320,-195 -449,-416 -47,-80 -137,-241 -177,-328 -49,-108 -114,-212 -179,-311 -379,-575 -831,-826 -1274,-1083l-119 -63 -10 46 247 149c311,184 648,381 929,716 107,128 198,250 291,408 61,104 217,424 252,470z"/> </g> </g> </svg> </a> <label class="md-header-nav__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header-nav__title data-md-component=header-title> <div class=md-header-nav__ellipsis> <span class="md-header-nav__topic md-ellipsis"> disponha </span> <span class="md-header-nav__topic md-ellipsis"> Optimization Algorithms </span> </div> </div> <label class="md-header-nav__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Buscar placeholder=Buscar autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query data-md-state=active> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <button type=reset class="md-search__icon md-icon" aria-label=Clear data-md-component=search-reset tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header-nav__source> <!-- 

<a href="https://github.com/andhremattos/" title="Ir ao repositório" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    esead
  </div>
</a>
--> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list> <li class=md-tabs__item> <!--
      <a href="../../.." class="md-tabs__link md-tabs__link--active">
        Home
      </a>
    --> <a href=/explore/ class="md-tabs__link md-tabs__link--active"> Explore e-books </a> </li> <!--
    <li class="md-tabs__item">
      
        <a href="../../../sobre/" class="md-tabs__link">
          Sobre
        </a>
      
    </li>--> <!--
    <li class="md-tabs__item">
      
        <a href="../../../explore/" class="md-tabs__link">
          Explore
        </a>
      
    </li>--> <!--
    <li class="md-tabs__item">
      
        <a href="../../../app_web_ebook/servico/" class="md-tabs__link">
          App Web ebook
        </a>
      
    </li>--> <!--
    <li class="md-tabs__item">
      
        <a href="../../../diagramacao/servico/" class="md-tabs__link">
          Diagramação
        </a>
      
    </li>--> <!--
    <li class="md-tabs__item">
      
        <a href="../../../ciencia_de_dados/servico/" class="md-tabs__link">
          Ciência de dados
        </a>
      
    </li>--> <!--
    <li class="md-tabs__item">
      
        <a href="../../../aprendacalculo/" class="md-tabs__link">
          Aprenda Cálculo
        </a>
      
    </li>--> <!--
    <li class="md-tabs__item">
      
        <a href="../../../cursolatex/" class="md-tabs__link">
          Curso de LaTeX
        </a>
      
    </li>--> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=https:/disponha.com/ title=disponha class="md-nav__button md-logo" aria-label=disponha> <?xml version="1.0" encoding="UTF-8"?> <!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><!-- Creator: CorelDRAW X7 --><svg xmlns=http://www.w3.org/2000/svg xml:space=preserve width=9000px height=9000px version=1.1 style="shape-rendering:geometricPrecision; text-rendering:geometricPrecision; image-rendering:optimizeQuality; fill-rule:evenodd; clip-rule:evenodd" viewbox="0 0 9000 9000" xmlns:xlink=http://www.w3.org/1999/xlink> <defs> <style type=text/css>
   <![CDATA[
    .str0 {stroke:#2E72A4;stroke-width:118.11}
    .fil0 {fill:#FEFEFE}
    .fil1 {fill:#2E72A4}
   ]]>
  </style> </defs> <g id=Camada_x0020_1> <metadata id=CorelCorpID_0Corel-Layer /> <g id=_1793748728448> <circle cx=4472 cy=4507 r=4281 class="fil0 str0"/> <path class="fil1 str0" d="M2045 5171c120,204 210,379 402,449 314,115 1000,-177 1339,-330 79,-35 179,-68 254,-120 41,-13 94,-46 135,-68l951 -479c363,-177 729,-363 1095,-521 186,-80 370,-180 558,-244 465,-158 1366,-413 1814,-369l1 -59c-328,-34 -853,93 -1189,181 -431,113 -680,200 -1103,395 -706,324 -1401,670 -2099,1021 -397,199 -1256,618 -1669,556 -218,-33 -320,-195 -449,-416 -47,-80 -137,-241 -177,-328 -49,-108 -114,-212 -179,-311 -379,-575 -831,-826 -1274,-1083l-119 -63 -10 46 247 149c311,184 648,381 929,716 107,128 198,250 291,408 61,104 217,424 252,470z"/> </g> </g> </svg> </a> disponha </label> <div class=md-nav__source> <!-- 

<a href="https://github.com/andhremattos/" title="Ir ao repositório" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    esead
  </div>
</a>
--> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. title=Home class=md-nav__link> Home </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2 type=checkbox id=nav-2> <label class=md-nav__link for=nav-2> Sobre <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Sobre data-md-level=1> <label class=md-nav__title for=nav-2> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Sobre </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../sobre/ title=Home class=md-nav__link> Home </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3 type=checkbox id=nav-3> <label class=md-nav__link for=nav-3> Explore <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Explore data-md-level=1> <label class=md-nav__title for=nav-3> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Explore </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../explore/ title=E-books class=md-nav__link> E-books </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../apoie/ title=Apoie class=md-nav__link> Apoie </a> </li> <li class=md-nav__item> <a href=../../../consultoria/ title=Consultoria class=md-nav__link> Consultoria </a> </li> <li class=md-nav__item> <a href=../../../politica_privacidade/ title=Privacidade class=md-nav__link> Privacidade </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-7 type=checkbox id=nav-7> <label class=md-nav__link for=nav-7> App Web ebook <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="App Web ebook" data-md-level=1> <label class=md-nav__title for=nav-7> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> App Web ebook </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../app_web_ebook/servico/ title=Serviço class=md-nav__link> Serviço </a> </li> <li class=md-nav__item> <a href=../../../app_web_ebook/amostra/ title="App Web ebook - amostra" class=md-nav__link> App Web ebook - amostra </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-8 type=checkbox id=nav-8> <label class=md-nav__link for=nav-8> Diagramação <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Diagramação data-md-level=1> <label class=md-nav__title for=nav-8> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Diagramação </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../diagramacao/servico/ title=Serviço class=md-nav__link> Serviço </a> </li> <li class=md-nav__item> <a href=../../../diagramacao/amostra-diagramacao/ title=Amostra class=md-nav__link> Amostra </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-9 type=checkbox id=nav-9> <label class=md-nav__link for=nav-9> Ciência de dados <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="Ciência de dados" data-md-level=1> <label class=md-nav__title for=nav-9> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Ciência de dados </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../ciencia_de_dados/servico/ title=Serviço class=md-nav__link> Serviço </a> </li> <li class=md-nav__item> <a href=../../../ciencia_de_dados/amostra-1/ title="Amostra 1" class=md-nav__link> Amostra 1 </a> </li> <li class=md-nav__item> <a href=../../../ciencia_de_dados/amostra-2/ title="Amostra 2" class=md-nav__link> Amostra 2 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-10 type=checkbox id=nav-10> <label class=md-nav__link for=nav-10> Aprenda Cálculo <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="Aprenda Cálculo" data-md-level=1> <label class=md-nav__title for=nav-10> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Aprenda Cálculo </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../aprendacalculo/ title=Bem-Vindo(a)s class=md-nav__link> Bem-Vindo(a)s </a> </li> <li class=md-nav__item> <a href=../../../aprendacalculo/pre_calculo/ title=Pré-Cálculo class=md-nav__link> Pré-Cálculo </a> </li> <li class=md-nav__item> <a href=../../../aprendacalculo/calculo_i/ title="Cálculo I" class=md-nav__link> Cálculo I </a> </li> <li class=md-nav__item> <a href=../../../aprendacalculo/calculo_ii/ title="Cálculo II" class=md-nav__link> Cálculo II </a> </li> <li class=md-nav__item> <a href=../../../aprendacalculo/calculo_iii/ title="Cálculo III" class=md-nav__link> Cálculo III </a> </li> <li class=md-nav__item> <a href=../../../aprendacalculo/calculo_iv/ title="Cálculo IV" class=md-nav__link> Cálculo IV </a> </li> <li class=md-nav__item> <a href=../../../aprendacalculo/calculo_numerico/ title="C. Numérico" class=md-nav__link> C. Numérico </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-11 type=checkbox id=nav-11> <label class=md-nav__link for=nav-11> Curso de LaTeX <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="Curso de LaTeX" data-md-level=1> <label class=md-nav__title for=nav-11> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Curso de LaTeX </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../cursolatex/ title=Bem-Vindo(a)s class=md-nav__link> Bem-Vindo(a)s </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/programas/ title=Programas class=md-nav__link> Programas </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/latex_online/ title="LaTeX online" class=md-nav__link> LaTeX online </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/parte_1/ title="Parte 1" class=md-nav__link> Parte 1 </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/parte_2/ title="Parte 2" class=md-nav__link> Parte 2 </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/parte_3/ title="Parte 3" class=md-nav__link> Parte 3 </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/parte_4/ title="Parte 4" class=md-nav__link> Parte 4 </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/parte_5/ title="Parte 5" class=md-nav__link> Parte 5 </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/parte_6/ title="Parte 6" class=md-nav__link> Parte 6 </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/parte_7/ title="Parte 7" class=md-nav__link> Parte 7 </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label=Índice> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Índice </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=#introduction-to-gradient-descent-optimizers class=md-nav__link> Introduction to Gradient-descent Optimizers </a> <nav class=md-nav aria-label="Introduction to Gradient-descent Optimizers"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#model-recap-1-hidden-layer-feedforward-neural-network-relu-activation class=md-nav__link> Model Recap: 1 Hidden Layer Feedforward Neural Network (ReLU Activation) </a> </li> <li class=md-nav__item> <a href=#steps class=md-nav__link> Steps </a> </li> <li class=md-nav__item> <a href=#non-technical-process class=md-nav__link> Non-Technical Process </a> </li> <li class=md-nav__item> <a href=#why-is-it-called-gradient-descent class=md-nav__link> Why is it called Gradient Descent? </a> </li> <li class=md-nav__item> <a href=#mathematical-interpretation-of-gradient-descent class=md-nav__link> Mathematical Interpretation of Gradient Descent </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#optimization-algorithm-1-batch-gradient-descent class=md-nav__link> Optimization Algorithm 1: Batch Gradient Descent </a> </li> <li class=md-nav__item> <a href=#optimization-algorithm-2-stochastic-gradient-descent class=md-nav__link> Optimization Algorithm 2: Stochastic Gradient Descent </a> </li> <li class=md-nav__item> <a href=#optimization-algorithm-3-mini-batch-gradient-descent class=md-nav__link> Optimization Algorithm 3: Mini-batch Gradient Descent </a> </li> <li class=md-nav__item> <a href=#optimization-algorithm-4-sgd-momentum class=md-nav__link> Optimization Algorithm 4: SGD Momentum </a> </li> <li class=md-nav__item> <a href=#optimization-algorithm-4-sgd-nesterov class=md-nav__link> Optimization Algorithm 4: SGD Nesterov </a> </li> <li class=md-nav__item> <a href=#optimization-algorithm-4-adam class=md-nav__link> Optimization Algorithm 4: Adam </a> </li> <li class=md-nav__item> <a href=#other-adaptive-algorithms class=md-nav__link> Other Adaptive Algorithms </a> </li> <li class=md-nav__item> <a href=#optimization-algorithm-5-adagrad class=md-nav__link> Optimization Algorithm 5: Adagrad </a> </li> <li class=md-nav__item> <a href=#optimization-algorithm-6-adadelta class=md-nav__link> Optimization Algorithm 6: Adadelta </a> </li> <li class=md-nav__item> <a href=#optimization-algorithm-6-adamax class=md-nav__link> Optimization Algorithm 6: Adamax </a> </li> <li class=md-nav__item> <a href=#optimization-algorithm-7-rmsprop class=md-nav__link> Optimization Algorithm 7: RMSProp </a> </li> <li class=md-nav__item> <a href=#summary-of-optimization-algorithms-performance class=md-nav__link> Summary of Optimization Algorithms Performance </a> </li> <li class=md-nav__item> <a href=#simple-suggestions class=md-nav__link> Simple Suggestions </a> </li> <li class=md-nav__item> <a href=#summary class=md-nav__link> Summary </a> </li> <li class=md-nav__item> <a href=#citation class=md-nav__link> Citation </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content> <article class="md-content__inner md-typeset"> <h1 id=optimization-algorithms>Optimization Algorithms<a class=headerlink href=#optimization-algorithms title="Permanent link">&para;</a></h1> <div class="admonition tip"> <p class=admonition-title>Run Jupyter Notebook</p> <p>You can run the code for this section in this <a href=https://github.com/ritchieng/deep-learning-wizard/blob/master/docs/deep_learning/boosting_models_pytorch/optimizers.ipynb>jupyter notebook link</a>.</p> </div> <h2 id=introduction-to-gradient-descent-optimizers>Introduction to Gradient-descent Optimizers<a class=headerlink href=#introduction-to-gradient-descent-optimizers title="Permanent link">&para;</a></h2> <h3 id=model-recap-1-hidden-layer-feedforward-neural-network-relu-activation>Model Recap: 1 Hidden Layer Feedforward Neural Network (ReLU Activation)<a class=headerlink href=#model-recap-1-hidden-layer-feedforward-neural-network-relu-activation title="Permanent link">&para;</a></h3> <p><img alt src=../images/nn1.png></p> <h3 id=steps>Steps<a class=headerlink href=#steps title="Permanent link">&para;</a></h3> <ul> <li>Step 1: Load Dataset</li> <li>Step 2: Make Dataset Iterable</li> <li>Step 3: Create Model Class</li> <li>Step 4: Instantiate Model Class</li> <li>Step 5: Instantiate Loss Class</li> <li><strong>Step 6: Instantiate Optimizer Class</strong></li> <li>Step 7: Train Model</li> </ul> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>torch</span>
<span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
<span class=kn>import</span> <span class=nn>torchvision.transforms</span> <span class=k>as</span> <span class=nn>transforms</span>
<span class=kn>import</span> <span class=nn>torchvision.datasets</span> <span class=k>as</span> <span class=nn>dsets</span>

<span class=c1># Set seed</span>
<span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>


<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 1: LOADING DATASET</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=n>train_dataset</span> <span class=o>=</span> <span class=n>dsets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> 
                            <span class=n>train</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> 
                            <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>
                            <span class=n>download</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>test_dataset</span> <span class=o>=</span> <span class=n>dsets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> 
                           <span class=n>train</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> 
                           <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>())</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 2: MAKING DATASET ITERABLE</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=n>batch_size</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>n_iters</span> <span class=o>=</span> <span class=mi>3000</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=n>n_iters</span> <span class=o>/</span> <span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>)</span> <span class=o>/</span> <span class=n>batch_size</span><span class=p>)</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>)</span>

<span class=n>train_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>train_dataset</span><span class=p>,</span> 
                                           <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> 
                                           <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>test_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>test_dataset</span><span class=p>,</span> 
                                          <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> 
                                          <span class=n>shuffle</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 3: CREATE MODEL CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=k>class</span> <span class=nc>FeedforwardNeuralNetModel</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>FeedforwardNeuralNetModel</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
        <span class=c1># Linear function</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>)</span> 
        <span class=c1># Non-linearity</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>relu</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>()</span>
        <span class=c1># Linear function (readout)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span>  

    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=c1># Linear function</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
        <span class=c1># Non-linearity</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>out</span><span class=p>)</span>
        <span class=c1># Linear function (readout)</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span><span class=p>(</span><span class=n>out</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>out</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 4: INSTANTIATE MODEL CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>input_dim</span> <span class=o>=</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span>
<span class=n>hidden_dim</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>output_dim</span> <span class=o>=</span> <span class=mi>10</span>

<span class=n>model</span> <span class=o>=</span> <span class=n>FeedforwardNeuralNetModel</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 5: INSTANTIATE LOSS CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>


<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 6: INSTANTIATE OPTIMIZER CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>learning_rate</span> <span class=o>=</span> <span class=mf>0.1</span>

<span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=n>learning_rate</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 7: TRAIN THE MODEL</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=nb>iter</span> <span class=o>=</span> <span class=mi>0</span>
<span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=p>(</span><span class=n>images</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_loader</span><span class=p>):</span>
        <span class=c1># Load images as Variable</span>
        <span class=n>images</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span><span class=p>)</span><span class=o>.</span><span class=n>requires_grad_</span><span class=p>()</span>

        <span class=c1># Clear gradients w.r.t. parameters</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>

        <span class=c1># Forward pass to get output/logits</span>
        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>

        <span class=c1># Calculate Loss: softmax --&gt; cross entropy loss</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>

        <span class=c1># Getting gradients w.r.t. parameters</span>
        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>

        <span class=c1># Updating parameters</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

        <span class=nb>iter</span> <span class=o>+=</span> <span class=mi>1</span>

        <span class=k>if</span> <span class=nb>iter</span> <span class=o>%</span> <span class=mi>500</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
            <span class=c1># Calculate Accuracy         </span>
            <span class=n>correct</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=n>total</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=c1># Iterate through test dataset</span>
            <span class=k>for</span> <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>test_loader</span><span class=p>:</span>
                <span class=c1># Load images to a Torch Variable</span>
                <span class=n>images</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span><span class=p>)</span>

                <span class=c1># Forward pass only to get logits/output</span>
                <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>

                <span class=c1># Get predictions from the maximum value</span>
                <span class=n>_</span><span class=p>,</span> <span class=n>predicted</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>outputs</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

                <span class=c1># Total number of labels</span>
                <span class=n>total</span> <span class=o>+=</span> <span class=n>labels</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>

                <span class=c1># Total correct predictions</span>
                <span class=n>correct</span> <span class=o>+=</span> <span class=p>(</span><span class=n>predicted</span> <span class=o>==</span> <span class=n>labels</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

            <span class=n>accuracy</span> <span class=o>=</span> <span class=mi>100</span> <span class=o>*</span> <span class=n>correct</span> <span class=o>/</span> <span class=n>total</span>

            <span class=c1># Print Loss</span>
            <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Iteration: </span><span class=si>{}</span><span class=s1>. Loss: </span><span class=si>{}</span><span class=s1>. Accuracy: </span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=nb>iter</span><span class=p>,</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span> <span class=n>accuracy</span><span class=p>))</span>
</code></pre></div> <div class=codehilite><pre><span></span><code>Iteration: 500. Loss: 0.3440718352794647. Accuracy: 91
Iteration: 1000. Loss: 0.2057694047689438. Accuracy: 93
Iteration: 1500. Loss: 0.2646750807762146. Accuracy: 94
Iteration: 2000. Loss: 0.17563636600971222. Accuracy: 94
Iteration: 2500. Loss: 0.1361844837665558. Accuracy: 95
Iteration: 3000. Loss: 0.11089023947715759. Accuracy: 95
</code></pre></div> <h3 id=non-technical-process>Non-Technical Process<a class=headerlink href=#non-technical-process title="Permanent link">&para;</a></h3> <ol> <li>Convert inputs/labels to variables</li> <li>Clear gradient buffers</li> <li>Get output given inputs </li> <li>Get loss by comparing with labels</li> <li>Get gradients w.r.t. parameters (backpropagation)</li> <li><strong>Update parameters using gradients (gradient descent)</strong><ul> <li><code>parameters = parameters - learning_rate * parameters_gradients</code></li> </ul> </li> <li>REPEAT</li> </ol> <h3 id=why-is-it-called-gradient-descent>Why is it called Gradient Descent?<a class=headerlink href=#why-is-it-called-gradient-descent title="Permanent link">&para;</a></h3> <ul> <li>Use gradients (calculated through backpropagation) <span><span class=MathJax_Preview>\rightarrow</span><script type=math/tex>\rightarrow</script></span> update parameters to minimize our loss (descent) <span><span class=MathJax_Preview>\rightarrow</span><script type=math/tex>\rightarrow</script></span> better predictive accuracy</li> </ul> <h3 id=mathematical-interpretation-of-gradient-descent>Mathematical Interpretation of Gradient Descent<a class=headerlink href=#mathematical-interpretation-of-gradient-descent title="Permanent link">&para;</a></h3> <ul> <li>Model's parameters: <span><span class=MathJax_Preview>\theta \in ℝ^d</span><script type=math/tex>\theta \in ℝ^d</script></span></li> <li>Loss function: <span><span class=MathJax_Preview>J(\theta)</span><script type=math/tex>J(\theta)</script></span></li> <li>Gradient w.r.t. parameters: <span><span class=MathJax_Preview>\nabla J(\theta)</span><script type=math/tex>\nabla J(\theta)</script></span></li> <li>Learning rate: <span><span class=MathJax_Preview>\eta</span><script type=math/tex>\eta</script></span></li> <li>Batch Gradient descent: <span><span class=MathJax_Preview>\theta = \theta - \eta \cdot \nabla J(\theta)</span><script type=math/tex>\theta = \theta - \eta \cdot  \nabla J(\theta)</script></span></li> </ul> <h2 id=optimization-algorithm-1-batch-gradient-descent>Optimization Algorithm 1: Batch Gradient Descent<a class=headerlink href=#optimization-algorithm-1-batch-gradient-descent title="Permanent link">&para;</a></h2> <ul> <li>What we've covered so far: batch gradient descent<ul> <li><span><span class=MathJax_Preview>\theta = \theta - \eta \cdot \nabla J(\theta)</span><script type=math/tex>\theta = \theta - \eta \cdot  \nabla J(\theta)</script></span></li> </ul> </li> <li>Characteristics<ul> <li>Compute the gradient of the lost function w.r.t. parameters for the entire training data, <span><span class=MathJax_Preview>\nabla J(\theta)</span><script type=math/tex>\nabla J(\theta)</script></span> </li> <li>Use this to update our parameters at every iteration</li> </ul> </li> <li>Problems<ul> <li>Unable to fit whole datasets in memory </li> <li>Computationally slow as we attempt to compute a large gradient matrix <span><span class=MathJax_Preview>\rightarrow</span><script type=math/tex>\rightarrow</script></span> first order derivative, <span><span class=MathJax_Preview>\nabla J(\theta)</span><script type=math/tex>\nabla J(\theta)</script></span></li> </ul> </li> <li>Conceptually easy to understand <span><span class=MathJax_Preview>\rightarrow</span><script type=math/tex>\rightarrow</script></span> rarely used</li> </ul> <h2 id=optimization-algorithm-2-stochastic-gradient-descent>Optimization Algorithm 2: Stochastic Gradient Descent<a class=headerlink href=#optimization-algorithm-2-stochastic-gradient-descent title="Permanent link">&para;</a></h2> <ul> <li>Modification of batch gradient descent<ul> <li><span><span class=MathJax_Preview>\theta = \theta - \eta \cdot \nabla J(\theta, x^{i}, y^{i})</span><script type=math/tex>\theta = \theta - \eta \cdot  \nabla J(\theta, x^{i}, y^{i})</script></span></li> </ul> </li> <li>Characteristics<ul> <li>Compute the gradient of the lost function w.r.t. parameters for the <strong>one set of training sample (1 input and 1 label)</strong>, <span><span class=MathJax_Preview>\nabla J(\theta, x^{i}, y^{i})</span><script type=math/tex>\nabla J(\theta, x^{i}, y^{i})</script></span></li> <li>Use this to update our parameters at every iteration</li> </ul> </li> <li>Benefits<ul> <li>Able to fit large datasets</li> <li>Computationally faster <span><span class=MathJax_Preview>\rightarrow</span><script type=math/tex>\rightarrow</script></span> instead gradients w.r.t to the whole training data, we get the gradients w.r.t. training sample</li> </ul> </li> <li>Problems<ul> <li>Updating very frequently <span><span class=MathJax_Preview>\rightarrow</span><script type=math/tex>\rightarrow</script></span> huge variance in parameter updates <span><span class=MathJax_Preview>\rightarrow</span><script type=math/tex>\rightarrow</script></span> may overshoot local minima <ul> <li>Can be solved by carefully decaying your learning rate <span><span class=MathJax_Preview>\rightarrow</span><script type=math/tex>\rightarrow</script></span> take smaller steps in incorporating gradients to improve the parameters</li> </ul> </li> </ul> </li> </ul> <h2 id=optimization-algorithm-3-mini-batch-gradient-descent>Optimization Algorithm 3: Mini-batch Gradient Descent<a class=headerlink href=#optimization-algorithm-3-mini-batch-gradient-descent title="Permanent link">&para;</a></h2> <ul> <li>Combination of batch gradient descent &amp; stochastic gradient descent<ul> <li><span><span class=MathJax_Preview>\theta = \theta - \eta \cdot \nabla J(\theta, x^{i: i+n}, y^{i:i+n})</span><script type=math/tex>\theta = \theta - \eta \cdot  \nabla J(\theta, x^{i: i+n}, y^{i:i+n})</script></span></li> </ul> </li> <li>Characteristics<ul> <li>Compute the gradient of the lost function w.r.t. parameters for <strong>n sets of training sample (n input and n label)</strong>, <span><span class=MathJax_Preview>\nabla J(\theta, x^{i: i+n}, y^{i:i+n})</span><script type=math/tex>\nabla J(\theta, x^{i: i+n}, y^{i:i+n})</script></span></li> <li>Use this to update our parameters at every iteration</li> </ul> </li> <li>Benefits<ul> <li>Able to fit large datasets</li> <li>Computationally faster <span><span class=MathJax_Preview>\rightarrow</span><script type=math/tex>\rightarrow</script></span> instead gradients w.r.t to the whole training data, we get the gradients w.r.t. training sample</li> <li>Lower variance of parameter updates</li> </ul> </li> <li>This is often called SGD in deep learning frameworks .__. </li> </ul> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>torch</span>
<span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
<span class=kn>import</span> <span class=nn>torchvision.transforms</span> <span class=k>as</span> <span class=nn>transforms</span>
<span class=kn>import</span> <span class=nn>torchvision.datasets</span> <span class=k>as</span> <span class=nn>dsets</span>

<span class=c1># Set seed</span>
<span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 1: LOADING DATASET</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=n>train_dataset</span> <span class=o>=</span> <span class=n>dsets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> 
                            <span class=n>train</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> 
                            <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>
                            <span class=n>download</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>test_dataset</span> <span class=o>=</span> <span class=n>dsets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> 
                           <span class=n>train</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> 
                           <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>())</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 2: MAKING DATASET ITERABLE</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=n>batch_size</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>n_iters</span> <span class=o>=</span> <span class=mi>3000</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=n>n_iters</span> <span class=o>/</span> <span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>)</span> <span class=o>/</span> <span class=n>batch_size</span><span class=p>)</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>)</span>

<span class=n>train_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>train_dataset</span><span class=p>,</span> 
                                           <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> 
                                           <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>test_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>test_dataset</span><span class=p>,</span> 
                                          <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> 
                                          <span class=n>shuffle</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 3: CREATE MODEL CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=k>class</span> <span class=nc>FeedforwardNeuralNetModel</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>FeedforwardNeuralNetModel</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
        <span class=c1># Linear function</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>)</span>
        <span class=c1># Non-linearity</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>relu</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>()</span>
        <span class=c1># Linear function (readout)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span>  

    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=c1># Linear function</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
        <span class=c1># Non-linearity</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>out</span><span class=p>)</span>
        <span class=c1># Linear function (readout)</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span><span class=p>(</span><span class=n>out</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>out</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 4: INSTANTIATE MODEL CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>input_dim</span> <span class=o>=</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span>
<span class=n>hidden_dim</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>output_dim</span> <span class=o>=</span> <span class=mi>10</span>

<span class=n>model</span> <span class=o>=</span> <span class=n>FeedforwardNeuralNetModel</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 5: INSTANTIATE LOSS CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>


<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 6: INSTANTIATE OPTIMIZER CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>learning_rate</span> <span class=o>=</span> <span class=mf>0.1</span>

<span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=n>learning_rate</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 7: TRAIN THE MODEL</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=nb>iter</span> <span class=o>=</span> <span class=mi>0</span>
<span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=p>(</span><span class=n>images</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_loader</span><span class=p>):</span>
        <span class=c1># Load images as Variable</span>
        <span class=n>images</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span><span class=p>)</span><span class=o>.</span><span class=n>requires_grad_</span><span class=p>()</span>

        <span class=c1># Clear gradients w.r.t. parameters</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>

        <span class=c1># Forward pass to get output/logits</span>
        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>

        <span class=c1># Calculate Loss: softmax --&gt; cross entropy loss</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>

        <span class=c1># Getting gradients w.r.t. parameters</span>
        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>

        <span class=c1># Updating parameters</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

        <span class=nb>iter</span> <span class=o>+=</span> <span class=mi>1</span>

        <span class=k>if</span> <span class=nb>iter</span> <span class=o>%</span> <span class=mi>500</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
            <span class=c1># Calculate Accuracy         </span>
            <span class=n>correct</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=n>total</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=c1># Iterate through test dataset</span>
            <span class=k>for</span> <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>test_loader</span><span class=p>:</span>
                <span class=c1># Load images to a Torch Variable</span>
                <span class=n>images</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span><span class=p>)</span><span class=o>.</span><span class=n>requires_grad_</span><span class=p>()</span>

                <span class=c1># Forward pass only to get logits/output</span>
                <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>

                <span class=c1># Get predictions from the maximum value</span>
                <span class=n>_</span><span class=p>,</span> <span class=n>predicted</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>outputs</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

                <span class=c1># Total number of labels</span>
                <span class=n>total</span> <span class=o>+=</span> <span class=n>labels</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>

                <span class=c1># Total correct predictions</span>
                <span class=n>correct</span> <span class=o>+=</span> <span class=p>(</span><span class=n>predicted</span> <span class=o>==</span> <span class=n>labels</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

            <span class=n>accuracy</span> <span class=o>=</span> <span class=mi>100</span> <span class=o>*</span> <span class=n>correct</span> <span class=o>/</span> <span class=n>total</span>

            <span class=c1># Print Loss</span>
            <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Iteration: </span><span class=si>{}</span><span class=s1>. Loss: </span><span class=si>{}</span><span class=s1>. Accuracy: </span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=nb>iter</span><span class=p>,</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span> <span class=n>accuracy</span><span class=p>))</span>
</code></pre></div> <div class=codehilite><pre><span></span><code>Iteration: 500. Loss: 0.3440718352794647. Accuracy: 91
Iteration: 1000. Loss: 0.2057694047689438. Accuracy: 93
Iteration: 1500. Loss: 0.2646750807762146. Accuracy: 94
Iteration: 2000. Loss: 0.17563636600971222. Accuracy: 94
Iteration: 2500. Loss: 0.1361844837665558. Accuracy: 95
Iteration: 3000. Loss: 0.11089023947715759. Accuracy: 95
</code></pre></div> <h2 id=optimization-algorithm-4-sgd-momentum>Optimization Algorithm 4: SGD Momentum<a class=headerlink href=#optimization-algorithm-4-sgd-momentum title="Permanent link">&para;</a></h2> <ul> <li>Modification of SGD<ul> <li><span><span class=MathJax_Preview>v_t = \gamma v_{t-1} + \eta \cdot \nabla J(\theta, x^{i: i+n}, y^{i:i+n})</span><script type=math/tex>v_t = \gamma v_{t-1} + \eta \cdot  \nabla J(\theta, x^{i: i+n}, y^{i:i+n})</script></span></li> <li><span><span class=MathJax_Preview>\theta = \theta - v_t</span><script type=math/tex>\theta = \theta - v_t</script></span></li> </ul> </li> <li>Characteristics<ul> <li>Compute the gradient of the lost function w.r.t. parameters for <strong>n sets of training sample (n input and n label)</strong>, <span><span class=MathJax_Preview>\nabla J(\theta, x^{i: i+n}, y^{i:i+n})</span><script type=math/tex>\nabla J(\theta, x^{i: i+n}, y^{i:i+n})</script></span></li> <li>Use this to add to the previous update vector <span><span class=MathJax_Preview>v_{t-1}</span><script type=math/tex>v_{t-1}</script></span></li> <li>Momentum, usually set to <span><span class=MathJax_Preview>\gamma = 0.9</span><script type=math/tex>\gamma = 0.9</script></span></li> <li>Parameters updated with update vector, <span><span class=MathJax_Preview>v_t</span><script type=math/tex>v_t</script></span> that incorporates previous update vector<ul> <li><span><span class=MathJax_Preview>\gamma v_{t}</span><script type=math/tex>\gamma v_{t}</script></span> increases if gradient same sign/direction as <span><span class=MathJax_Preview>v_{t-1}</span><script type=math/tex>v_{t-1}</script></span> <ul> <li>Gives SGD the push when it is going in the right direction (minimizing loss)</li> <li>Accelerated convergence</li> </ul> </li> <li><span><span class=MathJax_Preview>\gamma v_{t}</span><script type=math/tex>\gamma v_{t}</script></span> decreases if gradient different sign/direction as <span><span class=MathJax_Preview>v_{t-1}</span><script type=math/tex>v_{t-1}</script></span><ul> <li>Dampens SGD when it is going in a different direction</li> <li>Lower variation in loss minimization</li> </ul> </li> </ul> </li> </ul> </li> <li>Problems<ul> <li>It might go the wrong direction (higher loss) <span><span class=MathJax_Preview>\rightarrow</span><script type=math/tex>\rightarrow</script></span> continue to be accelerated to the wrong direction (higher loss) </li> </ul> </li> </ul> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>torch</span>
<span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
<span class=kn>import</span> <span class=nn>torchvision.transforms</span> <span class=k>as</span> <span class=nn>transforms</span>
<span class=kn>import</span> <span class=nn>torchvision.datasets</span> <span class=k>as</span> <span class=nn>dsets</span>

<span class=c1># Set seed</span>
<span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 1: LOADING DATASET</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=n>train_dataset</span> <span class=o>=</span> <span class=n>dsets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> 
                            <span class=n>train</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> 
                            <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>
                            <span class=n>download</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>test_dataset</span> <span class=o>=</span> <span class=n>dsets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> 
                           <span class=n>train</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> 
                           <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>())</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 2: MAKING DATASET ITERABLE</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=n>batch_size</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>n_iters</span> <span class=o>=</span> <span class=mi>3000</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=n>n_iters</span> <span class=o>/</span> <span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>)</span> <span class=o>/</span> <span class=n>batch_size</span><span class=p>)</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>)</span>

<span class=n>train_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>train_dataset</span><span class=p>,</span> 
                                           <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> 
                                           <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>test_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>test_dataset</span><span class=p>,</span> 
                                          <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> 
                                          <span class=n>shuffle</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 3: CREATE MODEL CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=k>class</span> <span class=nc>FeedforwardNeuralNetModel</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>FeedforwardNeuralNetModel</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
        <span class=c1># Linear function</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>)</span> 
        <span class=c1># Non-linearity</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>relu</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>()</span>
        <span class=c1># Linear function (readout)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span>  

    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=c1># Linear function</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
        <span class=c1># Non-linearity</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>out</span><span class=p>)</span>
        <span class=c1># Linear function (readout)</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span><span class=p>(</span><span class=n>out</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>out</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 4: INSTANTIATE MODEL CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>input_dim</span> <span class=o>=</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span>
<span class=n>hidden_dim</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>output_dim</span> <span class=o>=</span> <span class=mi>10</span>

<span class=n>model</span> <span class=o>=</span> <span class=n>FeedforwardNeuralNetModel</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 5: INSTANTIATE LOSS CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>


<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 6: INSTANTIATE OPTIMIZER CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>learning_rate</span> <span class=o>=</span> <span class=mf>0.1</span>

<span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=n>learning_rate</span><span class=p>,</span> <span class=n>momentum</span><span class=o>=</span><span class=mf>0.9</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 7: TRAIN THE MODEL</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=nb>iter</span> <span class=o>=</span> <span class=mi>0</span>
<span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=p>(</span><span class=n>images</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_loader</span><span class=p>):</span>
        <span class=c1># Load images as Variable</span>
        <span class=n>images</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span><span class=p>)</span><span class=o>.</span><span class=n>requires_grad_</span><span class=p>()</span>

        <span class=c1># Clear gradients w.r.t. parameters</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>

        <span class=c1># Forward pass to get output/logits</span>
        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>

        <span class=c1># Calculate Loss: softmax --&gt; cross entropy loss</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>

        <span class=c1># Getting gradients w.r.t. parameters</span>
        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>

        <span class=c1># Updating parameters</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

        <span class=nb>iter</span> <span class=o>+=</span> <span class=mi>1</span>

        <span class=k>if</span> <span class=nb>iter</span> <span class=o>%</span> <span class=mi>500</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
            <span class=c1># Calculate Accuracy         </span>
            <span class=n>correct</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=n>total</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=c1># Iterate through test dataset</span>
            <span class=k>for</span> <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>test_loader</span><span class=p>:</span>
                <span class=c1># Load images to a Torch Variable</span>
                <span class=n>images</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span><span class=p>)</span>

                <span class=c1># Forward pass only to get logits/output</span>
                <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>

                <span class=c1># Get predictions from the maximum value</span>
                <span class=n>_</span><span class=p>,</span> <span class=n>predicted</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>outputs</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

                <span class=c1># Total number of labels</span>
                <span class=n>total</span> <span class=o>+=</span> <span class=n>labels</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>

                <span class=c1># Total correct predictions</span>
                <span class=n>correct</span> <span class=o>+=</span> <span class=p>(</span><span class=n>predicted</span> <span class=o>==</span> <span class=n>labels</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

            <span class=n>accuracy</span> <span class=o>=</span> <span class=mi>100</span> <span class=o>*</span> <span class=n>correct</span> <span class=o>/</span> <span class=n>total</span>

            <span class=c1># Print Loss</span>
            <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Iteration: </span><span class=si>{}</span><span class=s1>. Loss: </span><span class=si>{}</span><span class=s1>. Accuracy: </span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=nb>iter</span><span class=p>,</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span> <span class=n>accuracy</span><span class=p>))</span>
</code></pre></div> <div class=codehilite><pre><span></span><code>Iteration: 500. Loss: 0.16120098531246185. Accuracy: 96
Iteration: 1000. Loss: 0.15727552771568298. Accuracy: 96
Iteration: 1500. Loss: 0.1303034871816635. Accuracy: 96
Iteration: 2000. Loss: 0.022178759798407555. Accuracy: 97
Iteration: 2500. Loss: 0.07027597725391388. Accuracy: 97
Iteration: 3000. Loss: 0.02519878000020981. Accuracy: 97
</code></pre></div> <h2 id=optimization-algorithm-4-sgd-nesterov>Optimization Algorithm 4: SGD Nesterov<a class=headerlink href=#optimization-algorithm-4-sgd-nesterov title="Permanent link">&para;</a></h2> <ul> <li>Modification of SGD Momentum <ul> <li><span><span class=MathJax_Preview>v_t = \gamma v_{t-1} + \eta \cdot \nabla J(\theta - \gamma v_{t-1}, x^{i: i+n}, y^{i:i+n})</span><script type=math/tex>v_t = \gamma v_{t-1} + \eta \cdot  \nabla J(\theta - \gamma v_{t-1}, x^{i: i+n}, y^{i:i+n})</script></span></li> <li><span><span class=MathJax_Preview>\theta = \theta - v_t</span><script type=math/tex>\theta = \theta - v_t</script></span></li> </ul> </li> <li>Characteristics<ul> <li>Compute the gradient of the lost function w.r.t. <strong>future approximate parameters</strong> for <strong>n sets of training sample (n input and n label)</strong>, <span><span class=MathJax_Preview>\nabla J(\theta - \gamma v_{t-1}, x^{i: i+n}, y^{i:i+n})</span><script type=math/tex>\nabla J(\theta - \gamma v_{t-1}, x^{i: i+n}, y^{i:i+n})</script></span><ul> <li>Use this to add to the previous update vector <span><span class=MathJax_Preview>v_{t-1}</span><script type=math/tex>v_{t-1}</script></span></li> <li>Momentum, usually set to <span><span class=MathJax_Preview>\gamma = 0.9</span><script type=math/tex>\gamma = 0.9</script></span></li> </ul> </li> <li>Gradients w.r.t. future approximate parameters <span><span class=MathJax_Preview>\rightarrow</span><script type=math/tex>\rightarrow</script></span> sense of where we will be <span><span class=MathJax_Preview>\rightarrow</span><script type=math/tex>\rightarrow</script></span> anticipate if we are going in the wrong direction in the next step <span><span class=MathJax_Preview>\rightarrow</span><script type=math/tex>\rightarrow</script></span> slow down accordingly</li> </ul> </li> </ul> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>torch</span>
<span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
<span class=kn>import</span> <span class=nn>torchvision.transforms</span> <span class=k>as</span> <span class=nn>transforms</span>
<span class=kn>import</span> <span class=nn>torchvision.datasets</span> <span class=k>as</span> <span class=nn>dsets</span>

<span class=c1># Set seed</span>
<span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 1: LOADING DATASET</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=n>train_dataset</span> <span class=o>=</span> <span class=n>dsets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> 
                            <span class=n>train</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> 
                            <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>
                            <span class=n>download</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>test_dataset</span> <span class=o>=</span> <span class=n>dsets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> 
                           <span class=n>train</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> 
                           <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>())</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 2: MAKING DATASET ITERABLE</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=n>batch_size</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>n_iters</span> <span class=o>=</span> <span class=mi>3000</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=n>n_iters</span> <span class=o>/</span> <span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>)</span> <span class=o>/</span> <span class=n>batch_size</span><span class=p>)</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>)</span>

<span class=n>train_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>train_dataset</span><span class=p>,</span> 
                                           <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> 
                                           <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>test_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>test_dataset</span><span class=p>,</span> 
                                          <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> 
                                          <span class=n>shuffle</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 3: CREATE MODEL CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=k>class</span> <span class=nc>FeedforwardNeuralNetModel</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>FeedforwardNeuralNetModel</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
        <span class=c1># Linear function</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>)</span> 
        <span class=c1># Non-linearity</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>relu</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>()</span>
        <span class=c1># Linear function (readout)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span>  

    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=c1># Linear function</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
        <span class=c1># Non-linearity</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>out</span><span class=p>)</span>
        <span class=c1># Linear function (readout)</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span><span class=p>(</span><span class=n>out</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>out</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 4: INSTANTIATE MODEL CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>input_dim</span> <span class=o>=</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span>
<span class=n>hidden_dim</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>output_dim</span> <span class=o>=</span> <span class=mi>10</span>

<span class=n>model</span> <span class=o>=</span> <span class=n>FeedforwardNeuralNetModel</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 5: INSTANTIATE LOSS CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>


<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 6: INSTANTIATE OPTIMIZER CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>learning_rate</span> <span class=o>=</span> <span class=mf>0.1</span>

<span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=n>learning_rate</span><span class=p>,</span> <span class=n>momentum</span><span class=o>=</span><span class=mf>0.9</span><span class=p>,</span> <span class=n>nesterov</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 7: TRAIN THE MODEL</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=nb>iter</span> <span class=o>=</span> <span class=mi>0</span>
<span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=p>(</span><span class=n>images</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_loader</span><span class=p>):</span>
        <span class=c1># Load images as Variable</span>
        <span class=n>images</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span><span class=p>)</span><span class=o>.</span><span class=n>requires_grad_</span><span class=p>()</span>

        <span class=c1># Clear gradients w.r.t. parameters</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>

        <span class=c1># Forward pass to get output/logits</span>
        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>

        <span class=c1># Calculate Loss: softmax --&gt; cross entropy loss</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>

        <span class=c1># Getting gradients w.r.t. parameters</span>
        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>

        <span class=c1># Updating parameters</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

        <span class=nb>iter</span> <span class=o>+=</span> <span class=mi>1</span>

        <span class=k>if</span> <span class=nb>iter</span> <span class=o>%</span> <span class=mi>500</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
            <span class=c1># Calculate Accuracy         </span>
            <span class=n>correct</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=n>total</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=c1># Iterate through test dataset</span>
            <span class=k>for</span> <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>test_loader</span><span class=p>:</span>
                <span class=c1># Load images to a Torch Variable</span>
                <span class=n>images</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span><span class=p>)</span>

                <span class=c1># Forward pass only to get logits/output</span>
                <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>

                <span class=c1># Get predictions from the maximum value</span>
                <span class=n>_</span><span class=p>,</span> <span class=n>predicted</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>outputs</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

                <span class=c1># Total number of labels</span>
                <span class=n>total</span> <span class=o>+=</span> <span class=n>labels</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>

                <span class=c1># Total correct predictions</span>
                <span class=n>correct</span> <span class=o>+=</span> <span class=p>(</span><span class=n>predicted</span> <span class=o>==</span> <span class=n>labels</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

            <span class=n>accuracy</span> <span class=o>=</span> <span class=mi>100</span> <span class=o>*</span> <span class=n>correct</span> <span class=o>/</span> <span class=n>total</span>

            <span class=c1># Print Loss</span>
            <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Iteration: </span><span class=si>{}</span><span class=s1>. Loss: </span><span class=si>{}</span><span class=s1>. Accuracy: </span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=nb>iter</span><span class=p>,</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span> <span class=n>accuracy</span><span class=p>))</span>
</code></pre></div> <div class=codehilite><pre><span></span><code>Iteration: 500. Loss: 0.15292978286743164. Accuracy: 96
Iteration: 1000. Loss: 0.11253029108047485. Accuracy: 96
Iteration: 1500. Loss: 0.11986596137285233. Accuracy: 96
Iteration: 2000. Loss: 0.016192540526390076. Accuracy: 97
Iteration: 2500. Loss: 0.06744947284460068. Accuracy: 97
Iteration: 3000. Loss: 0.03692319989204407. Accuracy: 97
</code></pre></div> <h2 id=optimization-algorithm-4-adam>Optimization Algorithm 4: Adam<a class=headerlink href=#optimization-algorithm-4-adam title="Permanent link">&para;</a></h2> <ul> <li>Adaptive Learning Rates<ul> <li><span><span class=MathJax_Preview>m_t = \beta_1 m_{t-1} + (1 - \beta_1)g_t</span><script type=math/tex>m_t = \beta_1 m_{t-1} + (1 - \beta_1)g_t</script></span><ul> <li>Keeping track of decaying gradient</li> <li>Estimate of the mean of gradients</li> </ul> </li> <li><span><span class=MathJax_Preview>v_t = \beta_2 v_{t-1} + (1 - \beta_2)g_t^2</span><script type=math/tex>v_t = \beta_2 v_{t-1} + (1 - \beta_2)g_t^2</script></span><ul> <li>Keeping track of decaying squared gradient </li> <li>Estimate of the variance of gradients</li> </ul> </li> <li>When <span><span class=MathJax_Preview>m_t, v_t</span><script type=math/tex>m_t, v_t</script></span> initializes as 0, <span><span class=MathJax_Preview>m_t, v_t \rightarrow 0</span><script type=math/tex>m_t, v_t \rightarrow 0</script></span> initially when decay rates small, <span><span class=MathJax_Preview>\beta_1, \beta_2 \rightarrow 1</span><script type=math/tex>\beta_1, \beta_2 \rightarrow 1</script></span> <ul> <li>Need to correct this with:</li> <li><span><span class=MathJax_Preview>\hat m_t = \frac{m_t}{1- \beta_1}</span><script type=math/tex>\hat m_t = \frac{m_t}{1- \beta_1}</script></span></li> <li><span><span class=MathJax_Preview>\hat v_t = \frac{v_t}{1- \beta_2}</span><script type=math/tex>\hat v_t = \frac{v_t}{1- \beta_2}</script></span></li> </ul> </li> <li><span><span class=MathJax_Preview>\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\hat v_t} + \epsilon}\hat m_t</span><script type=math/tex>\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\hat v_t} + \epsilon}\hat m_t</script></span></li> <li>Default recommended values<ul> <li><span><span class=MathJax_Preview>\beta_1 = 0.9</span><script type=math/tex>\beta_1 = 0.9</script></span></li> <li><span><span class=MathJax_Preview>\beta_2 = 0.999</span><script type=math/tex>\beta_2 = 0.999</script></span></li> <li><span><span class=MathJax_Preview>\epsilon = 10^{-8}</span><script type=math/tex>\epsilon = 10^{-8}</script></span></li> </ul> </li> </ul> </li> <li>Instead of learning rate <span><span class=MathJax_Preview>\rightarrow</span><script type=math/tex>\rightarrow</script></span> equations account for estimates of mean/variance of gradients to determine the next learning rate</li> </ul> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>torch</span>
<span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
<span class=kn>import</span> <span class=nn>torchvision.transforms</span> <span class=k>as</span> <span class=nn>transforms</span>
<span class=kn>import</span> <span class=nn>torchvision.datasets</span> <span class=k>as</span> <span class=nn>dsets</span>

<span class=c1># Set seed</span>
<span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 1: LOADING DATASET</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=n>train_dataset</span> <span class=o>=</span> <span class=n>dsets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> 
                            <span class=n>train</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> 
                            <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>
                            <span class=n>download</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>test_dataset</span> <span class=o>=</span> <span class=n>dsets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> 
                           <span class=n>train</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> 
                           <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>())</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 2: MAKING DATASET ITERABLE</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=n>batch_size</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>n_iters</span> <span class=o>=</span> <span class=mi>3000</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=n>n_iters</span> <span class=o>/</span> <span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>)</span> <span class=o>/</span> <span class=n>batch_size</span><span class=p>)</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>)</span>

<span class=n>train_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>train_dataset</span><span class=p>,</span> 
                                           <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> 
                                           <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>test_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>test_dataset</span><span class=p>,</span> 
                                          <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> 
                                          <span class=n>shuffle</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 3: CREATE MODEL CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=k>class</span> <span class=nc>FeedforwardNeuralNetModel</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>FeedforwardNeuralNetModel</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
        <span class=c1># Linear function</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>)</span> 
        <span class=c1># Non-linearity</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>relu</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>()</span>
        <span class=c1># Linear function (readout)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span>  

    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=c1># Linear function</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
        <span class=c1># Non-linearity</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>out</span><span class=p>)</span>
        <span class=c1># Linear function (readout)</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span><span class=p>(</span><span class=n>out</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>out</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 4: INSTANTIATE MODEL CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>input_dim</span> <span class=o>=</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span>
<span class=n>hidden_dim</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>output_dim</span> <span class=o>=</span> <span class=mi>10</span>

<span class=n>model</span> <span class=o>=</span> <span class=n>FeedforwardNeuralNetModel</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 5: INSTANTIATE LOSS CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>


<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 6: INSTANTIATE OPTIMIZER CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=c1># learning_rate = 0.001</span>

<span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 7: TRAIN THE MODEL</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=nb>iter</span> <span class=o>=</span> <span class=mi>0</span>
<span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=p>(</span><span class=n>images</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_loader</span><span class=p>):</span>
        <span class=c1># Load images as Variable</span>
        <span class=n>images</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span><span class=p>)</span><span class=o>.</span><span class=n>requires_grad_</span><span class=p>()</span>

        <span class=c1># Clear gradients w.r.t. parameters</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>

        <span class=c1># Forward pass to get output/logits</span>
        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>

        <span class=c1># Calculate Loss: softmax --&gt; cross entropy loss</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>

        <span class=c1># Getting gradients w.r.t. parameters</span>
        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>

        <span class=c1># Updating parameters</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

        <span class=nb>iter</span> <span class=o>+=</span> <span class=mi>1</span>

        <span class=k>if</span> <span class=nb>iter</span> <span class=o>%</span> <span class=mi>500</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
            <span class=c1># Calculate Accuracy         </span>
            <span class=n>correct</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=n>total</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=c1># Iterate through test dataset</span>
            <span class=k>for</span> <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>test_loader</span><span class=p>:</span>
                <span class=c1># Load images to a Torch Variable</span>
                <span class=n>images</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span><span class=p>)</span>

                <span class=c1># Forward pass only to get logits/output</span>
                <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>

                <span class=c1># Get predictions from the maximum value</span>
                <span class=n>_</span><span class=p>,</span> <span class=n>predicted</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>outputs</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

                <span class=c1># Total number of labels</span>
                <span class=n>total</span> <span class=o>+=</span> <span class=n>labels</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>

                <span class=c1># Total correct predictions</span>
                <span class=n>correct</span> <span class=o>+=</span> <span class=p>(</span><span class=n>predicted</span> <span class=o>==</span> <span class=n>labels</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

            <span class=n>accuracy</span> <span class=o>=</span> <span class=mi>100</span> <span class=o>*</span> <span class=n>correct</span> <span class=o>/</span> <span class=n>total</span>

            <span class=c1># Print Loss</span>
            <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Iteration: </span><span class=si>{}</span><span class=s1>. Loss: </span><span class=si>{}</span><span class=s1>. Accuracy: </span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=nb>iter</span><span class=p>,</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span> <span class=n>accuracy</span><span class=p>))</span>
</code></pre></div> <div class=codehilite><pre><span></span><code>Iteration: 500. Loss: 0.2703690826892853. Accuracy: 93
Iteration: 1000. Loss: 0.15547044575214386. Accuracy: 95
Iteration: 1500. Loss: 0.17266806960105896. Accuracy: 95
Iteration: 2000. Loss: 0.0865858644247055. Accuracy: 96
Iteration: 2500. Loss: 0.07156120240688324. Accuracy: 96
Iteration: 3000. Loss: 0.04664849117398262. Accuracy: 97
</code></pre></div> <h2 id=other-adaptive-algorithms>Other Adaptive Algorithms<a class=headerlink href=#other-adaptive-algorithms title="Permanent link">&para;</a></h2> <ul> <li>Other adaptive algorithms (like Adam, adapting learning rates)<ul> <li>Adagrad</li> <li>Adadelta</li> <li>Adamax</li> <li>RMSProp</li> </ul> </li> </ul> <h2 id=optimization-algorithm-5-adagrad>Optimization Algorithm 5: Adagrad<a class=headerlink href=#optimization-algorithm-5-adagrad title="Permanent link">&para;</a></h2> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>torch</span>
<span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
<span class=kn>import</span> <span class=nn>torchvision.transforms</span> <span class=k>as</span> <span class=nn>transforms</span>
<span class=kn>import</span> <span class=nn>torchvision.datasets</span> <span class=k>as</span> <span class=nn>dsets</span>

<span class=c1># Set seed</span>
<span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 1: LOADING DATASET</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=n>train_dataset</span> <span class=o>=</span> <span class=n>dsets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> 
                            <span class=n>train</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> 
                            <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>
                            <span class=n>download</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>test_dataset</span> <span class=o>=</span> <span class=n>dsets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> 
                           <span class=n>train</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> 
                           <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>())</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 2: MAKING DATASET ITERABLE</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=n>batch_size</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>n_iters</span> <span class=o>=</span> <span class=mi>3000</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=n>n_iters</span> <span class=o>/</span> <span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>)</span> <span class=o>/</span> <span class=n>batch_size</span><span class=p>)</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>)</span>

<span class=n>train_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>train_dataset</span><span class=p>,</span> 
                                           <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> 
                                           <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>test_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>test_dataset</span><span class=p>,</span> 
                                          <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> 
                                          <span class=n>shuffle</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 3: CREATE MODEL CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=k>class</span> <span class=nc>FeedforwardNeuralNetModel</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>FeedforwardNeuralNetModel</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
        <span class=c1># Linear function</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>)</span> 
        <span class=c1># Non-linearity</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>relu</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>()</span>
        <span class=c1># Linear function (readout)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span>  

    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=c1># Linear function</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
        <span class=c1># Non-linearity</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>out</span><span class=p>)</span>
        <span class=c1># Linear function (readout)</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span><span class=p>(</span><span class=n>out</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>out</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 4: INSTANTIATE MODEL CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>input_dim</span> <span class=o>=</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span>
<span class=n>hidden_dim</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>output_dim</span> <span class=o>=</span> <span class=mi>10</span>

<span class=n>model</span> <span class=o>=</span> <span class=n>FeedforwardNeuralNetModel</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 5: INSTANTIATE LOSS CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>


<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 6: INSTANTIATE OPTIMIZER CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=c1># learning_rate = 0.001</span>

<span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>Adagrad</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 7: TRAIN THE MODEL</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=nb>iter</span> <span class=o>=</span> <span class=mi>0</span>
<span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=p>(</span><span class=n>images</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_loader</span><span class=p>):</span>
        <span class=c1># Load images as Variable</span>
        <span class=n>images</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span><span class=p>)</span><span class=o>.</span><span class=n>requires_grad_</span><span class=p>()</span>

        <span class=c1># Clear gradients w.r.t. parameters</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>

        <span class=c1># Forward pass to get output/logits</span>
        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>

        <span class=c1># Calculate Loss: softmax --&gt; cross entropy loss</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>

        <span class=c1># Getting gradients w.r.t. parameters</span>
        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>

        <span class=c1># Updating parameters</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

        <span class=nb>iter</span> <span class=o>+=</span> <span class=mi>1</span>

        <span class=k>if</span> <span class=nb>iter</span> <span class=o>%</span> <span class=mi>500</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
            <span class=c1># Calculate Accuracy         </span>
            <span class=n>correct</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=n>total</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=c1># Iterate through test dataset</span>
            <span class=k>for</span> <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>test_loader</span><span class=p>:</span>
                <span class=c1># Load images to a Torch Variable</span>
                <span class=n>images</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span><span class=p>)</span>

                <span class=c1># Forward pass only to get logits/output</span>
                <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>

                <span class=c1># Get predictions from the maximum value</span>
                <span class=n>_</span><span class=p>,</span> <span class=n>predicted</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>outputs</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

                <span class=c1># Total number of labels</span>
                <span class=n>total</span> <span class=o>+=</span> <span class=n>labels</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>

                <span class=c1># Total correct predictions</span>
                <span class=n>correct</span> <span class=o>+=</span> <span class=p>(</span><span class=n>predicted</span> <span class=o>==</span> <span class=n>labels</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

            <span class=n>accuracy</span> <span class=o>=</span> <span class=mi>100</span> <span class=o>*</span> <span class=n>correct</span> <span class=o>/</span> <span class=n>total</span>

            <span class=c1># Print Loss</span>
            <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Iteration: </span><span class=si>{}</span><span class=s1>. Loss: </span><span class=si>{}</span><span class=s1>. Accuracy: </span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=nb>iter</span><span class=p>,</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span> <span class=n>accuracy</span><span class=p>))</span>
</code></pre></div> <div class=codehilite><pre><span></span><code>Iteration: 500. Loss: 0.2757369875907898. Accuracy: 92
Iteration: 1000. Loss: 0.1992958039045334. Accuracy: 93
Iteration: 1500. Loss: 0.2227272093296051. Accuracy: 94
Iteration: 2000. Loss: 0.18628711998462677. Accuracy: 94
Iteration: 2500. Loss: 0.1470586657524109. Accuracy: 95
Iteration: 3000. Loss: 0.11748368293046951. Accuracy: 95
</code></pre></div> <h2 id=optimization-algorithm-6-adadelta>Optimization Algorithm 6: Adadelta<a class=headerlink href=#optimization-algorithm-6-adadelta title="Permanent link">&para;</a></h2> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>torch</span>
<span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
<span class=kn>import</span> <span class=nn>torchvision.transforms</span> <span class=k>as</span> <span class=nn>transforms</span>
<span class=kn>import</span> <span class=nn>torchvision.datasets</span> <span class=k>as</span> <span class=nn>dsets</span>

<span class=c1># Set seed</span>
<span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 1: LOADING DATASET</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=n>train_dataset</span> <span class=o>=</span> <span class=n>dsets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> 
                            <span class=n>train</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> 
                            <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>
                            <span class=n>download</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>test_dataset</span> <span class=o>=</span> <span class=n>dsets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> 
                           <span class=n>train</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> 
                           <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>())</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 2: MAKING DATASET ITERABLE</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=n>batch_size</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>n_iters</span> <span class=o>=</span> <span class=mi>3000</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=n>n_iters</span> <span class=o>/</span> <span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>)</span> <span class=o>/</span> <span class=n>batch_size</span><span class=p>)</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>)</span>

<span class=n>train_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>train_dataset</span><span class=p>,</span> 
                                           <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> 
                                           <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>test_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>test_dataset</span><span class=p>,</span> 
                                          <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> 
                                          <span class=n>shuffle</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 3: CREATE MODEL CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=k>class</span> <span class=nc>FeedforwardNeuralNetModel</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>FeedforwardNeuralNetModel</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
        <span class=c1># Linear function</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>)</span> 
        <span class=c1># Non-linearity</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>relu</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>()</span>
        <span class=c1># Linear function (readout)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span>  

    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=c1># Linear function</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
        <span class=c1># Non-linearity</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>out</span><span class=p>)</span>
        <span class=c1># Linear function (readout)</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span><span class=p>(</span><span class=n>out</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>out</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 4: INSTANTIATE MODEL CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>input_dim</span> <span class=o>=</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span>
<span class=n>hidden_dim</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>output_dim</span> <span class=o>=</span> <span class=mi>10</span>

<span class=n>model</span> <span class=o>=</span> <span class=n>FeedforwardNeuralNetModel</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 5: INSTANTIATE LOSS CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>


<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 6: INSTANTIATE OPTIMIZER CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=c1># learning_rate = 0.001</span>

<span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>Adadelta</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 7: TRAIN THE MODEL</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=nb>iter</span> <span class=o>=</span> <span class=mi>0</span>
<span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=p>(</span><span class=n>images</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_loader</span><span class=p>):</span>
        <span class=c1># Load images as Variable</span>
        <span class=n>images</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span><span class=p>)</span><span class=o>.</span><span class=n>requires_grad_</span><span class=p>()</span>

        <span class=c1># Clear gradients w.r.t. parameters</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>

        <span class=c1># Forward pass to get output/logits</span>
        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>

        <span class=c1># Calculate Loss: softmax --&gt; cross entropy loss</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>

        <span class=c1># Getting gradients w.r.t. parameters</span>
        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>

        <span class=c1># Updating parameters</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

        <span class=nb>iter</span> <span class=o>+=</span> <span class=mi>1</span>

        <span class=k>if</span> <span class=nb>iter</span> <span class=o>%</span> <span class=mi>500</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
            <span class=c1># Calculate Accuracy         </span>
            <span class=n>correct</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=n>total</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=c1># Iterate through test dataset</span>
            <span class=k>for</span> <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>test_loader</span><span class=p>:</span>
                <span class=c1># Load images to a Torch Variable</span>
                <span class=n>images</span> <span class=o>=</span> <span class=n>Variable</span><span class=p>(</span><span class=n>images</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span><span class=p>))</span>

                <span class=c1># Forward pass only to get logits/output</span>
                <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>

                <span class=c1># Get predictions from the maximum value</span>
                <span class=n>_</span><span class=p>,</span> <span class=n>predicted</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>outputs</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

                <span class=c1># Total number of labels</span>
                <span class=n>total</span> <span class=o>+=</span> <span class=n>labels</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>

                <span class=c1># Total correct predictions</span>
                <span class=n>correct</span> <span class=o>+=</span> <span class=p>(</span><span class=n>predicted</span> <span class=o>==</span> <span class=n>labels</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

            <span class=n>accuracy</span> <span class=o>=</span> <span class=mi>100</span> <span class=o>*</span> <span class=n>correct</span> <span class=o>/</span> <span class=n>total</span>

            <span class=c1># Print Loss</span>
            <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Iteration: </span><span class=si>{}</span><span class=s1>. Loss: </span><span class=si>{}</span><span class=s1>. Accuracy: </span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=nb>iter</span><span class=p>,</span> <span class=n>loss</span><span class=o>.</span><span class=n>data</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>accuracy</span><span class=p>))</span>
</code></pre></div> <div class=codehilite><pre><span></span><code>Iteration: 500. Loss: 0.26303035020828247. Accuracy: 93.95
Iteration: 1000. Loss: 0.08731874823570251. Accuracy: 95.83
Iteration: 1500. Loss: 0.11502093076705933. Accuracy: 96.87
Iteration: 2000. Loss: 0.03550947830080986. Accuracy: 97.12
Iteration: 2500. Loss: 0.042649827897548676. Accuracy: 97.54
Iteration: 3000. Loss: 0.03061559610068798. Accuracy: 97.45
</code></pre></div> <h2 id=optimization-algorithm-6-adamax>Optimization Algorithm 6: Adamax<a class=headerlink href=#optimization-algorithm-6-adamax title="Permanent link">&para;</a></h2> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>torch</span>
<span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
<span class=kn>import</span> <span class=nn>torchvision.transforms</span> <span class=k>as</span> <span class=nn>transforms</span>
<span class=kn>import</span> <span class=nn>torchvision.datasets</span> <span class=k>as</span> <span class=nn>dsets</span>

<span class=c1># Set seed</span>
<span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 1: LOADING DATASET</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=n>train_dataset</span> <span class=o>=</span> <span class=n>dsets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> 
                            <span class=n>train</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> 
                            <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>
                            <span class=n>download</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>test_dataset</span> <span class=o>=</span> <span class=n>dsets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> 
                           <span class=n>train</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> 
                           <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>())</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 2: MAKING DATASET ITERABLE</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=n>batch_size</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>n_iters</span> <span class=o>=</span> <span class=mi>3000</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=n>n_iters</span> <span class=o>/</span> <span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>)</span> <span class=o>/</span> <span class=n>batch_size</span><span class=p>)</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>)</span>

<span class=n>train_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>train_dataset</span><span class=p>,</span> 
                                           <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> 
                                           <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>test_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>test_dataset</span><span class=p>,</span> 
                                          <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> 
                                          <span class=n>shuffle</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 3: CREATE MODEL CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=k>class</span> <span class=nc>FeedforwardNeuralNetModel</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>FeedforwardNeuralNetModel</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
        <span class=c1># Linear function</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>)</span> 
        <span class=c1># Non-linearity</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>relu</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>()</span>
        <span class=c1># Linear function (readout)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span>  

    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=c1># Linear function</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
        <span class=c1># Non-linearity</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>out</span><span class=p>)</span>
        <span class=c1># Linear function (readout)</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span><span class=p>(</span><span class=n>out</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>out</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 4: INSTANTIATE MODEL CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>input_dim</span> <span class=o>=</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span>
<span class=n>hidden_dim</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>output_dim</span> <span class=o>=</span> <span class=mi>10</span>

<span class=n>model</span> <span class=o>=</span> <span class=n>FeedforwardNeuralNetModel</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 5: INSTANTIATE LOSS CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>


<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 6: INSTANTIATE OPTIMIZER CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=c1># learning_rate = 0.001</span>

<span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>Adamax</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 7: TRAIN THE MODEL</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=nb>iter</span> <span class=o>=</span> <span class=mi>0</span>
<span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=p>(</span><span class=n>images</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_loader</span><span class=p>):</span>
        <span class=c1># Load images as Variable</span>
        <span class=n>images</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span><span class=p>)</span><span class=o>.</span><span class=n>requires_grad_</span><span class=p>()</span>

        <span class=c1># Clear gradients w.r.t. parameters</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>

        <span class=c1># Forward pass to get output/logits</span>
        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>

        <span class=c1># Calculate Loss: softmax --&gt; cross entropy loss</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>

        <span class=c1># Getting gradients w.r.t. parameters</span>
        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>

        <span class=c1># Updating parameters</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

        <span class=nb>iter</span> <span class=o>+=</span> <span class=mi>1</span>

        <span class=k>if</span> <span class=nb>iter</span> <span class=o>%</span> <span class=mi>500</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
            <span class=c1># Calculate Accuracy         </span>
            <span class=n>correct</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=n>total</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=c1># Iterate through test dataset</span>
            <span class=k>for</span> <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>test_loader</span><span class=p>:</span>
                <span class=c1># Load images to a Torch Variable</span>
                <span class=n>images</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span><span class=p>)</span>

                <span class=c1># Forward pass only to get logits/output</span>
                <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>

                <span class=c1># Get predictions from the maximum value</span>
                <span class=n>_</span><span class=p>,</span> <span class=n>predicted</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>outputs</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

                <span class=c1># Total number of labels</span>
                <span class=n>total</span> <span class=o>+=</span> <span class=n>labels</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>

                <span class=c1># Total correct predictions</span>
                <span class=n>correct</span> <span class=o>+=</span> <span class=p>(</span><span class=n>predicted</span> <span class=o>==</span> <span class=n>labels</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

            <span class=n>accuracy</span> <span class=o>=</span> <span class=mi>100</span> <span class=o>*</span> <span class=n>correct</span> <span class=o>/</span> <span class=n>total</span>

            <span class=c1># Print Loss</span>
            <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Iteration: </span><span class=si>{}</span><span class=s1>. Loss: </span><span class=si>{}</span><span class=s1>. Accuracy: </span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=nb>iter</span><span class=p>,</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span> <span class=n>accuracy</span><span class=p>))</span>
</code></pre></div> <div class=codehilite><pre><span></span><code>Iteration: 500. Loss: 0.29930350184440613. Accuracy: 92
Iteration: 1000. Loss: 0.18749120831489563. Accuracy: 93
Iteration: 1500. Loss: 0.21887679398059845. Accuracy: 95
Iteration: 2000. Loss: 0.14390651881694794. Accuracy: 95
Iteration: 2500. Loss: 0.10771607607603073. Accuracy: 96
Iteration: 3000. Loss: 0.0839928686618805. Accuracy: 96
</code></pre></div> <h2 id=optimization-algorithm-7-rmsprop>Optimization Algorithm 7: RMSProp<a class=headerlink href=#optimization-algorithm-7-rmsprop title="Permanent link">&para;</a></h2> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>torch</span>
<span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
<span class=kn>import</span> <span class=nn>torchvision.transforms</span> <span class=k>as</span> <span class=nn>transforms</span>
<span class=kn>import</span> <span class=nn>torchvision.datasets</span> <span class=k>as</span> <span class=nn>dsets</span>

<span class=c1># Set seed</span>
<span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 1: LOADING DATASET</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=n>train_dataset</span> <span class=o>=</span> <span class=n>dsets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> 
                            <span class=n>train</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> 
                            <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>
                            <span class=n>download</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>test_dataset</span> <span class=o>=</span> <span class=n>dsets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> 
                           <span class=n>train</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> 
                           <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>())</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 2: MAKING DATASET ITERABLE</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=n>batch_size</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>n_iters</span> <span class=o>=</span> <span class=mi>3000</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=n>n_iters</span> <span class=o>/</span> <span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>)</span> <span class=o>/</span> <span class=n>batch_size</span><span class=p>)</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>)</span>

<span class=n>train_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>train_dataset</span><span class=p>,</span> 
                                           <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> 
                                           <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>test_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>test_dataset</span><span class=p>,</span> 
                                          <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> 
                                          <span class=n>shuffle</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 3: CREATE MODEL CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=k>class</span> <span class=nc>FeedforwardNeuralNetModel</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>FeedforwardNeuralNetModel</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
        <span class=c1># Linear function</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>)</span> 
        <span class=c1># Non-linearity</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>relu</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>()</span>
        <span class=c1># Linear function (readout)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span>  

    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=c1># Linear function</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
        <span class=c1># Non-linearity</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>out</span><span class=p>)</span>
        <span class=c1># Linear function (readout)</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span><span class=p>(</span><span class=n>out</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>out</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 4: INSTANTIATE MODEL CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>input_dim</span> <span class=o>=</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span>
<span class=n>hidden_dim</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>output_dim</span> <span class=o>=</span> <span class=mi>10</span>

<span class=n>model</span> <span class=o>=</span> <span class=n>FeedforwardNeuralNetModel</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 5: INSTANTIATE LOSS CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>


<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 6: INSTANTIATE OPTIMIZER CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=c1># learning_rate = 0.001</span>

<span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>RMSprop</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 7: TRAIN THE MODEL</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=nb>iter</span> <span class=o>=</span> <span class=mi>0</span>
<span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=p>(</span><span class=n>images</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_loader</span><span class=p>):</span>
        <span class=c1># Load images as Variable</span>
        <span class=n>images</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span><span class=p>)</span><span class=o>.</span><span class=n>requires_grad_</span><span class=p>()</span>

        <span class=c1># Clear gradients w.r.t. parameters</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>

        <span class=c1># Forward pass to get output/logits</span>
        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>

        <span class=c1># Calculate Loss: softmax --&gt; cross entropy loss</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>

        <span class=c1># Getting gradients w.r.t. parameters</span>
        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>

        <span class=c1># Updating parameters</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

        <span class=nb>iter</span> <span class=o>+=</span> <span class=mi>1</span>

        <span class=k>if</span> <span class=nb>iter</span> <span class=o>%</span> <span class=mi>500</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
            <span class=c1># Calculate Accuracy         </span>
            <span class=n>correct</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=n>total</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=c1># Iterate through test dataset</span>
            <span class=k>for</span> <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>test_loader</span><span class=p>:</span>
                <span class=c1># Load images to a Torch Variable</span>
                <span class=n>images</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span><span class=p>)</span><span class=o>.</span><span class=n>requires_grad_</span><span class=p>()</span>

                <span class=c1># Forward pass only to get logits/output</span>
                <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>

                <span class=c1># Get predictions from the maximum value</span>
                <span class=n>_</span><span class=p>,</span> <span class=n>predicted</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>outputs</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

                <span class=c1># Total number of labels</span>
                <span class=n>total</span> <span class=o>+=</span> <span class=n>labels</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>

                <span class=c1># Total correct predictions</span>
                <span class=n>correct</span> <span class=o>+=</span> <span class=p>(</span><span class=n>predicted</span> <span class=o>==</span> <span class=n>labels</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

            <span class=n>accuracy</span> <span class=o>=</span> <span class=mi>100</span> <span class=o>*</span> <span class=n>correct</span> <span class=o>/</span> <span class=n>total</span>

            <span class=c1># Print Loss</span>
            <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Iteration: </span><span class=si>{}</span><span class=s1>. Loss: </span><span class=si>{}</span><span class=s1>. Accuracy: </span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=nb>iter</span><span class=p>,</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span> <span class=n>accuracy</span><span class=p>))</span>
</code></pre></div> <div class=codehilite><pre><span></span><code>Iteration: 500. Loss: 0.25550296902656555. Accuracy: 95
Iteration: 1000. Loss: 0.17357593774795532. Accuracy: 93
Iteration: 1500. Loss: 0.10597744584083557. Accuracy: 96
Iteration: 2000. Loss: 0.03807783126831055. Accuracy: 96
Iteration: 2500. Loss: 0.10654022544622421. Accuracy: 96
Iteration: 3000. Loss: 0.05745543912053108. Accuracy: 96
</code></pre></div> <h2 id=summary-of-optimization-algorithms-performance>Summary of Optimization Algorithms Performance<a class=headerlink href=#summary-of-optimization-algorithms-performance title="Permanent link">&para;</a></h2> <ul> <li>SGD: 95.78%</li> <li><strong>SGD Momentum: 97.69%</strong></li> <li><strong>SGD Nesterov: 97.58%</strong></li> <li><strong>Adam: 97.20%</strong></li> <li>Adagrad: 95.51%</li> <li><strong>Adadelta: 97.45%</strong></li> <li>Adamax: 96.58%</li> <li><strong>RMSProp: 97.1%</strong></li> </ul> <div class="admonition warning"> <p class=admonition-title>Performance is not definitive here</p> <p>I have used a seed to ensure you can reproduce results here. However, if you change the seed number you would realize that the performance of these optimization algorithms would change. A solution is to run each optimization on many seeds and get the average performance. Then you can compare the mean performance across all optimization algorithms. </p> <p>There are a lot of other factors like how Adam and SGD Momentum may have different ideal starting learning rates and require different learning rate scheduling. But off the hand, SGD and Adam are very robust optimization algorithms that you can rely on. </p> <p>Subsequently, we will look into more advanced optimization algorithms that are based mainly on SGD and Adam.</p> </div> <h2 id=simple-suggestions>Simple Suggestions<a class=headerlink href=#simple-suggestions title="Permanent link">&para;</a></h2> <ul> <li>Momentum/Nesterov<ul> <li>Powerful if we control the learning rate schedule</li> </ul> </li> <li>Adam<ul> <li>Lazy to control the learning rate schedule</li> </ul> </li> </ul> <h2 id=summary>Summary<a class=headerlink href=#summary title="Permanent link">&para;</a></h2> <p>We've learnt...</p> <div class="admonition success"> <p class=admonition-title>Success</p> <ul class=task-list> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> <strong>Recap of 7 step process</strong><ul class=task-list> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Step 1: Load Dataset</li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Step 2: Make Dataset Iterable</li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Step 3: Create Model Class</li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Step 4: Instantiate Model Class</li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Step 5: Instantiate Loss Class</li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> <strong>Step 6: Instantiate Optimizer Class</strong></li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Step 7: Train Model</li> </ul> </li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> <strong>Step 6</strong><ul class=task-list> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Update parameters using gradients</li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> <code>parameters = parameters - learning_rate * parameters_gradients</code></li> </ul> </li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> <strong>Gradient descent</strong><ul class=task-list> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Using gradients (error signals from loss class) to update parameters</li> </ul> </li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> <strong>Mathematical</strong> interpretation: <span><span class=MathJax_Preview>\theta = \theta - \eta \cdot \nabla J(\theta)</span><script type=math/tex>\theta = \theta - \eta \cdot  \nabla J(\theta)</script></span></li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> <strong>Optimisation Algorithms</strong><ul class=task-list> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Batch gradient descent</li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Stochastic gradient descent</li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Mini-batch gradient descent (SGD)</li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> SGD + Momentum</li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> SGD + Nesterov</li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Adam</li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Other adaptive algorithms: adagrad, adamax, adadelta, RMSProp</li> </ul> </li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> <strong>Recommendations</strong><ul class=task-list> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> SGD+M</li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> SGD+N</li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Adam</li> </ul> </li> </ul> </div> <h2 id=citation>Citation<a class=headerlink href=#citation title="Permanent link">&para;</a></h2> <p>If you have found these useful in your research, presentations, school work, projects or workshops, feel free to cite using this DOI.</p> <p><a href=https://zenodo.org/badge/latestdoi/139945544><img alt=DOI src=https://zenodo.org/badge/139945544.svg></a> </p> </article> </div> </div> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> Copyright &copy; 2020 Disponha </div> Todo o conteúdo deste site está publicado sob a licença <a href=https://creativecommons.org/licenses/by-nc-sa/4.0/ target=_blank rel=noopener> Creative Commons CC BY-SA 4.0 Brasil </a> </div> <div class=md-footer-social> <a href=https://github.com/andhremattos target=_blank rel=noopener title=github.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> <a href=https://facebook.com/dhematos target=_blank rel=noopener title=facebook.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg> </a> <a href=https://instagram.com/dhematos target=_blank rel=noopener title=instagram.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M224.1 141c-63.6 0-114.9 51.3-114.9 114.9s51.3 114.9 114.9 114.9S339 319.5 339 255.9 287.7 141 224.1 141zm0 189.6c-41.1 0-74.7-33.5-74.7-74.7s33.5-74.7 74.7-74.7 74.7 33.5 74.7 74.7-33.6 74.7-74.7 74.7zm146.4-194.3c0 14.9-12 26.8-26.8 26.8-14.9 0-26.8-12-26.8-26.8s12-26.8 26.8-26.8 26.8 12 26.8 26.8zm76.1 27.2c-1.7-35.9-9.9-67.7-36.2-93.9-26.2-26.2-58-34.4-93.9-36.2-37-2.1-147.9-2.1-184.9 0-35.8 1.7-67.6 9.9-93.9 36.1s-34.4 58-36.2 93.9c-2.1 37-2.1 147.9 0 184.9 1.7 35.9 9.9 67.7 36.2 93.9s58 34.4 93.9 36.2c37 2.1 147.9 2.1 184.9 0 35.9-1.7 67.7-9.9 93.9-36.2 26.2-26.2 34.4-58 36.2-93.9 2.1-37 2.1-147.8 0-184.8zM398.8 388c-7.8 19.6-22.9 34.7-42.6 42.6-29.5 11.7-99.5 9-132.1 9s-102.7 2.6-132.1-9c-19.6-7.8-34.7-22.9-42.6-42.6-11.7-29.5-9-99.5-9-132.1s-2.6-102.7 9-132.1c7.8-19.6 22.9-34.7 42.6-42.6 29.5-11.7 99.5-9 132.1-9s102.7-2.6 132.1 9c19.6 7.8 34.7 22.9 42.6 42.6 11.7 29.5 9 99.5 9 132.1s2.7 102.7-9 132.1z"/></svg> </a> </div> </div> </div> </footer> </div> <script src=../../../assets/javascripts/vendor.de50e36d.min.js></script> <script src=../../../assets/javascripts/bundle.fc9c3121.min.js></script><script id=__lang type=application/json>{"clipboard.copy": "Copiar para \u00e1rea de transfer\u00eancia", "clipboard.copied": "Copiado para \u00e1rea de transfer\u00eancia", "search.config.lang": "pt", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Digite para iniciar a busca", "search.result.none": "Nenhum resultado encontrado", "search.result.one": "1 resultado encontrado", "search.result.other": "# resultados encontrados"}</script> <script>
        app = initialize({
          base: "../../..",
          features: ["tabs"],
          search: Object.assign({
            worker:"../../../assets/javascripts/worker/search.a68abb33.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script> <script src=../../../javascripts/config.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script> </body> </html>