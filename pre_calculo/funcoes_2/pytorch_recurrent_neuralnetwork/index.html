<!doctype html><html lang=pt class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Plataforma para disponibilização cursos de cálculo."><link href=https:///disponha.com/pre_calculo/funcoes_2/pytorch_recurrent_neuralnetwork/ rel=canonical><meta name=author content="Carlos André"><link rel="shortcut icon" href=../../../assets/favicon.png><meta name=generator content="mkdocs-1.1.2, mkdocs-material-5.4.0"><title>Recurrent Neural Network with PyTorch - disponha</title><link rel=stylesheet href=../../../assets/stylesheets/main.545621a7.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.36d1b78f.min.css><meta name=theme-color content=#009688><link href=https://fonts.gstatic.com rel=preconnect crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Helvetica:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>body,input{font-family:"Helvetica",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","None","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){if(this.value){var e=document.location.pathname;ga("send","pageview",e+"?q="+this.value)}})}),document.addEventListener("DOMContentSwitch",function(){ga("send","pageview")})</script><script async src=https://www.google-analytics.com/analytics.js></script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=teal data-md-color-accent=teal> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#recurrent-neural-network-with-pytorch class=md-skip> Ir para o conteúdo </a> </div> <!-- 
    <div data-md-component="announce">
      
    </div>
  --> <header class=md-header data-md-component=header> <nav class="md-header-nav md-grid" aria-label=Header> <a href=https:/disponha.com/ title=disponha class="md-header-nav__button md-logo" aria-label=disponha> <?xml version="1.0" encoding="UTF-8"?> <!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><!-- Creator: CorelDRAW X7 --><svg xmlns=http://www.w3.org/2000/svg xml:space=preserve width=9000px height=9000px version=1.1 style="shape-rendering:geometricPrecision; text-rendering:geometricPrecision; image-rendering:optimizeQuality; fill-rule:evenodd; clip-rule:evenodd" viewbox="0 0 9000 9000" xmlns:xlink=http://www.w3.org/1999/xlink> <defs> <style type=text/css>
   <![CDATA[
    .str0 {stroke:#2E72A4;stroke-width:118.11}
    .fil0 {fill:#FEFEFE}
    .fil1 {fill:#2E72A4}
   ]]>
  </style> </defs> <g id=Camada_x0020_1> <metadata id=CorelCorpID_0Corel-Layer /> <g id=_1793748728448> <circle cx=4472 cy=4507 r=4281 class="fil0 str0"/> <path class="fil1 str0" d="M2045 5171c120,204 210,379 402,449 314,115 1000,-177 1339,-330 79,-35 179,-68 254,-120 41,-13 94,-46 135,-68l951 -479c363,-177 729,-363 1095,-521 186,-80 370,-180 558,-244 465,-158 1366,-413 1814,-369l1 -59c-328,-34 -853,93 -1189,181 -431,113 -680,200 -1103,395 -706,324 -1401,670 -2099,1021 -397,199 -1256,618 -1669,556 -218,-33 -320,-195 -449,-416 -47,-80 -137,-241 -177,-328 -49,-108 -114,-212 -179,-311 -379,-575 -831,-826 -1274,-1083l-119 -63 -10 46 247 149c311,184 648,381 929,716 107,128 198,250 291,408 61,104 217,424 252,470z"/> </g> </g> </svg> </a> <label class="md-header-nav__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header-nav__title data-md-component=header-title> <div class=md-header-nav__ellipsis> <span class="md-header-nav__topic md-ellipsis"> disponha </span> <span class="md-header-nav__topic md-ellipsis"> Recurrent Neural Network with PyTorch </span> </div> </div> <label class="md-header-nav__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Buscar placeholder=Buscar autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query data-md-state=active> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <button type=reset class="md-search__icon md-icon" aria-label=Clear data-md-component=search-reset tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header-nav__source> <!-- 

<a href="https://github.com/andhremattos/" title="Ir ao repositório" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    esead
  </div>
</a>
--> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list> <li class=md-tabs__item> <!--
      <a href="../../.." class="md-tabs__link md-tabs__link--active">
        Home
      </a>
    --> <a href=/explore/ class="md-tabs__link md-tabs__link--active"> Explore e-books </a> </li> <!--
    <li class="md-tabs__item">
      
        <a href="../../../sobre/" class="md-tabs__link">
          Sobre
        </a>
      
    </li>--> <!--
    <li class="md-tabs__item">
      
        <a href="../../../explore/" class="md-tabs__link">
          Explore
        </a>
      
    </li>--> <!--
    <li class="md-tabs__item">
      
        <a href="../../../app_web_ebook/servico/" class="md-tabs__link">
          App Web ebook
        </a>
      
    </li>--> <!--
    <li class="md-tabs__item">
      
        <a href="../../../diagramacao/servico/" class="md-tabs__link">
          Diagramação
        </a>
      
    </li>--> <!--
    <li class="md-tabs__item">
      
        <a href="../../../ciencia_de_dados/servico/" class="md-tabs__link">
          Ciência de dados
        </a>
      
    </li>--> <!--
    <li class="md-tabs__item">
      
        <a href="../../../aprendacalculo/" class="md-tabs__link">
          Aprenda Cálculo
        </a>
      
    </li>--> <!--
    <li class="md-tabs__item">
      
        <a href="../../../cursolatex/" class="md-tabs__link">
          Curso de LaTeX
        </a>
      
    </li>--> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=https:/disponha.com/ title=disponha class="md-nav__button md-logo" aria-label=disponha> <?xml version="1.0" encoding="UTF-8"?> <!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><!-- Creator: CorelDRAW X7 --><svg xmlns=http://www.w3.org/2000/svg xml:space=preserve width=9000px height=9000px version=1.1 style="shape-rendering:geometricPrecision; text-rendering:geometricPrecision; image-rendering:optimizeQuality; fill-rule:evenodd; clip-rule:evenodd" viewbox="0 0 9000 9000" xmlns:xlink=http://www.w3.org/1999/xlink> <defs> <style type=text/css>
   <![CDATA[
    .str0 {stroke:#2E72A4;stroke-width:118.11}
    .fil0 {fill:#FEFEFE}
    .fil1 {fill:#2E72A4}
   ]]>
  </style> </defs> <g id=Camada_x0020_1> <metadata id=CorelCorpID_0Corel-Layer /> <g id=_1793748728448> <circle cx=4472 cy=4507 r=4281 class="fil0 str0"/> <path class="fil1 str0" d="M2045 5171c120,204 210,379 402,449 314,115 1000,-177 1339,-330 79,-35 179,-68 254,-120 41,-13 94,-46 135,-68l951 -479c363,-177 729,-363 1095,-521 186,-80 370,-180 558,-244 465,-158 1366,-413 1814,-369l1 -59c-328,-34 -853,93 -1189,181 -431,113 -680,200 -1103,395 -706,324 -1401,670 -2099,1021 -397,199 -1256,618 -1669,556 -218,-33 -320,-195 -449,-416 -47,-80 -137,-241 -177,-328 -49,-108 -114,-212 -179,-311 -379,-575 -831,-826 -1274,-1083l-119 -63 -10 46 247 149c311,184 648,381 929,716 107,128 198,250 291,408 61,104 217,424 252,470z"/> </g> </g> </svg> </a> disponha </label> <div class=md-nav__source> <!-- 

<a href="https://github.com/andhremattos/" title="Ir ao repositório" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    esead
  </div>
</a>
--> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. title=Home class=md-nav__link> Home </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2 type=checkbox id=nav-2> <label class=md-nav__link for=nav-2> Sobre <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Sobre data-md-level=1> <label class=md-nav__title for=nav-2> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Sobre </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../sobre/ title=Home class=md-nav__link> Home </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3 type=checkbox id=nav-3> <label class=md-nav__link for=nav-3> Explore <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Explore data-md-level=1> <label class=md-nav__title for=nav-3> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Explore </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../explore/ title=E-books class=md-nav__link> E-books </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../apoie/ title=Apoie class=md-nav__link> Apoie </a> </li> <li class=md-nav__item> <a href=../../../consultoria/ title=Consultoria class=md-nav__link> Consultoria </a> </li> <li class=md-nav__item> <a href=../../../politica_privacidade/ title=Privacidade class=md-nav__link> Privacidade </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-7 type=checkbox id=nav-7> <label class=md-nav__link for=nav-7> App Web ebook <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="App Web ebook" data-md-level=1> <label class=md-nav__title for=nav-7> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> App Web ebook </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../app_web_ebook/servico/ title=Serviço class=md-nav__link> Serviço </a> </li> <li class=md-nav__item> <a href=../../../app_web_ebook/amostra/ title="App Web ebook - amostra" class=md-nav__link> App Web ebook - amostra </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-8 type=checkbox id=nav-8> <label class=md-nav__link for=nav-8> Diagramação <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Diagramação data-md-level=1> <label class=md-nav__title for=nav-8> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Diagramação </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../diagramacao/servico/ title=Serviço class=md-nav__link> Serviço </a> </li> <li class=md-nav__item> <a href=../../../diagramacao/amostra-diagramacao/ title=Amostra class=md-nav__link> Amostra </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-9 type=checkbox id=nav-9> <label class=md-nav__link for=nav-9> Ciência de dados <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="Ciência de dados" data-md-level=1> <label class=md-nav__title for=nav-9> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Ciência de dados </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../ciencia_de_dados/servico/ title=Serviço class=md-nav__link> Serviço </a> </li> <li class=md-nav__item> <a href=../../../ciencia_de_dados/amostra-1/ title="Amostra 1" class=md-nav__link> Amostra 1 </a> </li> <li class=md-nav__item> <a href=../../../ciencia_de_dados/amostra-2/ title="Amostra 2" class=md-nav__link> Amostra 2 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-10 type=checkbox id=nav-10> <label class=md-nav__link for=nav-10> Aprenda Cálculo <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="Aprenda Cálculo" data-md-level=1> <label class=md-nav__title for=nav-10> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Aprenda Cálculo </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../aprendacalculo/ title=Bem-Vindo(a)s class=md-nav__link> Bem-Vindo(a)s </a> </li> <li class=md-nav__item> <a href=../../../aprendacalculo/pre_calculo/ title=Pré-Cálculo class=md-nav__link> Pré-Cálculo </a> </li> <li class=md-nav__item> <a href=../../../aprendacalculo/calculo_i/ title="Cálculo I" class=md-nav__link> Cálculo I </a> </li> <li class=md-nav__item> <a href=../../../aprendacalculo/calculo_ii/ title="Cálculo II" class=md-nav__link> Cálculo II </a> </li> <li class=md-nav__item> <a href=../../../aprendacalculo/calculo_iii/ title="Cálculo III" class=md-nav__link> Cálculo III </a> </li> <li class=md-nav__item> <a href=../../../aprendacalculo/calculo_iv/ title="Cálculo IV" class=md-nav__link> Cálculo IV </a> </li> <li class=md-nav__item> <a href=../../../aprendacalculo/calculo_numerico/ title="C. Numérico" class=md-nav__link> C. Numérico </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-11 type=checkbox id=nav-11> <label class=md-nav__link for=nav-11> Curso de LaTeX <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="Curso de LaTeX" data-md-level=1> <label class=md-nav__title for=nav-11> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Curso de LaTeX </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../cursolatex/ title=Bem-Vindo(a)s class=md-nav__link> Bem-Vindo(a)s </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/programas/ title=Programas class=md-nav__link> Programas </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/latex_online/ title="LaTeX online" class=md-nav__link> LaTeX online </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/parte_1/ title="Parte 1" class=md-nav__link> Parte 1 </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/parte_2/ title="Parte 2" class=md-nav__link> Parte 2 </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/parte_3/ title="Parte 3" class=md-nav__link> Parte 3 </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/parte_4/ title="Parte 4" class=md-nav__link> Parte 4 </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/parte_5/ title="Parte 5" class=md-nav__link> Parte 5 </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/parte_6/ title="Parte 6" class=md-nav__link> Parte 6 </a> </li> <li class=md-nav__item> <a href=../../../cursolatex/parte_7/ title="Parte 7" class=md-nav__link> Parte 7 </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label=Índice> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Índice </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=#about-recurrent-neural-network class=md-nav__link> About Recurrent Neural Network </a> <nav class=md-nav aria-label="About Recurrent Neural Network"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#feedforward-neural-networks-transition-to-1-layer-recurrent-neural-networks-rnn class=md-nav__link> Feedforward Neural Networks Transition to 1 Layer Recurrent Neural Networks (RNN) </a> </li> <li class=md-nav__item> <a href=#2-layer-rnn-breakdown class=md-nav__link> 2 Layer RNN Breakdown </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#building-a-recurrent-neural-network-with-pytorch class=md-nav__link> Building a Recurrent Neural Network with PyTorch </a> <nav class=md-nav aria-label="Building a Recurrent Neural Network with PyTorch"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#model-a-1-hidden-layer-relu class=md-nav__link> Model A: 1 Hidden Layer (ReLU) </a> <nav class=md-nav aria-label="Model A: 1 Hidden Layer (ReLU)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#steps class=md-nav__link> Steps </a> </li> <li class=md-nav__item> <a href=#step-1-loading-mnist-train-dataset class=md-nav__link> Step 1: Loading MNIST Train Dataset </a> </li> <li class=md-nav__item> <a href=#step-2-make-dataset-iterable class=md-nav__link> Step 2: Make Dataset Iterable </a> </li> <li class=md-nav__item> <a href=#step-3-create-model-class class=md-nav__link> Step 3: Create Model Class </a> </li> <li class=md-nav__item> <a href=#step-4-instantiate-model-class class=md-nav__link> Step 4: Instantiate Model Class </a> </li> <li class=md-nav__item> <a href=#step-5-instantiate-loss-class class=md-nav__link> Step 5: Instantiate Loss Class </a> </li> <li class=md-nav__item> <a href=#step-6-instantiate-optimizer-class class=md-nav__link> Step 6: Instantiate Optimizer Class </a> <nav class=md-nav aria-label="Step 6: Instantiate Optimizer Class"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#parameters-in-depth class=md-nav__link> Parameters In-Depth </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#step-7-train-model class=md-nav__link> Step 7: Train Model </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#model-b-2-hidden-layer-relu class=md-nav__link> Model B: 2 Hidden Layer (ReLU) </a> <nav class=md-nav aria-label="Model B: 2 Hidden Layer (ReLU)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#steps_1 class=md-nav__link> Steps </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#model-c-2-hidden-layer class=md-nav__link> Model C: 2 Hidden Layer </a> <nav class=md-nav aria-label="Model C: 2 Hidden Layer"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#steps_2 class=md-nav__link> Steps </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#summary-of-results class=md-nav__link> Summary of Results </a> </li> <li class=md-nav__item> <a href=#general-deep-learning-notes class=md-nav__link> General Deep Learning Notes </a> </li> <li class=md-nav__item> <a href=#3-building-a-recurrent-neural-network-with-pytorch-gpu class=md-nav__link> 3. Building a Recurrent Neural Network with PyTorch (GPU) </a> <nav class=md-nav aria-label="3. Building a Recurrent Neural Network with PyTorch (GPU)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#model-c-2-hidden-layer-tanh class=md-nav__link> Model C: 2 Hidden Layer (Tanh) </a> </li> <li class=md-nav__item> <a href=#steps_3 class=md-nav__link> Steps </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#summary class=md-nav__link> Summary </a> </li> <li class=md-nav__item> <a href=#citation class=md-nav__link> Citation </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content> <article class="md-content__inner md-typeset"> <h1 id=recurrent-neural-network-with-pytorch>Recurrent Neural Network with PyTorch<a class=headerlink href=#recurrent-neural-network-with-pytorch title="Permanent link">&para;</a></h1> <div class="admonition tip"> <p class=admonition-title>Run Jupyter Notebook</p> <p>You can run the code for this section in this <a href=https://github.com/ritchieng/deep-learning-wizard/blob/master/docs/deep_learning/practical_pytorch/pytorch_recurrent_neuralnetwork.ipynb>jupyter notebook link</a>.</p> </div> <h2 id=about-recurrent-neural-network>About Recurrent Neural Network<a class=headerlink href=#about-recurrent-neural-network title="Permanent link">&para;</a></h2> <h3 id=feedforward-neural-networks-transition-to-1-layer-recurrent-neural-networks-rnn>Feedforward Neural Networks Transition to 1 Layer Recurrent Neural Networks (RNN)<a class=headerlink href=#feedforward-neural-networks-transition-to-1-layer-recurrent-neural-networks-rnn title="Permanent link">&para;</a></h3> <ul> <li>RNN is essentially an FNN but with a hidden layer (non-linear output) that passes on information to the next FNN</li> <li>Compared to an FNN, we've one additional set of weight and bias that allows information to flow from one FNN to another FNN sequentially that allows time-dependency.</li> <li>The diagram below shows the only difference between an FNN and a RNN. <img alt src=../images/rnn0-1.png></li> </ul> <h3 id=2-layer-rnn-breakdown>2 Layer RNN Breakdown<a class=headerlink href=#2-layer-rnn-breakdown title="Permanent link">&para;</a></h3> <p><img alt src=../images/rnn0-2.png></p> <h2 id=building-a-recurrent-neural-network-with-pytorch>Building a Recurrent Neural Network with PyTorch<a class=headerlink href=#building-a-recurrent-neural-network-with-pytorch title="Permanent link">&para;</a></h2> <h3 id=model-a-1-hidden-layer-relu>Model A: 1 Hidden Layer (ReLU)<a class=headerlink href=#model-a-1-hidden-layer-relu title="Permanent link">&para;</a></h3> <ul> <li>Unroll 28 time steps<ul> <li>Each step input size: 28 x 1</li> <li>Total per unroll: 28 x 28<ul> <li>Feedforward Neural Network input size: 28 x 28 </li> </ul> </li> </ul> </li> <li>1 Hidden layer</li> <li>ReLU Activation Function</li> </ul> <p><img alt src=../images/rnn2n.png></p> <h4 id=steps>Steps<a class=headerlink href=#steps title="Permanent link">&para;</a></h4> <ul> <li>Step 1: Load Dataset</li> <li>Step 2: Make Dataset Iterable</li> <li>Step 3: Create Model Class</li> <li>Step 4: Instantiate Model Class</li> <li>Step 5: Instantiate Loss Class</li> <li>Step 6: Instantiate Optimizer Class</li> <li>Step 7: Train Model</li> </ul> <h4 id=step-1-loading-mnist-train-dataset>Step 1: Loading MNIST Train Dataset<a class=headerlink href=#step-1-loading-mnist-train-dataset title="Permanent link">&para;</a></h4> <p><strong>Images from 1 to 9</strong></p> <div class="admonition note"> <p class=admonition-title>Looking into the MNIST Dataset</p> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>torch</span>
<span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
<span class=kn>import</span> <span class=nn>torchvision.transforms</span> <span class=k>as</span> <span class=nn>transforms</span>
<span class=kn>import</span> <span class=nn>torchvision.datasets</span> <span class=k>as</span> <span class=nn>dsets</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>train_dataset</span> <span class=o>=</span> <span class=n>dsets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> 
                            <span class=n>train</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> 
                            <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>
                            <span class=n>download</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>test_dataset</span> <span class=o>=</span> <span class=n>dsets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> 
                           <span class=n>train</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> 
                           <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>())</span>
</code></pre></div> <p>We would have 60k training images of size 28 x 28 pixels.</p> <div class=highlight><pre><span></span><code><span class=nb>print</span><span class=p>(</span><span class=n>train_dataset</span><span class=o>.</span><span class=n>train_data</span><span class=o>.</span><span class=n>size</span><span class=p>())</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=nb>print</span><span class=p>(</span><span class=n>train_dataset</span><span class=o>.</span><span class=n>train_labels</span><span class=o>.</span><span class=n>size</span><span class=p>())</span>
</code></pre></div> <p>Here we would have 10k testing images of the same size, 28 x 28 pixels.</p> <div class=highlight><pre><span></span><code><span class=nb>print</span><span class=p>(</span><span class=n>test_dataset</span><span class=o>.</span><span class=n>test_data</span><span class=o>.</span><span class=n>size</span><span class=p>())</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=nb>print</span><span class=p>(</span><span class=n>test_dataset</span><span class=o>.</span><span class=n>test_labels</span><span class=o>.</span><span class=n>size</span><span class=p>())</span>
</code></pre></div> </div> <div class=highlight><pre><span></span><code><span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>60000</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>28</span><span class=p>])</span>

<span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>60000</span><span class=p>])</span>

<span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>10000</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>28</span><span class=p>])</span>

<span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>10000</span><span class=p>])</span>
</code></pre></div> <h4 id=step-2-make-dataset-iterable>Step 2: Make Dataset Iterable<a class=headerlink href=#step-2-make-dataset-iterable title="Permanent link">&para;</a></h4> <div class="admonition note"> <p class=admonition-title>Creating iterable objects to loop through subsequently</p> <div class=highlight><pre><span></span><code><span class=n>batch_size</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>n_iters</span> <span class=o>=</span> <span class=mi>3000</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=n>n_iters</span> <span class=o>/</span> <span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>)</span> <span class=o>/</span> <span class=n>batch_size</span><span class=p>)</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>)</span>

<span class=n>train_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>train_dataset</span><span class=p>,</span> 
                                           <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> 
                                           <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>test_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>test_dataset</span><span class=p>,</span> 
                                          <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> 
                                          <span class=n>shuffle</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</code></pre></div> </div> <h4 id=step-3-create-model-class>Step 3: Create Model Class<a class=headerlink href=#step-3-create-model-class title="Permanent link">&para;</a></h4> <div class="admonition note"> <p class=admonition-title>1 Layer RNN</p> <p><img alt src=../images/rnn2n.png></p> <div class=highlight><pre><span></span><code><span class=k>class</span> <span class=nc>RNNModel</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>layer_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>RNNModel</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
        <span class=c1># Hidden dimensions</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>hidden_dim</span> <span class=o>=</span> <span class=n>hidden_dim</span>

        <span class=c1># Number of hidden layers</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>layer_dim</span> <span class=o>=</span> <span class=n>layer_dim</span>

        <span class=c1># Building your RNN</span>
        <span class=c1># batch_first=True causes input/output tensors to be of shape</span>
        <span class=c1># (batch_dim, seq_dim, input_dim)</span>
        <span class=c1># batch_dim = number of samples per batch</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>RNN</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>layer_dim</span><span class=p>,</span> <span class=n>batch_first</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>nonlinearity</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>)</span>

        <span class=c1># Readout layer</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span>

    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=c1># Initialize hidden state with zeros</span>
        <span class=c1># (layer_dim, batch_size, hidden_dim)</span>
        <span class=n>h0</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>layer_dim</span><span class=p>,</span> <span class=n>x</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>),</span> <span class=bp>self</span><span class=o>.</span><span class=n>hidden_dim</span><span class=p>)</span><span class=o>.</span><span class=n>requires_grad_</span><span class=p>()</span>

        <span class=c1># We need to detach the hidden state to prevent exploding/vanishing gradients</span>
        <span class=c1># This is part of truncated backpropagation through time (BPTT)</span>
        <span class=n>out</span><span class=p>,</span> <span class=n>hn</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>h0</span><span class=o>.</span><span class=n>detach</span><span class=p>())</span>

        <span class=c1># Index hidden state of last time step</span>
        <span class=c1># out.size() --&gt; 100, 28, 10</span>
        <span class=c1># out[:, -1, :] --&gt; 100, 10 --&gt; just want last time step hidden states! </span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc</span><span class=p>(</span><span class=n>out</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=p>:])</span> 
        <span class=c1># out.size() --&gt; 100, 10</span>
        <span class=k>return</span> <span class=n>out</span>
</code></pre></div> </div> <h4 id=step-4-instantiate-model-class>Step 4: Instantiate Model Class<a class=headerlink href=#step-4-instantiate-model-class title="Permanent link">&para;</a></h4> <ul> <li>28 time steps<ul> <li>Each time step: input dimension = 28</li> </ul> </li> <li>1 hidden layer</li> <li>MNIST 1-9 digits <span><span class=MathJax_Preview>\rightarrow</span><script type=math/tex>\rightarrow</script></span> output dimension = 10</li> </ul> <div class="admonition note"> <p class=admonition-title>Instantiate model class and assign to an object</p> <div class=highlight><pre><span></span><code><span class=n>input_dim</span> <span class=o>=</span> <span class=mi>28</span>
<span class=n>hidden_dim</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>layer_dim</span> <span class=o>=</span> <span class=mi>1</span>
<span class=n>output_dim</span> <span class=o>=</span> <span class=mi>10</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>model</span> <span class=o>=</span> <span class=n>RNNModel</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>layer_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span>
</code></pre></div> </div> <h4 id=step-5-instantiate-loss-class>Step 5: Instantiate Loss Class<a class=headerlink href=#step-5-instantiate-loss-class title="Permanent link">&para;</a></h4> <ul> <li>Recurrent Neural Network: <strong>Cross Entropy Loss</strong><ul> <li><em>Convolutional Neural Network</em>: <strong>Cross Entropy Loss</strong></li> <li><em>Feedforward Neural Network</em>: <strong>Cross Entropy Loss</strong></li> <li><em>Logistic Regression</em>: <strong>Cross Entropy Loss</strong></li> <li><em>Linear Regression</em>: <strong>MSE</strong></li> </ul> </li> </ul> <div class="admonition note"> <p class=admonition-title>Cross Entropy Loss for Classification Task</p> <div class=highlight><pre><span></span><code><span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>
</code></pre></div> </div> <div class="admonition warning"> <p class=admonition-title>Cross Entropy vs MSE</p> <p>Take note that there are cases where RNN, CNN and FNN use MSE as a loss function.</p> <p>We use cross entropy for classification tasks (predicting 0-9 digits in MNIST for example).</p> <p>And we use MSE for regression tasks (predicting temperatures in every December in San Francisco for example).</p> </div> <h4 id=step-6-instantiate-optimizer-class>Step 6: Instantiate Optimizer Class<a class=headerlink href=#step-6-instantiate-optimizer-class title="Permanent link">&para;</a></h4> <ul> <li>Simplified equation<ul> <li><span><span class=MathJax_Preview>\theta = \theta - \eta \cdot \nabla_\theta</span><script type=math/tex>\theta = \theta - \eta \cdot \nabla_\theta</script></span><ul> <li><span><span class=MathJax_Preview>\theta</span><script type=math/tex>\theta</script></span>: parameters (our tensors with gradient accumulation abilities)</li> <li><span><span class=MathJax_Preview>\eta</span><script type=math/tex>\eta</script></span>: learning rate (how fast we want to learn)</li> <li><span><span class=MathJax_Preview>\nabla_\theta</span><script type=math/tex>\nabla_\theta</script></span>: gradients of loss with respect to the model's parameters</li> </ul> </li> </ul> </li> <li>Even simplier equation<ul> <li><code>parameters = parameters - learning_rate * parameters_gradients</code></li> <li><strong>At every iteration, we update our model's parameters</strong></li> </ul> </li> </ul> <div class=highlight><pre><span></span><code><span class=n>learning_rate</span> <span class=o>=</span> <span class=mf>0.01</span>

<span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=n>learning_rate</span><span class=p>)</span>  
</code></pre></div> <h6 id=parameters-in-depth>Parameters In-Depth<a class=headerlink href=#parameters-in-depth title="Permanent link">&para;</a></h6> <ul> <li>Input to Hidden Layer Affine Function<ul> <li>A1, B1</li> </ul> </li> <li>Hidden Layer to Output Affine Function<ul> <li>A2, B2</li> </ul> </li> <li>Hidden Layer to Hidden Layer Affine Function<ul> <li>A3, B3</li> </ul> </li> </ul> <p><img alt src=./images/rnn4n.pn></p> <div class="admonition note"> <p class=admonition-title>Total groups of parameters</p> <p>We should have 6 groups as shown above.</p> <div class=highlight><pre><span></span><code><span class=nb>len</span><span class=p>(</span><span class=nb>list</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>()))</span>
</code></pre></div> </div> <div class=highlight><pre><span></span><code><span class=mi>6</span>
</code></pre></div> <div class="admonition note"> <p class=admonition-title>Input to Hidden Weight</p> <p>Remember we defined our hidden layer to have a size of 100. Because our input is a size of 28 at each time step, this gives rise to a weight matrix of 100 x 28.</p> <div class=highlight><pre><span></span><code><span class=c1># Input --&gt; Hidden (A1)</span>
<span class=nb>list</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>size</span><span class=p>()</span>
</code></pre></div> </div> <div class=highlight><pre><span></span><code><span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>100</span><span class=p>,</span> <span class=mi>28</span><span class=p>])</span>
</code></pre></div> <div class="admonition note"> <p class=admonition-title>Input to Hidden Bias</p> <div class=highlight><pre><span></span><code><span class=c1># Input --&gt; Hidden BIAS (B1)</span>
<span class=nb>list</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())[</span><span class=mi>2</span><span class=p>]</span><span class=o>.</span><span class=n>size</span><span class=p>()</span>
</code></pre></div> </div> <div class=highlight><pre><span></span><code><span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>100</span><span class=p>])</span>
</code></pre></div> <div class="admonition note"> <p class=admonition-title>Hidden to Hidden</p> <div class=highlight><pre><span></span><code><span class=c1># Hidden --&gt; Hidden (A3)</span>
<span class=nb>list</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>size</span><span class=p>()</span>
</code></pre></div> </div> <div class=highlight><pre><span></span><code><span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>100</span><span class=p>,</span> <span class=mi>100</span><span class=p>])</span>
</code></pre></div> <div class="admonition note"> <p class=admonition-title>Hidden to Hidden Bias</p> <div class=highlight><pre><span></span><code><span class=c1># Hidden --&gt; Hidden BIAS(B3)</span>
<span class=nb>list</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())[</span><span class=mi>3</span><span class=p>]</span><span class=o>.</span><span class=n>size</span><span class=p>()</span>
</code></pre></div> </div> <div class=highlight><pre><span></span><code><span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>100</span><span class=p>])</span>
</code></pre></div> <div class="admonition note"> <p class=admonition-title>Hidden to Output</p> <div class=highlight><pre><span></span><code><span class=c1># Hidden --&gt; Output (A2)</span>
<span class=nb>list</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())[</span><span class=mi>4</span><span class=p>]</span><span class=o>.</span><span class=n>size</span><span class=p>()</span>
</code></pre></div> </div> <div class=highlight><pre><span></span><code><span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>10</span><span class=p>,</span> <span class=mi>100</span><span class=p>])</span>
</code></pre></div> <div class="admonition note"> <p class=admonition-title>Hidden to Output Bias</p> <div class=highlight><pre><span></span><code><span class=c1># Hidden --&gt; Output BIAS (B2)</span>
<span class=nb>list</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())[</span><span class=mi>5</span><span class=p>]</span><span class=o>.</span><span class=n>size</span><span class=p>()</span>
</code></pre></div> </div> <div class=highlight><pre><span></span><code><span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>10</span><span class=p>])</span>
</code></pre></div> <h4 id=step-7-train-model>Step 7: Train Model<a class=headerlink href=#step-7-train-model title="Permanent link">&para;</a></h4> <ul> <li>Process <ol> <li><strong>Convert inputs/labels to tensors with gradient accumulation abilities</strong><ul> <li>RNN Input: (1, 28)</li> <li>CNN Input: (1, 28, 28) </li> <li>FNN Input: (1, 28*28)</li> </ul> </li> <li>Clear gradient buffets</li> <li>Get output given inputs </li> <li>Get loss</li> <li>Get gradients w.r.t. parameters</li> <li>Update parameters using gradients<ul> <li><code>parameters = parameters - learning_rate * parameters_gradients</code></li> </ul> </li> <li>REPEAT</li> </ol> </li> </ul> <div class="admonition note"> <p class=admonition-title>Same 7 step process for training models</p> <div class=highlight><pre><span></span><code><span class=c1># Number of steps to unroll</span>
<span class=n>seq_dim</span> <span class=o>=</span> <span class=mi>28</span>  

<span class=nb>iter</span> <span class=o>=</span> <span class=mi>0</span>
<span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=p>(</span><span class=n>images</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_loader</span><span class=p>):</span>
        <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
        <span class=c1># Load images as tensors with gradient accumulation abilities</span>
        <span class=n>images</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>seq_dim</span><span class=p>,</span> <span class=n>input_dim</span><span class=p>)</span><span class=o>.</span><span class=n>requires_grad_</span><span class=p>()</span>

        <span class=c1># Clear gradients w.r.t. parameters</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>

        <span class=c1># Forward pass to get output/logits</span>
        <span class=c1># outputs.size() --&gt; 100, 10</span>
        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>

        <span class=c1># Calculate Loss: softmax --&gt; cross entropy loss</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>

        <span class=c1># Getting gradients w.r.t. parameters</span>
        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>

        <span class=c1># Updating parameters</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

        <span class=nb>iter</span> <span class=o>+=</span> <span class=mi>1</span>

        <span class=k>if</span> <span class=nb>iter</span> <span class=o>%</span> <span class=mi>500</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
            <span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
            <span class=c1># Calculate Accuracy         </span>
            <span class=n>correct</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=n>total</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=c1># Iterate through test dataset</span>
            <span class=k>for</span> <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>test_loader</span><span class=p>:</span>
                <span class=c1># Load images to a Torch tensors with gradient accumulation abilities</span>
                <span class=n>images</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>seq_dim</span><span class=p>,</span> <span class=n>input_dim</span><span class=p>)</span>

                <span class=c1># Forward pass only to get logits/output</span>
                <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>

                <span class=c1># Get predictions from the maximum value</span>
                <span class=n>_</span><span class=p>,</span> <span class=n>predicted</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>outputs</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

                <span class=c1># Total number of labels</span>
                <span class=n>total</span> <span class=o>+=</span> <span class=n>labels</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>

                <span class=c1># Total correct predictions</span>
                <span class=n>correct</span> <span class=o>+=</span> <span class=p>(</span><span class=n>predicted</span> <span class=o>==</span> <span class=n>labels</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

            <span class=n>accuracy</span> <span class=o>=</span> <span class=mi>100</span> <span class=o>*</span> <span class=n>correct</span> <span class=o>/</span> <span class=n>total</span>

            <span class=c1># Print Loss</span>
            <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Iteration: </span><span class=si>{}</span><span class=s1>. Loss: </span><span class=si>{}</span><span class=s1>. Accuracy: </span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=nb>iter</span><span class=p>,</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span> <span class=n>accuracy</span><span class=p>))</span>
</code></pre></div> </div> <div class=highlight><pre><span></span><code><span class=n>Iteration</span><span class=p>:</span> <span class=mf>500.</span> <span class=n>Loss</span><span class=p>:</span> <span class=mf>2.301494836807251</span><span class=o>.</span> <span class=n>Accuracy</span><span class=p>:</span> <span class=mi>12</span>
<span class=n>Iteration</span><span class=p>:</span> <span class=mf>1000.</span> <span class=n>Loss</span><span class=p>:</span> <span class=mf>2.2986037731170654</span><span class=o>.</span> <span class=n>Accuracy</span><span class=p>:</span> <span class=mi>14</span>
<span class=n>Iteration</span><span class=p>:</span> <span class=mf>1500.</span> <span class=n>Loss</span><span class=p>:</span> <span class=mf>2.278566598892212</span><span class=o>.</span> <span class=n>Accuracy</span><span class=p>:</span> <span class=mi>18</span>
<span class=n>Iteration</span><span class=p>:</span> <span class=mf>2000.</span> <span class=n>Loss</span><span class=p>:</span> <span class=mf>2.169614315032959</span><span class=o>.</span> <span class=n>Accuracy</span><span class=p>:</span> <span class=mi>21</span>
<span class=n>Iteration</span><span class=p>:</span> <span class=mf>2500.</span> <span class=n>Loss</span><span class=p>:</span> <span class=mf>1.1662731170654297</span><span class=o>.</span> <span class=n>Accuracy</span><span class=p>:</span> <span class=mi>51</span>
<span class=n>Iteration</span><span class=p>:</span> <span class=mf>3000.</span> <span class=n>Loss</span><span class=p>:</span> <span class=mf>0.9290509223937988</span><span class=o>.</span> <span class=n>Accuracy</span><span class=p>:</span> <span class=mi>71</span>
</code></pre></div> <h3 id=model-b-2-hidden-layer-relu>Model B: 2 Hidden Layer (ReLU)<a class=headerlink href=#model-b-2-hidden-layer-relu title="Permanent link">&para;</a></h3> <ul> <li>Unroll 28 time steps<ul> <li>Each step input size: 28 x 1</li> <li>Total per unroll: 28 x 28<ul> <li>Feedforward Neural Network inpt size: 28 x 28 </li> </ul> </li> </ul> </li> <li><strong>2 Hidden layer</strong></li> <li>ReLU Activation Function</li> </ul> <p><img alt src=../images/rnn5nr.png></p> <h4 id=steps_1>Steps<a class=headerlink href=#steps_1 title="Permanent link">&para;</a></h4> <ul> <li>Step 1: Load Dataset</li> <li>Step 2: Make Dataset Iterable</li> <li>Step 3: Create Model Class</li> <li><strong>Step 4: Instantiate Model Class</strong></li> <li>Step 5: Instantiate Loss Class</li> <li>Step 6: Instantiate Optimizer Class</li> <li>Step 7: Train Model</li> </ul> <div class="admonition note"> <p class=admonition-title>2 Hidden Layer + ReLU</p> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>torch</span>
<span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
<span class=kn>import</span> <span class=nn>torchvision.transforms</span> <span class=k>as</span> <span class=nn>transforms</span>
<span class=kn>import</span> <span class=nn>torchvision.datasets</span> <span class=k>as</span> <span class=nn>dsets</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 1: LOADING DATASET</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>train_dataset</span> <span class=o>=</span> <span class=n>dsets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> 
                            <span class=n>train</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> 
                            <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>
                            <span class=n>download</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>test_dataset</span> <span class=o>=</span> <span class=n>dsets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> 
                           <span class=n>train</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> 
                           <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>())</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 2: MAKING DATASET ITERABLE</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=n>batch_size</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>n_iters</span> <span class=o>=</span> <span class=mi>3000</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=n>n_iters</span> <span class=o>/</span> <span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>)</span> <span class=o>/</span> <span class=n>batch_size</span><span class=p>)</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>)</span>

<span class=n>train_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>train_dataset</span><span class=p>,</span> 
                                           <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> 
                                           <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>test_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>test_dataset</span><span class=p>,</span> 
                                          <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> 
                                          <span class=n>shuffle</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 3: CREATE MODEL CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=k>class</span> <span class=nc>RNNModel</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>layer_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>RNNModel</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
        <span class=c1># Hidden dimensions</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>hidden_dim</span> <span class=o>=</span> <span class=n>hidden_dim</span>

        <span class=c1># Number of hidden layers</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>layer_dim</span> <span class=o>=</span> <span class=n>layer_dim</span>

        <span class=c1># Building your RNN</span>
        <span class=c1># batch_first=True causes input/output tensors to be of shape</span>
        <span class=c1># (batch_dim, seq_dim, feature_dim)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>RNN</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>layer_dim</span><span class=p>,</span> <span class=n>batch_first</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>nonlinearity</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>)</span>

        <span class=c1># Readout layer</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span>

    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=c1># Initialize hidden state with zeros</span>
        <span class=n>h0</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>layer_dim</span><span class=p>,</span> <span class=n>x</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>),</span> <span class=bp>self</span><span class=o>.</span><span class=n>hidden_dim</span><span class=p>)</span><span class=o>.</span><span class=n>requires_grad_</span><span class=p>()</span>

        <span class=c1># We need to detach the hidden state to prevent exploding/vanishing gradients</span>
        <span class=c1># This is part of truncated backpropagation through time (BPTT)</span>
        <span class=n>out</span><span class=p>,</span> <span class=n>hn</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>h0</span><span class=o>.</span><span class=n>detach</span><span class=p>())</span>

        <span class=c1># Index hidden state of last time step</span>
        <span class=c1># out.size() --&gt; 100, 28, 100</span>
        <span class=c1># out[:, -1, :] --&gt; 100, 100 --&gt; just want last time step hidden states! </span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc</span><span class=p>(</span><span class=n>out</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=p>:])</span> 
        <span class=c1># out.size() --&gt; 100, 10</span>
        <span class=k>return</span> <span class=n>out</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 4: INSTANTIATE MODEL CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>input_dim</span> <span class=o>=</span> <span class=mi>28</span>
<span class=n>hidden_dim</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>layer_dim</span> <span class=o>=</span> <span class=mi>2</span>  <span class=c1># ONLY CHANGE IS HERE FROM ONE LAYER TO TWO LAYER</span>
<span class=n>output_dim</span> <span class=o>=</span> <span class=mi>10</span>

<span class=n>model</span> <span class=o>=</span> <span class=n>RNNModel</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>layer_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span>

<span class=c1># JUST PRINTING MODEL &amp; PARAMETERS </span>
<span class=nb>print</span><span class=p>(</span><span class=n>model</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=nb>list</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())))</span>
<span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=nb>list</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>()))):</span>
    <span class=nb>print</span><span class=p>(</span><span class=nb>list</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>size</span><span class=p>())</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 5: INSTANTIATE LOSS CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 6: INSTANTIATE OPTIMIZER CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>learning_rate</span> <span class=o>=</span> <span class=mf>0.01</span>

<span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=n>learning_rate</span><span class=p>)</span>  

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 7: TRAIN THE MODEL</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=c1># Number of steps to unroll</span>
<span class=n>seq_dim</span> <span class=o>=</span> <span class=mi>28</span>  

<span class=nb>iter</span> <span class=o>=</span> <span class=mi>0</span>
<span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=p>(</span><span class=n>images</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_loader</span><span class=p>):</span>
        <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
        <span class=c1># Load images as tensors with gradient accumulation abilities</span>
        <span class=n>images</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>seq_dim</span><span class=p>,</span> <span class=n>input_dim</span><span class=p>)</span><span class=o>.</span><span class=n>requires_grad_</span><span class=p>()</span>

        <span class=c1># Clear gradients w.r.t. parameters</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>

        <span class=c1># Forward pass to get output/logits</span>
        <span class=c1># outputs.size() --&gt; 100, 10</span>
        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>

        <span class=c1># Calculate Loss: softmax --&gt; cross entropy loss</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>

        <span class=c1># Getting gradients w.r.t. parameters</span>
        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>

        <span class=c1># Updating parameters</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

        <span class=nb>iter</span> <span class=o>+=</span> <span class=mi>1</span>

        <span class=k>if</span> <span class=nb>iter</span> <span class=o>%</span> <span class=mi>500</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
            <span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
            <span class=c1># Calculate Accuracy         </span>
            <span class=n>correct</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=n>total</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=c1># Iterate through test dataset</span>
            <span class=k>for</span> <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>test_loader</span><span class=p>:</span>
                <span class=c1># Resize images</span>
                <span class=n>images</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>seq_dim</span><span class=p>,</span> <span class=n>input_dim</span><span class=p>)</span>

                <span class=c1># Forward pass only to get logits/output</span>
                <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>

                <span class=c1># Get predictions from the maximum value</span>
                <span class=n>_</span><span class=p>,</span> <span class=n>predicted</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>outputs</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

                <span class=c1># Total number of labels</span>
                <span class=n>total</span> <span class=o>+=</span> <span class=n>labels</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>

                <span class=c1># Total correct predictions</span>
                <span class=n>correct</span> <span class=o>+=</span> <span class=p>(</span><span class=n>predicted</span> <span class=o>==</span> <span class=n>labels</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

            <span class=n>accuracy</span> <span class=o>=</span> <span class=mi>100</span> <span class=o>*</span> <span class=n>correct</span> <span class=o>/</span> <span class=n>total</span>

            <span class=c1># Print Loss</span>
            <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Iteration: </span><span class=si>{}</span><span class=s1>. Loss: </span><span class=si>{}</span><span class=s1>. Accuracy: </span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=nb>iter</span><span class=p>,</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span> <span class=n>accuracy</span><span class=p>))</span>
</code></pre></div> </div> <div class=highlight><pre><span></span><code><span class=n>RNNModel</span><span class=p>(</span>
  <span class=p>(</span><span class=n>rnn</span><span class=p>):</span> <span class=n>RNN</span><span class=p>(</span><span class=mi>28</span><span class=p>,</span> <span class=mi>100</span><span class=p>,</span> <span class=n>num_layers</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>batch_first</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
  <span class=p>(</span><span class=n>fc</span><span class=p>):</span> <span class=n>Linear</span><span class=p>(</span><span class=n>in_features</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>out_features</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<span class=p>)</span>

<span class=mi>10</span>

<span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>100</span><span class=p>,</span> <span class=mi>28</span><span class=p>])</span>
<span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>100</span><span class=p>,</span> <span class=mi>100</span><span class=p>])</span>
<span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>100</span><span class=p>])</span>
<span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>100</span><span class=p>])</span>
<span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>100</span><span class=p>,</span> <span class=mi>100</span><span class=p>])</span>
<span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>100</span><span class=p>,</span> <span class=mi>100</span><span class=p>])</span>
<span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>100</span><span class=p>])</span>
<span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>100</span><span class=p>])</span>
<span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>10</span><span class=p>,</span> <span class=mi>100</span><span class=p>])</span>
<span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>10</span><span class=p>])</span>

<span class=n>Iteration</span><span class=p>:</span> <span class=mf>500.</span> <span class=n>Loss</span><span class=p>:</span> <span class=mf>2.3019518852233887</span><span class=o>.</span> <span class=n>Accuracy</span><span class=p>:</span> <span class=mi>11</span>
<span class=n>Iteration</span><span class=p>:</span> <span class=mf>1000.</span> <span class=n>Loss</span><span class=p>:</span> <span class=mf>2.299217700958252</span><span class=o>.</span> <span class=n>Accuracy</span><span class=p>:</span> <span class=mi>11</span>
<span class=n>Iteration</span><span class=p>:</span> <span class=mf>1500.</span> <span class=n>Loss</span><span class=p>:</span> <span class=mf>2.279090166091919</span><span class=o>.</span> <span class=n>Accuracy</span><span class=p>:</span> <span class=mi>14</span>
<span class=n>Iteration</span><span class=p>:</span> <span class=mf>2000.</span> <span class=n>Loss</span><span class=p>:</span> <span class=mf>2.126953125</span><span class=o>.</span> <span class=n>Accuracy</span><span class=p>:</span> <span class=mi>25</span>
<span class=n>Iteration</span><span class=p>:</span> <span class=mf>2500.</span> <span class=n>Loss</span><span class=p>:</span> <span class=mf>1.356347680091858</span><span class=o>.</span> <span class=n>Accuracy</span><span class=p>:</span> <span class=mi>57</span>
<span class=n>Iteration</span><span class=p>:</span> <span class=mf>3000.</span> <span class=n>Loss</span><span class=p>:</span> <span class=mf>0.7377720475196838</span><span class=o>.</span> <span class=n>Accuracy</span><span class=p>:</span> <span class=mi>69</span>
</code></pre></div> <ul> <li><strong>10 sets of parameters</strong></li> <li>First hidden Layer<ul> <li><span><span class=MathJax_Preview>A_1 = [100, 28]</span><script type=math/tex>A_1 = [100, 28]</script></span></li> <li><span><span class=MathJax_Preview>A_3 = [100, 100]</span><script type=math/tex>A_3 = [100, 100]</script></span></li> <li><span><span class=MathJax_Preview>B_1 = [100]</span><script type=math/tex>B_1 = [100]</script></span></li> <li><span><span class=MathJax_Preview>B_3 = [100]</span><script type=math/tex>B_3 = [100]</script></span></li> </ul> </li> <li>Second hidden layer<ul> <li><span><span class=MathJax_Preview>A_2 = [100, 100]</span><script type=math/tex>A_2 = [100, 100]</script></span></li> <li><span><span class=MathJax_Preview>A_5 = [100, 100]</span><script type=math/tex>A_5 = [100, 100]</script></span></li> <li><span><span class=MathJax_Preview>B_2 = [100]</span><script type=math/tex>B_2 = [100]</script></span></li> <li><span><span class=MathJax_Preview>B_5 = [100]</span><script type=math/tex>B_5 = [100]</script></span></li> </ul> </li> <li>Readout layer<ul> <li><span><span class=MathJax_Preview>A_4 = [10, 100]</span><script type=math/tex>A_4 = [10, 100]</script></span></li> <li><span><span class=MathJax_Preview>B_4 = [10]</span><script type=math/tex>B_4 = [10]</script></span></li> </ul> </li> </ul> <p><img alt src=../images/rnn6.png></p> <h3 id=model-c-2-hidden-layer>Model C: 2 Hidden Layer<a class=headerlink href=#model-c-2-hidden-layer title="Permanent link">&para;</a></h3> <ul> <li>Unroll 28 time steps<ul> <li>Each step input size: 28 x 1</li> <li>Total per unroll: 28 x 28<ul> <li>Feedforward Neural Network inpt size: 28 x 28 </li> </ul> </li> </ul> </li> <li>2 Hidden layer</li> <li><strong>Tanh</strong> Activation Function</li> </ul> <p><img alt src=../images/rnn5nr.png></p> <h4 id=steps_2>Steps<a class=headerlink href=#steps_2 title="Permanent link">&para;</a></h4> <ul> <li>Step 1: Load Dataset</li> <li>Step 2: Make Dataset Iterable</li> <li>Step 3: Create Model Class</li> <li><strong>Step 4: Instantiate Model Class</strong></li> <li>Step 5: Instantiate Loss Class</li> <li>Step 6: Instantiate Optimizer Class</li> <li>Step 7: Train Model</li> </ul> <p>!!! "2 Hidden + ReLU" <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>torch</span>
<span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
<span class=kn>import</span> <span class=nn>torchvision.transforms</span> <span class=k>as</span> <span class=nn>transforms</span>
<span class=kn>import</span> <span class=nn>torchvision.datasets</span> <span class=k>as</span> <span class=nn>dsets</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 1: LOADING DATASET</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>train_dataset</span> <span class=o>=</span> <span class=n>dsets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> 
                            <span class=n>train</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> 
                            <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>
                            <span class=n>download</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>test_dataset</span> <span class=o>=</span> <span class=n>dsets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> 
                           <span class=n>train</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> 
                           <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>())</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 2: MAKING DATASET ITERABLE</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=n>batch_size</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>n_iters</span> <span class=o>=</span> <span class=mi>3000</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=n>n_iters</span> <span class=o>/</span> <span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>)</span> <span class=o>/</span> <span class=n>batch_size</span><span class=p>)</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>)</span>

<span class=n>train_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>train_dataset</span><span class=p>,</span> 
                                           <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> 
                                           <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>test_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>test_dataset</span><span class=p>,</span> 
                                          <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> 
                                          <span class=n>shuffle</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 3: CREATE MODEL CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=k>class</span> <span class=nc>RNNModel</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>layer_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>RNNModel</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
        <span class=c1># Hidden dimensions</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>hidden_dim</span> <span class=o>=</span> <span class=n>hidden_dim</span>

        <span class=c1># Number of hidden layers</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>layer_dim</span> <span class=o>=</span> <span class=n>layer_dim</span>

        <span class=c1># Building your RNN</span>
        <span class=c1># batch_first=True causes input/output tensors to be of shape</span>
        <span class=c1># (batch_dim, seq_dim, feature_dim)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>RNN</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>layer_dim</span><span class=p>,</span> <span class=n>batch_first</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>nonlinearity</span><span class=o>=</span><span class=s1>&#39;tanh&#39;</span><span class=p>)</span>

        <span class=c1># Readout layer</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span>

    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=c1># Initialize hidden state with zeros</span>
        <span class=n>h0</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>layer_dim</span><span class=p>,</span> <span class=n>x</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>),</span> <span class=bp>self</span><span class=o>.</span><span class=n>hidden_dim</span><span class=p>)</span><span class=o>.</span><span class=n>requires_grad_</span><span class=p>()</span>

        <span class=c1># One time step</span>
        <span class=c1># We need to detach the hidden state to prevent exploding/vanishing gradients</span>
        <span class=c1># This is part of truncated backpropagation through time (BPTT)</span>
        <span class=n>out</span><span class=p>,</span> <span class=n>hn</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>h0</span><span class=o>.</span><span class=n>detach</span><span class=p>())</span>

        <span class=c1># Index hidden state of last time step</span>
        <span class=c1># out.size() --&gt; 100, 28, 100</span>
        <span class=c1># out[:, -1, :] --&gt; 100, 100 --&gt; just want last time step hidden states! </span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc</span><span class=p>(</span><span class=n>out</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=p>:])</span> 
        <span class=c1># out.size() --&gt; 100, 10</span>
        <span class=k>return</span> <span class=n>out</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 4: INSTANTIATE MODEL CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>input_dim</span> <span class=o>=</span> <span class=mi>28</span>
<span class=n>hidden_dim</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>layer_dim</span> <span class=o>=</span> <span class=mi>2</span>  <span class=c1># ONLY CHANGE IS HERE FROM ONE LAYER TO TWO LAYER</span>
<span class=n>output_dim</span> <span class=o>=</span> <span class=mi>10</span>

<span class=n>model</span> <span class=o>=</span> <span class=n>RNNModel</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>layer_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span>

<span class=c1># JUST PRINTING MODEL &amp; PARAMETERS </span>
<span class=nb>print</span><span class=p>(</span><span class=n>model</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=nb>list</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())))</span>
<span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=nb>list</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>()))):</span>
    <span class=nb>print</span><span class=p>(</span><span class=nb>list</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>size</span><span class=p>())</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 5: INSTANTIATE LOSS CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 6: INSTANTIATE OPTIMIZER CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>learning_rate</span> <span class=o>=</span> <span class=mf>0.1</span>

<span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=n>learning_rate</span><span class=p>)</span>  

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 7: TRAIN THE MODEL</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=c1># Number of steps to unroll</span>
<span class=n>seq_dim</span> <span class=o>=</span> <span class=mi>28</span>  

<span class=nb>iter</span> <span class=o>=</span> <span class=mi>0</span>
<span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=p>(</span><span class=n>images</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_loader</span><span class=p>):</span>
        <span class=c1># Load images as tensors with gradient accumulation abilities</span>
        <span class=n>images</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>seq_dim</span><span class=p>,</span> <span class=n>input_dim</span><span class=p>)</span><span class=o>.</span><span class=n>requires_grad_</span><span class=p>()</span>

        <span class=c1># Clear gradients w.r.t. parameters</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>

        <span class=c1># Forward pass to get output/logits</span>
        <span class=c1># outputs.size() --&gt; 100, 10</span>
        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>

        <span class=c1># Calculate Loss: softmax --&gt; cross entropy loss</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>

        <span class=c1># Getting gradients w.r.t. parameters</span>
        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>

        <span class=c1># Updating parameters</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

        <span class=nb>iter</span> <span class=o>+=</span> <span class=mi>1</span>

        <span class=k>if</span> <span class=nb>iter</span> <span class=o>%</span> <span class=mi>500</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
            <span class=c1># Calculate Accuracy         </span>
            <span class=n>correct</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=n>total</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=c1># Iterate through test dataset</span>
            <span class=k>for</span> <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>test_loader</span><span class=p>:</span>
                <span class=c1># Resize images</span>
                <span class=n>images</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>seq_dim</span><span class=p>,</span> <span class=n>input_dim</span><span class=p>)</span>

                <span class=c1># Forward pass only to get logits/output</span>
                <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>

                <span class=c1># Get predictions from the maximum value</span>
                <span class=n>_</span><span class=p>,</span> <span class=n>predicted</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>outputs</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

                <span class=c1># Total number of labels</span>
                <span class=n>total</span> <span class=o>+=</span> <span class=n>labels</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>

                <span class=c1># Total correct predictions</span>
                <span class=n>correct</span> <span class=o>+=</span> <span class=p>(</span><span class=n>predicted</span> <span class=o>==</span> <span class=n>labels</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

            <span class=n>accuracy</span> <span class=o>=</span> <span class=mi>100</span> <span class=o>*</span> <span class=n>correct</span> <span class=o>/</span> <span class=n>total</span>

            <span class=c1># Print Loss</span>
            <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Iteration: </span><span class=si>{}</span><span class=s1>. Loss: </span><span class=si>{}</span><span class=s1>. Accuracy: </span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=nb>iter</span><span class=p>,</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span> <span class=n>accuracy</span><span class=p>))</span>
</code></pre></div></p> <div class=highlight><pre><span></span><code><span class=n>RNNModel</span><span class=p>(</span>
  <span class=p>(</span><span class=n>rnn</span><span class=p>):</span> <span class=n>RNN</span><span class=p>(</span><span class=mi>28</span><span class=p>,</span> <span class=mi>100</span><span class=p>,</span> <span class=n>num_layers</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>batch_first</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
  <span class=p>(</span><span class=n>fc</span><span class=p>):</span> <span class=n>Linear</span><span class=p>(</span><span class=n>in_features</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>out_features</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<span class=p>)</span>

<span class=mi>10</span>

<span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>100</span><span class=p>,</span> <span class=mi>28</span><span class=p>])</span>
<span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>100</span><span class=p>,</span> <span class=mi>100</span><span class=p>])</span>
<span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>100</span><span class=p>])</span>
<span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>100</span><span class=p>])</span>
<span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>100</span><span class=p>,</span> <span class=mi>100</span><span class=p>])</span>
<span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>100</span><span class=p>,</span> <span class=mi>100</span><span class=p>])</span>
<span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>100</span><span class=p>])</span>
<span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>100</span><span class=p>])</span>
<span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>10</span><span class=p>,</span> <span class=mi>100</span><span class=p>])</span>
<span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>10</span><span class=p>])</span>
<span class=n>Iteration</span><span class=p>:</span> <span class=mf>500.</span> <span class=n>Loss</span><span class=p>:</span> <span class=mf>0.5943437218666077</span><span class=o>.</span> <span class=n>Accuracy</span><span class=p>:</span> <span class=mi>77</span>
<span class=n>Iteration</span><span class=p>:</span> <span class=mf>1000.</span> <span class=n>Loss</span><span class=p>:</span> <span class=mf>0.22048641741275787</span><span class=o>.</span> <span class=n>Accuracy</span><span class=p>:</span> <span class=mi>91</span>
<span class=n>Iteration</span><span class=p>:</span> <span class=mf>1500.</span> <span class=n>Loss</span><span class=p>:</span> <span class=mf>0.18479223549365997</span><span class=o>.</span> <span class=n>Accuracy</span><span class=p>:</span> <span class=mi>94</span>
<span class=n>Iteration</span><span class=p>:</span> <span class=mf>2000.</span> <span class=n>Loss</span><span class=p>:</span> <span class=mf>0.2723771929740906</span><span class=o>.</span> <span class=n>Accuracy</span><span class=p>:</span> <span class=mi>91</span>
<span class=n>Iteration</span><span class=p>:</span> <span class=mf>2500.</span> <span class=n>Loss</span><span class=p>:</span> <span class=mf>0.18817797303199768</span><span class=o>.</span> <span class=n>Accuracy</span><span class=p>:</span> <span class=mi>92</span>
<span class=n>Iteration</span><span class=p>:</span> <span class=mf>3000.</span> <span class=n>Loss</span><span class=p>:</span> <span class=mf>0.1685929149389267</span><span class=o>.</span> <span class=n>Accuracy</span><span class=p>:</span> <span class=mi>92</span>
</code></pre></div> <h2 id=summary-of-results>Summary of Results<a class=headerlink href=#summary-of-results title="Permanent link">&para;</a></h2> <table> <thead> <tr> <th>Model A</th> <th>Model B</th> <th>Model C</th> </tr> </thead> <tbody> <tr> <td>ReLU</td> <td>ReLU</td> <td>Tanh</td> </tr> <tr> <td>1 Hidden Layer</td> <td>2 Hidden Layers</td> <td>2 Hidden Layers</td> </tr> <tr> <td>100 Hidden Units</td> <td>100 Hidden Units</td> <td>100 Hidden Units</td> </tr> <tr> <td>92.48%</td> <td>95.09%</td> <td>95.54%</td> </tr> </tbody> </table> <h2 id=general-deep-learning-notes>General Deep Learning Notes<a class=headerlink href=#general-deep-learning-notes title="Permanent link">&para;</a></h2> <ul> <li>2 ways to expand a recurrent neural network<ul> <li>More non-linear activation units (neurons)</li> <li>More hidden layers</li> </ul> </li> <li>Cons<ul> <li>Need a larger dataset<ul> <li>Curse of dimensionality</li> </ul> </li> <li>Does not necessarily mean higher accuracy</li> </ul> </li> </ul> <h2 id=3-building-a-recurrent-neural-network-with-pytorch-gpu>3. Building a Recurrent Neural Network with PyTorch (GPU)<a class=headerlink href=#3-building-a-recurrent-neural-network-with-pytorch-gpu title="Permanent link">&para;</a></h2> <h3 id=model-c-2-hidden-layer-tanh>Model C: 2 Hidden Layer (Tanh)<a class=headerlink href=#model-c-2-hidden-layer-tanh title="Permanent link">&para;</a></h3> <p><img alt src=../images/rnn5nr.png></p> <p>GPU: 2 things must be on GPU - <code>model</code> - <code>tensors</code></p> <h3 id=steps_3>Steps<a class=headerlink href=#steps_3 title="Permanent link">&para;</a></h3> <ul> <li>Step 1: Load Dataset</li> <li>Step 2: Make Dataset Iterable</li> <li><strong>Step 3: Create Model Class</strong></li> <li><strong>Step 4: Instantiate Model Class</strong></li> <li>Step 5: Instantiate Loss Class</li> <li>Step 6: Instantiate Optimizer Class</li> <li><strong>Step 7: Train Model</strong></li> </ul> <div class="admonition note"> <p class=admonition-title>2 Layer RNN + Tanh</p> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>torch</span>
<span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
<span class=kn>import</span> <span class=nn>torchvision.transforms</span> <span class=k>as</span> <span class=nn>transforms</span>
<span class=kn>import</span> <span class=nn>torchvision.datasets</span> <span class=k>as</span> <span class=nn>dsets</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 1: LOADING DATASET</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>train_dataset</span> <span class=o>=</span> <span class=n>dsets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> 
                            <span class=n>train</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> 
                            <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>
                            <span class=n>download</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>test_dataset</span> <span class=o>=</span> <span class=n>dsets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> 
                           <span class=n>train</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> 
                           <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>())</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 2: MAKING DATASET ITERABLE</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=n>batch_size</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>n_iters</span> <span class=o>=</span> <span class=mi>3000</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=n>n_iters</span> <span class=o>/</span> <span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>)</span> <span class=o>/</span> <span class=n>batch_size</span><span class=p>)</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>)</span>

<span class=n>train_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>train_dataset</span><span class=p>,</span> 
                                           <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> 
                                           <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=n>test_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>test_dataset</span><span class=p>,</span> 
                                          <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> 
                                          <span class=n>shuffle</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 3: CREATE MODEL CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=k>class</span> <span class=nc>RNNModel</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>layer_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>RNNModel</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
        <span class=c1># Hidden dimensions</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>hidden_dim</span> <span class=o>=</span> <span class=n>hidden_dim</span>

        <span class=c1># Number of hidden layers</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>layer_dim</span> <span class=o>=</span> <span class=n>layer_dim</span>

        <span class=c1># Building your RNN</span>
        <span class=c1># batch_first=True causes input/output tensors to be of shape</span>
        <span class=c1># (batch_dim, seq_dim, feature_dim)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>RNN</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>layer_dim</span><span class=p>,</span> <span class=n>batch_first</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>nonlinearity</span><span class=o>=</span><span class=s1>&#39;tanh&#39;</span><span class=p>)</span>

        <span class=c1># Readout layer</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span>

    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=c1># Initialize hidden state with zeros</span>
        <span class=c1>#######################</span>
        <span class=c1>#  USE GPU FOR MODEL  #</span>
        <span class=c1>#######################</span>
        <span class=n>h0</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>layer_dim</span><span class=p>,</span> <span class=n>x</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>),</span> <span class=bp>self</span><span class=o>.</span><span class=n>hidden_dim</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>

        <span class=c1># One time step</span>
        <span class=c1># We need to detach the hidden state to prevent exploding/vanishing gradients</span>
        <span class=c1># This is part of truncated backpropagation through time (BPTT)</span>
        <span class=n>out</span><span class=p>,</span> <span class=n>hn</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>rnn</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>h0</span><span class=o>.</span><span class=n>detach</span><span class=p>())</span>

        <span class=c1># Index hidden state of last time step</span>
        <span class=c1># out.size() --&gt; 100, 28, 100</span>
        <span class=c1># out[:, -1, :] --&gt; 100, 100 --&gt; just want last time step hidden states! </span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc</span><span class=p>(</span><span class=n>out</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=p>:])</span> 
        <span class=c1># out.size() --&gt; 100, 10</span>
        <span class=k>return</span> <span class=n>out</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 4: INSTANTIATE MODEL CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>input_dim</span> <span class=o>=</span> <span class=mi>28</span>
<span class=n>hidden_dim</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>layer_dim</span> <span class=o>=</span> <span class=mi>2</span>  <span class=c1># ONLY CHANGE IS HERE FROM ONE LAYER TO TWO LAYER</span>
<span class=n>output_dim</span> <span class=o>=</span> <span class=mi>10</span>

<span class=n>model</span> <span class=o>=</span> <span class=n>RNNModel</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>layer_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span>

<span class=c1>#######################</span>
<span class=c1>#  USE GPU FOR MODEL  #</span>
<span class=c1>#######################</span>

<span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>&quot;cuda:0&quot;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s2>&quot;cpu&quot;</span><span class=p>)</span>
<span class=n>model</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>


<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 5: INSTANTIATE LOSS CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 6: INSTANTIATE OPTIMIZER CLASS</span>
<span class=sd>&#39;&#39;&#39;</span>
<span class=n>learning_rate</span> <span class=o>=</span> <span class=mf>0.1</span>

<span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=n>learning_rate</span><span class=p>)</span>  

<span class=sd>&#39;&#39;&#39;</span>
<span class=sd>STEP 7: TRAIN THE MODEL</span>
<span class=sd>&#39;&#39;&#39;</span>

<span class=c1># Number of steps to unroll</span>
<span class=n>seq_dim</span> <span class=o>=</span> <span class=mi>28</span>  

<span class=nb>iter</span> <span class=o>=</span> <span class=mi>0</span>
<span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=p>(</span><span class=n>images</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_loader</span><span class=p>):</span>
        <span class=c1># Load images as tensors with gradient accumulation abilities</span>
        <span class=c1>#######################</span>
        <span class=c1>#  USE GPU FOR MODEL  #</span>
        <span class=c1>#######################</span>
        <span class=n>images</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>seq_dim</span><span class=p>,</span> <span class=n>input_dim</span><span class=p>)</span><span class=o>.</span><span class=n>requires_grad_</span><span class=p>()</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
        <span class=n>labels</span> <span class=o>=</span> <span class=n>labels</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>

        <span class=c1># Clear gradients w.r.t. parameters</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>

        <span class=c1># Forward pass to get output/logits</span>
        <span class=c1># outputs.size() --&gt; 100, 10</span>
        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>

        <span class=c1># Calculate Loss: softmax --&gt; cross entropy loss</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>

        <span class=c1># Getting gradients w.r.t. parameters</span>
        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>

        <span class=c1># Updating parameters</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

        <span class=nb>iter</span> <span class=o>+=</span> <span class=mi>1</span>

        <span class=k>if</span> <span class=nb>iter</span> <span class=o>%</span> <span class=mi>500</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
            <span class=c1># Calculate Accuracy         </span>
            <span class=n>correct</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=n>total</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=c1># Iterate through test dataset</span>
            <span class=k>for</span> <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>test_loader</span><span class=p>:</span>
                <span class=c1>#######################</span>
                <span class=c1>#  USE GPU FOR MODEL  #</span>
                <span class=c1>#######################</span>
                <span class=n>images</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>seq_dim</span><span class=p>,</span> <span class=n>input_dim</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>

                <span class=c1># Forward pass only to get logits/output</span>
                <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>

                <span class=c1># Get predictions from the maximum value</span>
                <span class=n>_</span><span class=p>,</span> <span class=n>predicted</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>outputs</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

                <span class=c1># Total number of labels</span>
                <span class=n>total</span> <span class=o>+=</span> <span class=n>labels</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>

                <span class=c1># Total correct predictions</span>
                <span class=c1>#######################</span>
                <span class=c1>#  USE GPU FOR MODEL  #</span>
                <span class=c1>#######################</span>
                <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>():</span>
                    <span class=n>correct</span> <span class=o>+=</span> <span class=p>(</span><span class=n>predicted</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span> <span class=o>==</span> <span class=n>labels</span><span class=o>.</span><span class=n>cpu</span><span class=p>())</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
                <span class=k>else</span><span class=p>:</span>
                    <span class=n>correct</span> <span class=o>+=</span> <span class=p>(</span><span class=n>predicted</span> <span class=o>==</span> <span class=n>labels</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

            <span class=n>accuracy</span> <span class=o>=</span> <span class=mi>100</span> <span class=o>*</span> <span class=n>correct</span> <span class=o>/</span> <span class=n>total</span>

            <span class=c1># Print Loss</span>
            <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Iteration: </span><span class=si>{}</span><span class=s1>. Loss: </span><span class=si>{}</span><span class=s1>. Accuracy: </span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=nb>iter</span><span class=p>,</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span> <span class=n>accuracy</span><span class=p>))</span>
</code></pre></div> </div> <div class=highlight><pre><span></span><code><span class=n>Iteration</span><span class=p>:</span> <span class=mf>500.</span> <span class=n>Loss</span><span class=p>:</span> <span class=mf>0.5983774662017822</span><span class=o>.</span> <span class=n>Accuracy</span><span class=p>:</span> <span class=mi>81</span>
<span class=n>Iteration</span><span class=p>:</span> <span class=mf>1000.</span> <span class=n>Loss</span><span class=p>:</span> <span class=mf>0.2960105836391449</span><span class=o>.</span> <span class=n>Accuracy</span><span class=p>:</span> <span class=mi>86</span>
<span class=n>Iteration</span><span class=p>:</span> <span class=mf>1500.</span> <span class=n>Loss</span><span class=p>:</span> <span class=mf>0.19428101181983948</span><span class=o>.</span> <span class=n>Accuracy</span><span class=p>:</span> <span class=mi>93</span>
<span class=n>Iteration</span><span class=p>:</span> <span class=mf>2000.</span> <span class=n>Loss</span><span class=p>:</span> <span class=mf>0.11918395012617111</span><span class=o>.</span> <span class=n>Accuracy</span><span class=p>:</span> <span class=mi>95</span>
<span class=n>Iteration</span><span class=p>:</span> <span class=mf>2500.</span> <span class=n>Loss</span><span class=p>:</span> <span class=mf>0.11246936023235321</span><span class=o>.</span> <span class=n>Accuracy</span><span class=p>:</span> <span class=mi>95</span>
<span class=n>Iteration</span><span class=p>:</span> <span class=mf>3000.</span> <span class=n>Loss</span><span class=p>:</span> <span class=mf>0.15849310159683228</span><span class=o>.</span> <span class=n>Accuracy</span><span class=p>:</span> <span class=mi>95</span>
</code></pre></div> <h2 id=summary>Summary<a class=headerlink href=#summary title="Permanent link">&para;</a></h2> <p>We've learnt to...</p> <div class="admonition success"> <p class=admonition-title>Success</p> <ul class=task-list> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> <strong>Feedforward Neural Networks</strong> Transition to Recurrent Neural Networks</li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> <strong>RNN Models</strong> in PyTorch<ul class=task-list> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Model A: 1 Hidden Layer RNN (ReLU)</li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Model B: 2 Hidden Layer RNN (ReLU)</li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Model C: 2 Hidden Layer RNN (Tanh)</li> </ul> </li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Models Variation in <strong>Code</strong><ul class=task-list> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Modifying only step 4</li> </ul> </li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Ways to Expand Model’s <strong>Capacity</strong><ul class=task-list> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> More non-linear activation units (<strong>neurons</strong>)</li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> More hidden <strong>layers</strong></li> </ul> </li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> <strong>Cons</strong> of Expanding Capacity<ul class=task-list> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Need more <strong>data</strong></li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Does not necessarily mean higher <strong>accuracy</strong></li> </ul> </li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> <strong>GPU</strong> Code<ul class=task-list> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> 2 things on GPU<ul class=task-list> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> <strong>model</strong></li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> <strong>tensors with gradient accumulation abilities</strong></li> </ul> </li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Modifying only <strong>Step 3, 4 and 7</strong></li> </ul> </li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> <strong>7 Step</strong> Model Building Recap<ul class=task-list> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Step 1: Load Dataset</li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Step 2: Make Dataset Iterable</li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> <strong>Step 3: Create Model Class</strong></li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> <strong>Step 4: Instantiate Model Class</strong></li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Step 5: Instantiate Loss Class</li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> Step 6: Instantiate Optimizer Class</li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> <strong>Step 7: Train Model</strong></li> <li class=task-list-item><label class=task-list-control><input type=checkbox checked><span class=task-list-indicator></span></label> <strong>Step 7: Train Model</strong></li> </ul> </li> </ul> </div> <h2 id=citation>Citation<a class=headerlink href=#citation title="Permanent link">&para;</a></h2> <p>If you have found these useful in your research, presentations, school work, projects or workshops, feel free to cite using this DOI.</p> <p><a href=https://zenodo.org/badge/latestdoi/139945544><img alt=DOI src=https://zenodo.org/badge/139945544.svg></a></p> </article> </div> </div> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> Copyright &copy; 2020 Disponha </div> Todo o conteúdo deste site está publicado sob a licença <a href=https://creativecommons.org/licenses/by-nc-sa/4.0/ target=_blank rel=noopener> Creative Commons CC BY-SA 4.0 Brasil </a> </div> <div class=md-footer-social> <a href=https://github.com/andhremattos target=_blank rel=noopener title=github.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> <a href=https://facebook.com/dhematos target=_blank rel=noopener title=facebook.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg> </a> <a href=https://instagram.com/dhematos target=_blank rel=noopener title=instagram.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M224.1 141c-63.6 0-114.9 51.3-114.9 114.9s51.3 114.9 114.9 114.9S339 319.5 339 255.9 287.7 141 224.1 141zm0 189.6c-41.1 0-74.7-33.5-74.7-74.7s33.5-74.7 74.7-74.7 74.7 33.5 74.7 74.7-33.6 74.7-74.7 74.7zm146.4-194.3c0 14.9-12 26.8-26.8 26.8-14.9 0-26.8-12-26.8-26.8s12-26.8 26.8-26.8 26.8 12 26.8 26.8zm76.1 27.2c-1.7-35.9-9.9-67.7-36.2-93.9-26.2-26.2-58-34.4-93.9-36.2-37-2.1-147.9-2.1-184.9 0-35.8 1.7-67.6 9.9-93.9 36.1s-34.4 58-36.2 93.9c-2.1 37-2.1 147.9 0 184.9 1.7 35.9 9.9 67.7 36.2 93.9s58 34.4 93.9 36.2c37 2.1 147.9 2.1 184.9 0 35.9-1.7 67.7-9.9 93.9-36.2 26.2-26.2 34.4-58 36.2-93.9 2.1-37 2.1-147.8 0-184.8zM398.8 388c-7.8 19.6-22.9 34.7-42.6 42.6-29.5 11.7-99.5 9-132.1 9s-102.7 2.6-132.1-9c-19.6-7.8-34.7-22.9-42.6-42.6-11.7-29.5-9-99.5-9-132.1s-2.6-102.7 9-132.1c7.8-19.6 22.9-34.7 42.6-42.6 29.5-11.7 99.5-9 132.1-9s102.7-2.6 132.1 9c19.6 7.8 34.7 22.9 42.6 42.6 11.7 29.5 9 99.5 9 132.1s2.7 102.7-9 132.1z"/></svg> </a> </div> </div> </div> </footer> </div> <script src=../../../assets/javascripts/vendor.de50e36d.min.js></script> <script src=../../../assets/javascripts/bundle.fc9c3121.min.js></script><script id=__lang type=application/json>{"clipboard.copy": "Copiar para \u00e1rea de transfer\u00eancia", "clipboard.copied": "Copiado para \u00e1rea de transfer\u00eancia", "search.config.lang": "pt", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Digite para iniciar a busca", "search.result.none": "Nenhum resultado encontrado", "search.result.one": "1 resultado encontrado", "search.result.other": "# resultados encontrados"}</script> <script>
        app = initialize({
          base: "../../..",
          features: ["tabs"],
          search: Object.assign({
            worker:"../../../assets/javascripts/worker/search.a68abb33.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script> <script src=../../../javascripts/config.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script> </body> </html>